<HTML><HEAD>

<TITLE>Intro to Algorithms: CHAPTER 30: ALGORITHMS FOR PARALLEL COMPUTERS</TITLE></HEAD><BODY BGCOLOR="#FFFFFF">

<a href="chap31.htm"><img align=right src="../../images/next.gif" alt="Next Chapter" border=0></A>
<a href="toc.htm"><img align=right src="../../images/toc.gif" alt="Return to Table of Contents" border=0></A>
<a href="chap29.htm"><img align=right src="../../images/prev.gif" alt="Previous Chapter" border=0></A>



<h1><a name="094b_19c7">CHAPTER 30: ALGORITHMS FOR PARALLEL COMPUTERS<a name="094b_19c7"></h1><P>
<a name="094b_19b9">As parallel-processing computers have proliferated, interest has increased in <I><B>parallel algorithms</I></B><I>:</I> algorithms that perform more than one operation at a time. The study of parallel algorithms has now developed into a research area in its own right. Indeed, parallel algorithms have been developed for many of the problems we have solved in this text using ordinary serial algorithms. In this chapter, we shall describe a few simple parallel algorithms that illustrate fundamental issues and techniques.<P>
In order to study parallel algorithms, we must choose an appropriate model for parallel computing. The random-access machine, or RAM, which we have used throughout most of this book, is, of course, serial rather than parallel. The parallel models we have studied--sorting networks (Chapter 28) and circuits (Chapter 29)--are too restrictive for investigating, for example, algorithms on data structures.<P>
The parallel algorithms in this chapter are presented in terms of one popular theoretical model: the parallel random-access machine, or PRAM (pronounced &quot;PEE-ram&quot;). Many parallel algorithms for arrays, lists, trees, and graphs can be easily described in the PRAM model. Although the PRAM ignores many important aspects of real parallel machines, the essential attributes of parallel algorithms tend to transcend the models for which they are designed. If one PRAM algorithm outperforms another PRAM algorithm, the relative performance is not likely to change substantially when both algorithms are adapted to run on a real parallel computer.<P>
The PRAM model<P>
<a name="094b_19ba"><a name="094b_19bb"><a name="094b_19bc">Figure 30.1 shows the basic architecture of the <I><B>parallel random-access machine (PRAM)</I></B>. There are <I>p</I> ordinary (serial) processors <I>P</I><SUB>0</SUB>,<I> P</I><SUB>1</SUB>,<I> . . . </I>,<I> P<SUB>p</I>-1</SUB> that have as storage a shared, global memory. All processors can read from or write to the global memory "in parallel" (at the same time). The processors can also perform various arithmetic and logical operations in parallel.<P>
The key assumption regarding algorithmic performance in the PRAM model is that running time can be measured as the number of parallel memory accesses an algorithm performs. This assumption is a straight- forward generalization of the ordinary RAM model, in which the number of memory accesses is asymptotically as good as any other measure of running time. This simple assumption will serve us well in our survey of parallel algorithms, even though real parallel computers cannot perform parallel accesses to global memory in unit time: the time for a memory access grows with the number of processors in the parallel computer.<P>
<img src="689_a.gif"><P>
<h4><a name="094b_19c8">Figure 30.1 The basic architecture of the PRAM. There are p processors P<SUB>0</SUB>, P<SUB>1</SUB>, . . ., P<SUB>p </SUB>-<SUB> 1</SUB> connected to a shared memory. Each processor can access an arbitrary word of shared memory in unit time.<a name="094b_19c8"></sub></sup></h4><P>
Nevertheless, for parallel algorithms that access data in an arbitrary fashion, the assumption of unit-time memory operations can be justified. Real parallel machines typically have a communication network that can support the abstraction of a global memory. Accessing data through the network is a relatively slow operation in comparison with arithmetic and other operations. Thus, counting the number of parallel memory accesses executed by two parallel algorithms does, in fact, yield a fairly accurate estimate of their relative performances. The principal way in which real machines violate the unit-time abstraction of the PRAM is that some memory-access patterns are faster than others. As a first approximation, however, the unit-time assumption in the PRAM model is quite reasonable.<P>
The running time of a parallel algorithm depends on the number of processors executing the algorithm as well as the size of the problem input. Generally, therefore, we must discuss both time and processor count when analyzing PRAM algorithms; this contrasts with serial algorithms, in whose analysis we have focused mainly on time. Typically, there is a trade-off between the number of processors used by an algorithm and its running time. Section 30.3 discusses these trade-offs.<P>
Concurrent versus exclusive memory accesses<P>
<a name="094b_19bd"><a name="094b_19be"><a name="094b_19bf"><a name="094b_19c0">A <I><B>concurrent-read</I></B> algorithm is a PRAM algorithm during whose execution multiple processors can read from the same location of shared memory at the same time. An <I><B>exclusive-read</I></B> algorithm is a PRAM algorithm in which no two processors ever read the same memory location at the same time. We make a similar distinction with respect to whether or not multiple processors can write into the same memory location at the same time, dividing PRAM algorithms into <I><B>concurrent-write</I></B> and <I><B>exclusive-write</I></B> algorithms. Commonly used abbreviations for the types of algorithms we encounter are<P>
<a name="094b_19c1"><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>EREW</I></B></FONT>: exclusive read and exclusive write,<P>
<a name="094b_19c2"><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>CREW</I></B></FONT>: concurrent read and exclusive write,<P>
<a name="094b_19c3"><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>ERCW</I></B></FONT>: exclusive read and concurrent write, and<P>
<a name="094b_19c4"><a name="094b_19c5"><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>CRCW</I></B></FONT>: concurrent read and concurrent write.<P>
(These abbreviations are usually pronounced not as words but rather as strings of letters.)<P>
Of these types of algorithms, the extremes--EREW and CRCW--are the most popular. A PRAM that supports only EREW algorithms is called an <I><B>EREW PRAM</I></B>, and one that supports CRCW algorithms is called a <I><B>CRCW PRAM</I></B>. A CRCW PRAM can, of course, execute EREW algorithms, but an EREW PRAM cannot directly support the concurrent memory accesses required in CRCW algorithms. The underlying hardware of an EREW PRAM is relatively simple, and therefore fast, because it needn't handle conflicting memory reads and writes. A CRCW PRAM requires more hardware support if the unit-time assumption is to provide a reasonably accurate measure of algorithmic performance, but it provides a programming model that is arguably more straightforward than that of an EREW PRAM.<P>
Of the remaining two algorithmic types--CREW and ERCW--more attention has been paid in the literature to the CREW. From a practical point of view, however, supporting concurrency for writes is no harder than supporting concurrency for reads. In this chapter, we shall generally treat an algorithm as being CRCW if it contains either concurrent reads or concurrent writes, without making further distinctions. We discuss the finer points of this distinction in Section 30.2.<P>
<a name="094b_19c6">When multiple processors write to the same location in a CRCW algorithm, the effect of the parallel write is not well defined without additional elaboration. In this chapter, we shall use the <I><B>common-CRCW</I></B> model: when several processors write into the same memory location, they must all write a common (the same) value. There are several alternative types of PRAM's in the literature that handle this problem with a different assumption. Other choices include<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>arbitrary</I></B><I>:</I></FONT> an arbitrary value from among those written is actually stored,<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>priority</I></B><I>:</I></FONT> the value written by the lowest-indexed processor is stored, and<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     <I><B>combining</I></B><I>:</I></FONT> the value stored is some specified combination of the values written.<P>
In the last case, the specified combination is typically some associative and commutative function such as addition (store the sum of all the values written) or maximum (store only the maximum value written).<P>
Synchronization and control<P>
PRAM algorithms must be highly synchronized to work correctly. How is this synchronization achieved? Also, the processors in PRAM algorithms must often detect termination of loop conditions that depend on the state of all processors. How is this control function implemented?<P>
We won't discuss these issues extensively. Many real parallel computers employ a control network connecting the processors that helps with synchronization and termination conditions. Typically, the control network can implement these functions as fast as a routing network can implement global memory references.<P>
For our purposes, it suffices to assume that the processors are inherently tightly synchronized. All processors execute the same statements at the same time. No processor races ahead while others are further back in the code. As we go through our first parallel algorithm, we shall point out where we assume that processors are synchronized.<P>
For detecting the termination of a parallel loop that depends on the state of all processors, we shall assume that a parallel termination condition can be tested through the control network in <I>O</I>(1) time. Some EREW PRAM models in the literature do not make this assumption, and the (logarithmic) time for testing the loop condition must be included in the overall running time (see Exercise 30.1-8). As we shall see in Section 30.2, CRCW PRAM<FONT FACE="CG Times (W1)" SIZE=2>'</FONT>s do not need a control network to test termination: they can detect termination of a parallel loop in <I>O</I>(1) time through the use of concurrent writes.<P>
Chapter outline<P>
Section 30.1 introduces the technique of pointer jumping, which provides a fast way to manipulate lists in parallel. We show how pointer jumping can be used to perform prefix computations on lists and how fast algorithms on lists can be adapted for use on trees. Section 30.2 discusses the relative power of CRCW and EREW algorithms and shows that concurrent memory accessing provides increased power.<P>
Section 30.3 presents Brent<FONT FACE="CG Times (W1)" SIZE=2>'</FONT>s theorem, which shows how combinational circuits can be efficiently simulated by PRAM<FONT FACE="CG Times (W1)" SIZE=2>'</FONT>s. The section also discusses the important issue of work efficiency and gives conditions under which a <I>p</I>-processor PRAM algorithm can be efficiently translated into a <I>p</I>'-processor PRAM algorithm for any <I>p</I>' &lt; <I>p</I>. Section 30.4 reprises the problem of performing a prefix computation on a linked list and shows how a randomized algorithm can perform the computation in a work-efficient fashion. Finally, Section 30.5 shows how symmetry can be broken in parallel in much less than logarithmic time using a deterministic algorithm.<P>
The parallel algorithms in this chapter have been drawn principally from the area of graph theory. They represent only a scant selection of the present array of parallel algorithms. The techniques introduced in this chapter, however, are quite representative of the techniques used for parallel algorithms in other areas of computer science.<P>





<h1><a name="094d_19c9">30.1 Pointer jumping<a name="094d_19c9"></h1><P>
<a name="094d_19c7"><a name="094d_19c8">Among the more interesting PRAM algorithms are those that involve pointers. In this section, we investigate a powerful technique called pointer jumping, which yields fast algorithms for operating on lists. Specifically, we introduce an <I>O</I>(lg <I>n</I>)-time algorithm that computes the distance to the end of the list for each object in an <I>n</I>-object list. We then modify this algorithm to perform a &quot;parallel prefix&quot; computation on an <I>n</I>-object list in <I>O</I>(lg <I>n</I>) time. Finally, we investigate a technique that allows many problems on trees to be converted to list problems, which can then be solved by pointer jumping. All of the algorithms in this section are EREW algorithms: no concurrent accesses to global memory are required.<P>





<h2><a name="094e_19cd">30.1.1 List ranking<a name="094e_19cd"></h2><P>
<a name="094e_19c9"><a name="094e_19ca"><a name="094e_19cb">Our first parallel algorithm operates on lists. We can store a list in a PRAM much as we store lists in an ordinary RAM. To operate on list objects in parallel, however, it is convenient to assign a &quot;responsible&quot; processor to each object. We shall assume that there are as many processors as list objects, and that the <I>i</I>th processor is responsible for the <I>i</I>th object. Figure 30.2(a), for example, shows a linked list consisting of the sequence of objects <IMG SRC="../IMAGES/lftwdchv.gif">3,4,6,1,0,5<IMG SRC="../IMAGES/wdrtchv.gif">. Since there is one processor per list object, every object in the list can be operated on by its responsible processor in <I>O</I>(1) time.<P>
Suppose that we are given a singly linked list <I>L</I> with <I>n</I> objects and wish to compute, for each object in <I>L</I>, its distance from the end of the list. More formally, if <I>next</I> is the pointer field, we wish to compute a value <I>d</I>[<I>i</I>] for each object <I>i</I> in the list such that<P>
<img src="692_a.gif"><P>
We call the problem of computing the <I>d</I> values the <I><B>list-ranking problem.</I></B><P>
One solution to the list-ranking problem is simply to propagate distances back from the end of the list. This method takes <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) time, since the <I>k</I>th object from the end must wait for the <I>k</I>- 1 objects following it to determine their distances from the end before it can determine its own. This solution is essentially a serial algorithm.<P>
<img src="693_a.gif"><P>
<h4><a name="094e_19ce">Figure 30.2 Finding the distance from each object in an n-object list to the end of the list in O(lg n) time using pointer jumping. (a) A linked list represented in a PRAM with d values initialized. At the end of the algorithm, each d value holds the distance of its object from the end of the list. Each object's responsible processor appears above the object. (b)-(d) The pointers and d values after each iteration of the while loop in the algorithm <FONT FACE="Courier New" SIZE=2>LIST<FONT FACE="Times New Roman" SIZE=2>-R<FONT FACE="Courier New" SIZE=2>ANK.<a name="094e_19ce"></FONT></FONT></FONT></sub></sup></h4><P>
An efficient parallel solution, requiring only <I>O</I>(lg <I>n</I>) time, is given by the following parallel pseudocode.<P>
<pre><a name="094e_19cc">LIST-RANK(<I>L</I>)</sub></sup></pre><P>
<pre>1<B>  for</B> each processor <I>i</I>, in parallel</sub></sup></pre><P>
<pre>2<B>       do if</B> <I>next</I>[<I>i</I>] = NIL</sub></sup></pre><P>
<pre>3<B>             then</B> <I>d</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> 0</sub></sup></pre><P>
<pre>4<B>             else</B> <I>d</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> 1</sub></sup></pre><P>
<pre>5<B>  while</B> there exists an object <I>i</I> such that <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>6<B>      do for</B> each processor <I>i,</I> in parallel</sub></sup></pre><P>
<pre>7<B>             do if</B> <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>8<B>                   then</B> <I>d</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>d</I>[<I>i</I>] + <I>d</I>[<I>next</I>[<I>i</I>]]</sub></sup></pre><P>
<pre>9                        <I>next</I>[i] <IMG SRC="../IMAGES/arrlt12.gif"> <I>next</I>[<I>next</I>[<I>i</I>]]</sub></sup></pre><P>
Figure 30.2 shows how the algorithm computes the distances. Each part of the figure shows the state of the list before an iteration of the <B>while </B> loop of lines 5-9. Part (a) shows the list just after initialization. In the first iteration, the first 5 list objects have non-<FONT FACE="Courier New" SIZE=2>nil</FONT> pointers, so that lines 8-9 are executed by their responsible processors. The result appears in part (b) of the figure. In the second iteration, only the first 4 objects have non-<FONT FACE="Courier New" SIZE=2>NIL</FONT> pointers; the result of this iteration is shown in part (c). In the third iteration, only the first 2 objects are operated on, and the final result, in which all objects have <FONT FACE="Courier New" SIZE=2>NIL</FONT> pointers, appears in part (d).<P>
The idea implemented by line 9, in which we set <I>next</I>[<I>i</I>]<I> </I><IMG SRC="../IMAGES/arrlt12.gif"><I> next</I>[<I>next</I>[<I>i</I>]] for all non-<FONT FACE="Courier New" SIZE=2>nil</FONT> pointers <I>next</I>[<I>i</I>]<I>,</I> is called <I><B>pointer jumping</I></B>. Note that th  e pointer fields are changed by pointer jumping, thus destroying the structure of the list. If the list structure must be preserved, then we make copies of the <I>next</I> pointers and use the copies to compute the distances.<P>





<h3>Correctness</h3><P>
<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT> maintains the invariant that at the beginning of each iteration of the <B>while</B> loop of lines 5-9, for each object <I>i,</I> if we add the <I>d</I> values in the sublist headed by <I>i,</I> we obtain the correct distance from <I>i</I> to the end of the original list <I>L</I>. In Figure 30.2(b), for example, the sublist headed by object 3 is the sequence <IMG SRC="../IMAGES/lftwdchv.gif">3,6,0<IMG SRC="../IMAGES/wdrtchv.gif"> whose <I>d</I> values 2, 2, and 1 sum to 5, its distance from the end of the original list. The reason the invariant is maintained is that when each object &quot;splices out&quot; its successor in the list, it adds its successor's <I>d</I> value to its own.<P>
Observe that for this pointer-jumping algorithm to work correctly, the parallel memory accesses must be synchronized. Each execution of line 9 can update several <I>next</I> pointers. We rely on all the memory reads on the right-hand side of the assignment (reading <I>next</I>[<I>next</I>[<I>i</I>]]) occurring before any of the memory writes (writing <I>next</I>[<I>i</I>]) on the left-hand side.<P>
Now let us see why <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT> is an EREW algorithm. Because each processor is responsible for at most one object, every read and write in lines 2-7 is exclusive, as are the writes in lines 8-9. Observe that pointer jumping maintains the invariant that for any two distinct objects <I>i</I> and <I>j, </I>either <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"><I> next</I>[<I>j</I>]<I> or next</I>[<I>i</I>]<I> = next</I>[<I>j</I>] = <FONT FACE="Courier New" SIZE=2>NIL</FONT>. This invariant is certainly true for the initial list, and it is maintained by line 9. Because all non-<FONT FACE="Courier New" SIZE=2>NIL</FONT> <I>next</I> values are distinct, all reads in line 9 are exclusive.<P>
We do need to assume that some synchronization is performed in line 8 if all reads are to be exclusive. In particular, we require that all processors <I>i </I>read <I>d</I>[<I>i</I>] and then <I>d</I>[<I>next</I>[<I>i</I>]]<I>.</I> With this synchronization, if an object <I>i </I>has <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> <FONT FACE="Courier New" SIZE=2>NIL</FONT> and there is another object <I>j</I> pointing to <I>i</I> (that is, <I>next</I>[<I>j</I>]<I> = i</I>)<I>,</I> then the first read fetches <I>d</I>[<I>i</I>] for processor <I>i</I> and the second read fetches <I>d</I>[<I>i</I>] for processor <I>j.</I> Thus, L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT> is an EREW algorithm.<P>
From here on, we ignore such details of synchronization and assume that the PRAM and its pseudocode programming environment act in a consistent, synchronized manner, with all processors executing reads and writes at the same time.<P>
<P>







<h3>Analysis</h3><P>
We now show that if there are <I>n</I> objects in list <I>L,</I> then L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT> takes <I>O</I>(lg <I>n</I>) time. Since the initialization takes <I>O</I>(1) time and each iteration of the <B>while</B> loop takes <I>O</I>(1) time, it suffices to show that there are exactly <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>n</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"></FONT> iterations. The key observation is that each step of pointer jumping transforms each list into two interleaved lists: one consisting of the objects in even positions and the other consisting of objects in odd positions. Thus, each pointer-jumping step doubles the number of lists and halves their lengths. By the end of <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>n</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"></FONT> iterations, therefore, all lists contain only one object.<P>
We are assuming that the termination test in line 5 takes <I>O</I>(1) time, presumably due to a control network in the EREW PRAM. Exercise 30.1-8 asks you to describe an<I> O</I>(1g <I>n</I>)-time EREW implementation of L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank </FONT>that performs the termination test explicitly in the pseudocode.<P>
<a name="0950_19cd">Besides parallel running time, there is another interesting performance measure for parallel algorithms. We define the <I><B>work</I></B> performed by a parallel algorithm as the product of its running time and the number of processors it requires. Intuitively, the work is the amount of computing that a serial RAM performs when it simulates the parallel algorithm.<P>
The procedure L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT> performs <IMG SRC="../IMAGES/bound.gif">(<I>n</I> lg <I>n</I>) work, since it requires <I>n </I>processors and runs in <IMG SRC="../IMAGES/bound.gif">(lg <I>n</I>) time. The straightforward serial algorithm for the list-ranking problem runs in <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) time, indicating that more work is performed by L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT> than is absolutely necessary, but only by a logarithmic factor.<P>
<a name="0950_19ce">We define a PRAM algorithm <I>A</I> to be <I><B>work-efficient</I></B> with respect to another (serial or parallel) algorithm <I>B</I> for the same problem if the work performed by <I>A</I> is within a constant factor of the work performed by <I>B</I>. We also say more simply that a PRAM algorithm <I>A </I>is <I><B>work-efficient</I></B> if  it is work-efficient with respect to the best possible algorithm on a serial RAM. Since the best possible serial algorithm for list ranking runs in <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) time on a serial RAM, <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT> is not work-efficient. We shall present a work-efficient parallel algorithm for list ranking in Section 30.4.<P>
<P>


<P>







<h2><a name="0951_19d5">30.1.2 Parallel prefix on a list<a name="0951_19d5"></h2><P>
<a name="0951_19cf"><a name="0951_19d0">The technique of pointer jumping extends well beyond the application of list ranking. Section 29.2.2 shows how, in the context of arithmetic circuits, a &quot;prefix&quot; computation can be used to perform binary addition quickly. We now investigate how pointer jumping can be used to perform prefix computations. Our EREW algorithm for the prefix problem runs in <I>O</I>(lg<I> n</I>) time on <I>n</I>-object lists.<P>
<a name="0951_19d1"><a name="0951_19d2"><a name="0951_19d3">A <I><B>prefix computation</I></B> is defined in terms of a binary, associative operator <IMG SRC="../IMAGES/circx.gif">. The computation takes as input a sequence <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1</SUB>, <I>x<SUB>2</I></SUB>, . . . , <I>x<SUB>n</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"> and produces as output a sequence <IMG SRC="../IMAGES/lftwdchv.gif"><I>y</I><SUB>1</SUB>, <I>y</I>, . . . , <I>y<SUB>n</SUB></I><IMG SRC="../IMAGES/wdrtchv.gif"><I> </I>such that <I>y</I><SUB>1</SUB> = <I>x</I><SUB>1</SUB> and<P>
<pre>y<I><SUB>k  </SUB>=  y<SUB>k</I>-1</SUB><IMG SRC="../IMAGES/circx.gif"> <I>x<SUB>k</I></sub></sup></pre><P>
<pre>=  <I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/circx.gif"> <I>x</I><SUB>2 </SUB><IMG SRC="../IMAGES/circx.gif"> . . . <IMG SRC="../IMAGES/circx.gif"> <I>x<SUB>k</I></sub></sup></pre><P>
for <I>k</I> = 2,3, . . ., <I>n.</I> In other words, each <I>y<SUB>k</I></SUB> is obtained by &quot;multiplying&quot; together the first <I>k</I> elements of the sequence of<I> x<SUB>k</I></SUB>--hence, the term &quot;prefix.<FONT FACE="CG Times (W1)" SIZE=2>&quot;</FONT> (The definition in Chapter 29 indexes the sequences from 0, whereas this definitionindexes from 1--an inessential difference.)<P>
As an example of a prefix computation, suppose that every element of an <I>n</I>-object list contains the value 1, and let <IMG SRC="../IMAGES/circx.gif"> be ordinary addition. Since the<I> k</I>th element of the list contains the value<I> x<SUB>k</I></SUB> = 1 for <I>k</I> = 1,2, . . ., <I>n,</I> a prefix computation produces <I>y<SUB>k</I></SUB> = <I>k,</I> the index of the <I>k</I>th element. Thus, another way to perform list ranking is to reverse the list (which can be done in <I>O</I>(1) time), perform this prefix computation, and subtract 1 from each value computed.<P>
We now show how an EREW algorithm can compute parallel prefixes in <I>O</I>(lg <I>n</I>) time on <I>n</I>-object lists. For convenience, we define the notation<P>
<pre>[<I>i, j</I>]<I> = x<SUB>i </I></SUB><IMG SRC="../IMAGES/circx.gif"><I><SUB> </SUB>x<SUB>i+</I>1</SUB><IMG SRC="../IMAGES/circx.gif"><I> <IMG SRC="../IMAGES/dot10.gif"><IMG SRC="../IMAGES/dot10.gif"><IMG SRC="../IMAGES/dot10.gif"> </I><IMG SRC="../IMAGES/circx.gif"><I> x<SUB>j  </I></sub></sup></pre><P>
for integers <I>i</I> and <I>j</I> in the range 1 <IMG SRC="../IMAGES/lteq12.gif"> <I>i </I><IMG SRC="../IMAGES/lteq12.gif"> j <I><IMG SRC="../IMAGES/lteq12.gif"> n.</I> Then, [<I>k,k</I>]<I> = x<SUB>k</I></SUB> for<P>
<pre><I>k = </I>1, 2,<I>...</I>, <I>n</I>, and</sub></sup></pre><P>
<pre>[<I>i,k</I>]<I> = </I>[<I>i</I>,<I> j</I>]<I> </I><IMG SRC="../IMAGES/circx.gif"><I> </I>[<I>j+</I>1, <I>k</I>]</sub></sup></pre><P>
for 0 <IMG SRC="../IMAGES/lteq12.gif"><I> i</I> <IMG SRC="../IMAGES/lteq12.gif"> <I>j </I>&lt; <I>k</I> <IMG SRC="../IMAGES/lteq12.gif"> <I>n</I>. In terms of this notation, the goal of a prefix computation is to compute <I>y<SUB>k</SUB> = </I>[1,<I> k</I>]<I> for k = </I>1, 2,<I> . . . </I>,<I> n.</I><P>
When we perform a prefix computation on a list, we wish the order of the input sequence <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . , <I>x</I><SUB>n</SUB><IMG SRC="../IMAGES/wdrtchv.gif"> to be determined by how the objects are linked together in the list, and not by the index of the object in the array of memory that stores objects. (Exercise 30.1-2 asks for a prefix algorithm for arrays.) The following EREW algorithm starts with a value <I>x</I>[<I>i</I>] in each object <I>i</I> in a list<I> L</I>. If object<I> i</I> is the <I>k</I>th object from the beginning of the list, then <I>x</I>[<I>i</I>]<I> = x<SUB>k</I></SUB> is the <I>k</I>th element of the input sequence. Thus, the parallel prefix computation produces <I>y</I>[<I>i</I>]<I> = y<SUB>k</SUB> = </I>[1,<I> k</I>].<P>
<pre><a name="0951_19d4">LIST-PREFIX(<I>L</I>)</sub></sup></pre><P>
<pre>1<B>  for</B> each processor <I>i</I>, in parallel</sub></sup></pre><P>
<pre>2<B>      do</B> <I>y</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>x</I>[<I>i</I>]</sub></sup></pre><P>
<pre>3<B>  while</B> there exists an object <I>i</I> such that <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>4<B>      do for</B> each processor <I>i,</I> in parallel</sub></sup></pre><P>
<pre>5<B>             do if</B> <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>6<B>                   then</B> <I>y</I>[<I>next</I>[<I>i</I>]] <IMG SRC="../IMAGES/arrlt12.gif"> <I>y</I>[<I>i</I>] <IMG SRC="../IMAGES/circx.gif"> <I>y</I>[<I>next</I>[<I>i</I>]]</sub></sup></pre><P>
<pre>7                        <I>next</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>next</I>[<I>next</I>[<I>i</I>]]</sub></sup></pre><P>
The pseudocode and Figure 30.3 indicate the similarity between this algorithm and L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT>. The only differences are the initialization and the updating of <I>d</I> or <I>y</I> values. In L<FONT FACE="Courier New" SIZE=2>ist-</FONT>R<FONT FACE="Courier New" SIZE=2>ank</FONT>, processor <I>i</I> updates <I>d</I>[<I>i</I>]--its own <I>d</I> value--whereas in <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT>, processor <I>i</I> updates <I>y</I>[<I>next</I>[<I>i</I>]]--another processor's <I>y</I> value. Note that L<FONT FACE="Courier New" SIZE=2>IST-</FONT><FONT FACE="Courier New" SIZE=2>PREFIX</FONT> is EREW for the same reason as L<FONT FACE="Courier New" SIZE=2>ist</FONT>-R<FONT FACE="Courier New" SIZE=2>ank</FONT>: pointer jumping maintains the invariant that for distinct objects <I>i</I> and <I>j</I>, either <I>next</I>[<I>i</I>]<I> </I><IMG SRC="../IMAGES/noteq.gif"><I> next</I>[<I>j</I>]<I> </I>or<I> next</I>[<I>i</I>]<I> = next</I>[<I>j</I>]<I> =<FONT FACE="Courier New" SIZE=2> NIL</FONT>.</I><P>
Figure 30.3 shows the state of the list before each iteration of the <B>while </B>loop. The procedure maintains the invariant that at the end of the <I>t</I>th execution of the <B>while</B> loop, the <I>k</I>th processor stores [max(1,<I> k - </I>2<I><SUP>t</SUP> + </I>1),<I> k</I>],<I> </I>for <I>k</I> = 1, 2, . . . , <I>n</I>. In the first iteration, the <I>k</I>th list object points initially to the (<I>k</I> + 1)st object, except that the last object has a <FONT FACE="Courier New" SIZE=2>NIL</FONT> pointer. Line 6 causes the <I>k</I>th object, for <I>k</I> = 1, 2, . . . , <I>n</I> - 1, to fetch the value [<I>k </I>+ 1, <I>k </I>+ 1] from its successor. It then performs the operation [<I>k, k</I>] <IMG SRC="../IMAGES/circx.gif"> [<I>k + </I>1,<I> k </I>+ 1], yielding [<I>k, k </I>+ 1], which it stores back into its successor. The <I>next</I> pointers are then jumped as in <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT>, and the result of the first iteration appears in Figure 30.3(b). We can view the second iteration similarly. For <I>k</I> = 1, 2, . . . , <I>n</I> - 2, the <I>k</I>th object fetches the value [<I>k + </I>1,<I> k </I>+ 2] from its successor (as defined by the new value in its field <I>next</I>), and then it stores [<I>k - </I>1,<I> k</I>]<I> </I><IMG SRC="../IMAGES/circx.gif"> <I></I>[<I>k + </I>1,<I> k + </I>2]<I> = </I>[<I>k - </I>1,<I> k + </I>2] into its successor. The result is shown in Figure 30.3(c). In the third and final iteration, only the first two list objects have non-<FONT FACE="Courier New" SIZE=2>NIL</FONT> pointers, and they fetch values from their successors in their respective lists. The final result appears in Figure 30.3(d). The key observation that makes <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> work is that at each step, if we perform a prefix computation on each of the several existing lists, each object obtains its correct value.<P>
<img src="697_a.gif"><P>
<h4><a name="0951_19d6">Figure 30.3 The parallel prefix algorithm <FONT FACE="Courier New" SIZE=2>LIST-PREFIX</FONT> on a linked list. (a) The initial y value of the kth object in the list is [k, k]. The next pointer of the kth object points to the (k + 1)st object, or <FONT FACE="Courier New" SIZE=2>NIL</FONT> for the last object. (b)-(d) The y and next values before each test in line 3. The final answer is in part (d), in which the y value for the kth object is [1, k] for all k.<a name="0951_19d6"></sub></sup></h4><P>
Since the two algorithms use the same pointer-jumping mechanism, <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> has the same analysis as <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT>: the running time is <I>O</I>(lg<I> n</I>) on an EREW PRAM, and the total work performed is <IMG SRC="../IMAGES/bound.gif">(<I>n </I>1g<I> n</I>).<P>
<P>







<h2><a name="0952_19d9">30.1.3 The Euler-tour technique<a name="0952_19d9"></h2><P>
<a name="0952_19d5"><a name="0952_19d6">In this section, we shall introduce the Euler-tour technique and show how it can be applied to the problem of computing the depth of each node in an <I>n</I>-node binary tree. A key step in this <I>O</I>(lg<I> n</I>)-time EREW algorithm is a parallel prefix computation.<P>
To store binary trees in a PRAM, we use a simple binary-tree representation of the sort presented in Section 11.4. Each node <I>i</I> has fields <I>parent</I>[<I>i</I>], <I>left</I>[<I>i</I>], and <I>right</I>[<I>i</I>], which point to node <I>i</I>'s parent, left child, and right child, respectively. Let us assume that each node is identified by a non-negative integer. For reasons that will soon become apparent, we associate not one but three processors with each node; we call these the node's <I>A, B</I>, and <I>C</I> processors. We should be able to map between a node and its three processors easily; for example, node <I>i</I> might be associated with processors 3<I>i</I>, 3<I>i </I>+ 1, and 3<I>i </I>+ 2.<P>
<a name="0952_19d7">Computing the depth of each node in an <I>n</I>-node tree takes <I>O</I>(<I>n</I>) time on a serial RAM. A simple parallel algorithm to compute depths propagates a &quot;wave&quot; downward from the root of the tree. The wave reaches all nodes at the same depth simultaneously, and thus by incrementing a counter carried along with the wave, we can compute the depth of each node. This parallel algorithm works well on a complete binary tree, since it runs in time proportional to the tree's height. The height of the tree could be as large as <I>n</I> - 1, however, in which case the algorithm would run in <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) time--no better than the serial algorithm. Using the Euler-tour technique, however, we can compute node depths in <I>O</I>(l<I>g n</I>) time on an EREW PRAM, whatever the height of the tree.<P>
<a name="0952_19d8">An <I><B>Euler tour</I></B> of a graph is a cycle that traverses each edge exactly once, although it may visit a vertex more than once. By Problem 23-3, a connected, directed graph has an Euler tour if and only if for all vertices <I>v</I>, the in-degree of <I>v</I> equals the out-degree of <I>v</I>. Since each undirected edge (<I>u, v</I>) in an undirected graph maps to two directed edges (<I>u, v</I>) and (<I>v, u</I>) in the directed version, the directed version of any connected, undirected graph--and therefore of any undirected tree--has an Euler tour.<P>
To compute the depths of nodes in a binary tree <I>T</I>, we first form an Euler tour of the directed version of <I>T</I> (viewed as an undirected graph). The tour corresponds to a walk of the tree and is represented in Figure 30.4(a) by a linked list running through the nodes of the tree. Its structure is as follows:<P>
<IMG SRC="../IMAGES/dot12.gif">     A node's <I>A</I> processor points to the <I>A</I> processor of its left child, if it exists, and otherwise to its own <I>B</I> processor.<P>
<IMG SRC="../IMAGES/dot12.gif">     A node's <I>B</I> processor points to the <I>A</I> processor of its right child, if it exists, and otherwise to its own <I>C</I> processor.<P>
<IMG SRC="../IMAGES/dot12.gif">     A node's <I>C</I> processor points to the <I>B</I> processor of its parent if it is a left child and to the <I>C</I> processor of its parent if it is a right child. The root's <I>C</I> processor points to <FONT FACE="Courier New" SIZE=2>NIL</FONT>.<P>
Thus, the head of the linked list formed by the Euler tour is the root's <I>A</I> processor, and the tail is the root's <I>C</I> processor. Given the pointers composing the original tree, an Euler tour can be constructed in <I>O</I>(1) time.<P>
Once we have the linked list representing the Euler tour of <I>T</I>, we place a 1 in each <I>A</I> processor, a 0 in each <I>B</I> processor, and a - 1 in each <I>C </I>processor, as shown in Figure 30.4(a). We then perform a parallel prefix computation using ordinary addition as the associative operation, as we did in Section 30.1.2. Figure 30.4(b) shows the result of the parallel prefix computation.<P>
<img src="699_a.gif"><P>
<h4><a name="0952_19da">Figure 30.4 Using the Euler-tour technique to compute the depth of each node in a binary tree. (a) The Euler tour is a list corresponding to a walk of the tree. Each processor contains a number used by a parallel prefix computation to compute node depths. (b) The result of the parallel prefix computation on the linked list from (a). The C processor of each node (blackened) contains the node's depth. (You can verify the result of this prefix computation by computing it serially.)<a name="0952_19da"></sub></sup></h4><P>
We claim that after performing the parallel prefix computation, the depth of each node resides in the node's <I>C</I> processor. Why? The numbers are placed into the <I>A</I>, <I>B</I>, and <I>C </I>processors in such a way that the net effect of visiting a subtree is to add 0 to the running sum. The <I>A</I> processor of each node <I>i</I> contributes 1 to the running sum in <I>i</I>'s left subtree, reflecting the depth of <I>i</I>'s left child being one greater than the depth of <I>i</I>. The <I>B </I>processor contributes 0 because the depth of node <I>i</I>'s left child equals the depth of node <I>i</I>'s right child. The <I>C</I> processor contributes - 1, so that from the perspective of node <I>i</I>'s parent, the entire visit to the subtree rooted at node <I>i</I> has no effect on the running sum.<P>
The list representing the Euler tour can be computed in <I>O</I>(1) time. It has 3<I>n</I> objects, and thus the the parallel prefix computation takes only <I>O</I>(lg <I>n</I>)<I> </I>time. Thus, the total amount of time to compute all node depths is <I>O</I>(lg<I> n</I>). Because no concurrent memory accesses are needed, the algorithm is an EREW algorithm.<P>
<P>







<h2><a name="0953_0001">Exercises<a name="0953_0001"></h2><P>
<a name="0953_0002">30.1-1<a name="0953_0002"><P>
Give an <I>O</I>(lg <I>n</I>)-time EREW algorithm that determines for each object in an <I>n</I>-object list whether it is the middle (<IMG SRC="../IMAGES/hfbrdl12.gif"><I>n</I>/2<IMG SRC="../IMAGES/hfbrdr12.gif">th) object.<P>
<a name="0953_0003">30.1-2<a name="0953_0003"><P>
Give an <I>O</I>(lg <I>n</I>)-time EREW algorithm to perform the prefix computation on an array <I>x</I>[1. . <I>n</I>]. Do not use pointers, but perform index computations directly.<P>
<a name="0953_0004">30.1-3<a name="0953_0004"><P>
Suppose that each object in an <I>n</I>-object list <I>L</I> is colored either red or blue. Give an efficient EREW algorithm to form two lists from the objects in <I>L</I>: one consisting of the blue objects and one consisting of the red objects.<P>
<a name="0953_0005">30.1-4<a name="0953_0005"><P>
An EREW PRAM has <I>n</I> objects distributed among several disjoint circular lists. Give an efficient algorithm that determines an arbitrary representative object for each list and acquaints each object in the list with the identity of the representative. Assume that each processor knows its own unique index.<P>
<a name="0953_0006">30.1-5<a name="0953_0006"><P>
Give an <I>O</I>(lg<I> n</I>)-time EREW algorithm to compute the size of the subtree rooted at each node of an <I>n</I>-node binary tree. (<I>Hint</I>: Take the difference of two values in a running sum along an Euler tour.)<P>
<a name="0953_0007">30.1-6<a name="0953_0007"><P>
Give an efficient EREW algorithm to compute preorder, inorder, and post-order numberings for an arbitrary binary tree.<P>
<a name="0953_0008">30.1-7<a name="0953_0008"><P>
Extend the Euler-tour technique from binary trees to ordered trees with arbitrary node degrees. Specifically, describe a representation for ordered trees that allows the Euler-tour technique to be applied. Give an EREW algorithm to compute the node depths of an <I>n</I>-node ordered tree in <I>O</I>(lg <I>n</I>) time.<P>
<a name="0953_0009">30.1-8<a name="0953_0009"><P>
Describe an <I>O</I>(l<I>g n</I>)-time EREW implementation of <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT> that performs the loop-termination test explicitly. (<I>Hint</I>: Interleave the test with the loop body.)<P>
<P>


<P>







<h1><a name="0954_19dd">30.2 CRCW algorithms versus EREW algorithms<a name="0954_19dd"></h1><P>
<a name="0954_19d9"><a name="0954_19da">The debate about whether or not concurrent memory accesses should be provided by the hardware of a parallel computer is a messy one. Some argue that hardware mechanisms to support CRCW algorithms are too expensive and used too infrequenly to be justified. Others complain that EREW PRAM's provide too restrictive a programming model. The answer to this debate probably lies somewhere in the middle, and various compromise models have been proposed. Nevertheless, it is instructive to examine what algorithmic advantage is provided by concurrent accesses to memory.<P>
<a name="0954_19db"><a name="0954_19dc">In this section, we shall show that there are problems on which a CRCW algorithm outperforms the best possible EREW algorithm. For the problem of finding the identities of the roots of trees in a forest, concurrent reads allow for a faster algorithm. For the problem of finding the maximum element in an array, concurrent writes permit a faster algorithm.<P>





<h2>A problem in which concurrent reads help</h2><P>
Suppose we are given a forest of binary trees in which each node <I>i</I> has a pointer <I>parent</I>[<I>i</I>] to its parent, and we wish each node to find the identity of the root of its tree. Associating processor <I>i </I>with each node <I>i</I> in a forest <I>F</I>, the following pointer-jumping algorithm stores the identity of the root of each node <I>i</I>'s tree in <I>root</I>[<I>i</I>].<P>
<pre><a name="0955_19dd">FIND-ROOTS(<I>F</I>)</sub></sup></pre><P>
<pre>1.<B>  for</B> each processor <I>i</I>, in parallel</sub></sup></pre><P>
<pre>2.<B>      do if</B> <I>parent</I>[<I>i</I>] = NIL</sub></sup></pre><P>
<pre>3.<B>            then</B> <I>root</I>[i]<IMG SRC="../IMAGES/arrlt12.gif"> <I>i</I></sub></sup></pre><P>
<pre>4.<B>  while</B> there exists a node <I>i</I> such that <I>parent</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>5.<B>      do for</B> each processor <I>i</I>, in parallel</sub></sup></pre><P>
<pre>6.<B>             do if</B> <I>parent</I>[<I>i</I>] <IMG SRC="../IMAGES/noteq.gif"> NIL</sub></sup></pre><P>
<pre>7.<B>                   then</B> <I>root</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"><I> root</I>[<I>parent</I>[<I>i</I>]]</sub></sup></pre><P>
<pre>8.                        <I>parent</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>parent</I>[<I>parent</I>[<I>i</I>]]</sub></sup></pre><P>
Figure 30.5 illustrates the operation of this algorithm. After the initialization performed by lines 1-3, shown in Figure 30.5(a), the only nodes that know the identities of their roots are the roots themselves. The <B>while </B>loop of lines 4-8 performs the pointer jumping and fills in the <I>root</I> fields. Figures 30.5(b)-(d) show the state of the forest after the first, second, and third iterations of the loop. As you can see, the algorithm maintains the invariant that if <I>parent</I>[<I>i</I>] = <FONT FACE="Courier New" SIZE=2>NIL</FONT>, then <I>root</I>[<I>i</I>] has been assigned the identity of the node's root.<P>
We claim that <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS</FONT> is a CREW algorithm that runs in <I>O</I>(lg <I>d</I>) time, where <I>d</I> is the depth of the maximum-depth tree in the forest. The only writes occur on lines 3, 7, and 8, and these are all exclusive because in each one, processor <I>i</I> writes into only node <I>i</I>. The reads in lines 7-8 are concurrent, however, because several nodes may have pointers to the same node. In Figure 30.5(b), for example, we see that during the second iteration of the <B>while</B> loop, <I>root</I>[4] and <I>parent</I>[4] are read by processors 18, 2, and 7.<P>
The running time of <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS</FONT> <I>O</I>(lg <I>d</I>) for essentially the same reason as for <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT>: the length of each path is halved in each iteration. Figure 30.5 shows this characteristic plainly.<P>
How fast can <I>n</I> nodes in a forest determine the roots of their binary trees using only exclusive reads? A simple argument shows that <IMG SRC="../IMAGES/omega12.gif"><I></I>(lg <I>n)</I> time is required. The key observation is that when reads are exclusive, each step of the PRAM allows a given piece of information to be copied to at most one other memory location; thus the number of locations that can contain a given piece of information at most doubles with each step. Looking at a single tree, we have initially that at most 1 memory location stores the identity of the root. After 1 step, at most 2 locations can contain the identity of the root; after <I>k</I> steps, at most 2<I><SUP>k</I>-1</SUP> locations can contain the identity of the root. If the size of the tree is <IMG SRC="../IMAGES/bound.gif">(<I>n</I>), we need <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) locations to contain the root's identity when the algorithm terminates; thus, <IMG SRC="../IMAGES/omega12.gif"><I></I>(lg <I>n</I>)<I> </I>steps are required in all.<P>
Whenever the depth <I>d</I> of the maximum-depth tree in the forest is 2<I><SUP>o</I>(lg <I>n</I>)</SUP>, the CREW algorithm <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS</FONT> asymptotically outperforms any EREW algorithm. Specifically, for any <I>n</I>-node forest whose maximum-depth tree is a balanced binary tree with <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) nodes, <I>d = O</I>(lg <I>n</I>), in which case <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS </FONT>runs in <I>O</I>(lg lg <I>n</I>) time. Any EREW algorithm for this problem must run in <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time, which is asymptotically slower. Thus, concurrent reads help for this problem. Exercise 30.2-1 gives a simpler scenario in which concurrent reads help.<P>
<img src="703_a.gif"><P>
<h4><a name="0955_19de">Figure 30.5 Finding the roots in a forest of binary trees on a CREW PRAM. Node numbers are next to the nodes, and stored root fields appear within nodes. The links represent parent pointers. (a)-(d) The state of the trees in the forest each time line 4 of <FONT FACE="Courier New" SIZE=2>FIND-ROOTS</FONT> is executed. Note that path lengths are halved in each iteration.<a name="0955_19de"></sub></sup></h4><P>
<P>







<h2>A problem in which concurrent writes help</h2><P>
<a name="0956_19de"><a name="0956_19df">To demonstrate that concurrent writes offer a performance advantage over exclusive writes, we examine the problem of finding the the maximum element in an array of real numbers. We shall see that any EREW algorithm for this problem takes <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time and that no CREW algorithm does any better. The problem can be solved in <I>O</I>(1) time using a common-CRCW algorithm, in which when several processors write to the same location, they all write the same value.<P>
The CRCW algorithm that finds the maximum of <I>n</I> array elements assumes that the input array is <I>A</I>[0 . . <I>n</I>-1]. The algorithm uses <I>n</I><SUP>2</SUP> processors, with each processor comparing <I>A</I>[<I>i</I>] and <I>A</I>[<I>j</I>] for some <I>i</I> and <I>j</I> in the range 0 <IMG SRC="../IMAGES/lteq12.gif"> <I>i, j</I> <IMG SRC="../IMAGES/lteq12.gif"> <I>n</I> - 1. In effect, the algorithm performs a matrix of comparisons, and so we can view each of the <I>n</I><SUP>2</SUP> processors as having not only a one-dimensional index in the PRAM, but also a two-dimensional index (<I>i, j</I>).<P>
<pre><a name="0956_19e0">FAST-MAX(<I>A</I>)</sub></sup></pre><P>
<pre>1 <I>n</I> <IMG SRC="../IMAGES/arrlt12.gif"> <I>length</I>[<I>A</I>]</sub></sup></pre><P>
<pre>2<B> for</B> <I>i</I> <IMG SRC="../IMAGES/arrlt12.gif"> 0 <B>to</B> <I>n</I> - 1, in parallel</sub></sup></pre><P>
<pre>3<B>       do</B> <I>m</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> TRUE</sub></sup></pre><P>
<pre>4<B> for</B><I> i</I> <IMG SRC="../IMAGES/arrlt12.gif"> 0 <B>to</B> <I>n</I> -1 and <I>j</I> <IMG SRC="../IMAGES/arrlt12.gif"> 0 <B>to</B> <I>n</I> - 1, in parallel</sub></sup></pre><P>
<pre>5<B>       do if</B> <I>A</I>[<I>i</I>] &lt; <I>A</I>[<I>j</I>]</sub></sup></pre><P>
<pre>6<B>             then</B> <I>m</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> FALSE</sub></sup></pre><P>
<pre>7<B> for</B> <I>i</I> <IMG SRC="../IMAGES/arrlt12.gif"> 0 <B>to</B> <I>n</I> - 1, in parallel</sub></sup></pre><P>
<pre>8<B>       do if</B> <I>m</I>[<I>i</I>] = TRUE</sub></sup></pre><P>
<pre>9<B>             then</B> <I>max</I> <IMG SRC="../IMAGES/arrlt12.gif"> <I>A</I>[<I>i</I>]</sub></sup></pre><P>
<pre>10<B> return</B><I> max</I></sub></sup></pre><P>
Line 1 simply determines the length of the array <I>A</I>; it only needs to be executed on one processor, say processor 0. We use an array <I>m</I>[0 . . <I>n</I> -1], where processor <I>i</I> is responsible for <I>m</I>[<I>i</I>]. We want <I>m</I>[<I>i</I>] = <FONT FACE="Courier New" SIZE=2>TRUE</FONT> if and only if <I>A</I>[<I>i</I>] is the maximum value in array <I>A</I>. We start (lines 2-3) by believing that each array element is possibly the maximum, and we rely on comparisons in line 5 to determine which array elements are not the maximum.<P>
Figure 30.6 illustrates the remainder of the algorithm. In the loop of lines 4-6, we check each ordered pair of elements of array <I>A</I>. For each pair <I>A</I>[<I>i</I>] and <I>A</I>[<I>j</I>], line 5 checks whether <I>A</I>[<I>i</I>] &lt; <I>A</I>[<I>j</I>]. If this comparison is <FONT FACE="Courier New" SIZE=2>TRUE</FONT>, we know that <I>A</I>[<I>i</I>] cannot be the maximum, and line 6 sets <I>m</I>[<I>i</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <FONT FACE="Courier New" SIZE=2>FALSE</FONT> to record this fact. Several (<I>i, j</I>) pairs may be writing to <I>m</I>[<I>i</I>] simultaneously, but th  ey all write the same value: <FONT FACE="Courier New" SIZE=2>FALSE</FONT>.<P>
<img src="705_a.gif"><P>
<h4><a name="0956_19e4">Figure 30.6 Finding the maximum of n values in O(1) time by the CRCW algorithm <FONT FACE="Courier New" SIZE=2>FAST-MAX<FONT FACE="Times New Roman" SIZE=2> </FONT></FONT>for each ordered pair of the elements in the input array A = <IMG SRC="../IMAGES/lftwdchv.gif">5, 6, 9, 2, 9<IMG SRC="../IMAGES/wdrtchv.gif">, the result of the comparison A[i] &lt; A[j] is shown in the matrix, abbreviated T for <FONT FACE="Courier New" SIZE=2>TRUE</FONT> and F for <FONT FACE="Courier New" SIZE=2>FALSE</FONT>. For any row that contains a <FONT FACE="Courier New" SIZE=2>TRUE</FONT> value, the corresponding element of m, shown at the right, is set to <FONT FACE="Courier New" SIZE=2>FALSE</FONT>. Elements of m that contain <FONT FACE="Courier New" SIZE=2>TRUE</FONT> correspond to the maximum-valued elements of A. In this case, the value 9 is written into the variable max.<a name="0956_19e4"></sub></sup></h4><P>
After line 6 is executed, therefore, <I>m</I>[<I>i</I>] = <FONT FACE="Courier New" SIZE=2>TRUE</FONT> for exactly the indices <I>i </I>such that <I>A</I>[<I>i</I>] achieves the maximum. Lines 7-9 then put the maximum value into the variable <I>max</I>, which is returned in line 10. Several processors may write into the variable <I>max</I>, but if they do, they all write the same value, as is consistent with the common-CRCW PRAM model.<P>
Since all three &quot;loops&quot; in the algorithm are executed in parallel, <FONT FACE="Courier New" SIZE=2>FAST</FONT>-<FONT FACE="Courier New" SIZE=2>MAX</FONT> runs in <I>O</I>(1) time. Of course, it is not work-efficient, since it requires <I>n</I><SUP>2</SUP> processors, and the problem of finding the maximum number in an array can be solved by a <IMG SRC="../IMAGES/bound.gif">(<I>n</I>)-time serial algorithm. We can come closer to a work-efficient algorithm, however, as Exercise 30.2-6 asks you to show.<P>
<a name="0956_19e1"><a name="0956_19e2"><a name="0956_19e3">In a sense, the key to <FONT FACE="Courier New" SIZE=2>FAST</FONT>-<FONT FACE="Courier New" SIZE=2>MAX</FONT> is that a CRCW PRAM is capable of performing a boolean AND of <I>n</I> variables in <I>O</I>(1) time with <I>n</I> processors. (Since this capability holds in the common-CRCW model, it holds in the more powerful CRCW PRAM models as well.) The code actually performs several AND's at once, computing for <I>i</I> = 0, 1, . . . , <I>n</I> - 1,<P>
<img src="705_b.gif"><P>
which can be derived from DeMorgan's laws (5.2). This powerful AND capability can be used in other ways. For example, the capability of a CRCW PRAM to perform an AND in <I>O</I>(1) time obviates the need for a separate control network to test whether all processors are finished iterating a loop, such as we have assumed for EREW algorithms. The decision to finish the loop is simply the AND of all processors<FONT FACE="CG Times (W1)" SIZE=2>'</FONT> desires to finish the loop.<P>
The EREW model does not have this powerful AND facility. Any EREW algorithm that computes the maximum of <I>n</I> elements takes <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time. The proof is conceptually similar to the lower-bound argument for finding the root of a binary tree. In that proof, we looked at how many nodes can &quot;know&quot; the identity of the root and showed that it at most doubles for each step. For the problem of computing the maximum of <I>n</I> elements, we consider how many elements &quot;think&quot; that they might possibly be the maximum. Intuitively, with each step of an EREW PRAM, this number can at most halve, which leads to the <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) lower bound.<P>
Remarkably, the <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) lower bound for computing the maximum holds even if we permit concurrent reading; that is, it holds for CREW algorithms. Cook, Dwork, and Reischuk [50] show, in fact, that any CREW algorithm for finding the maximum of <I>n</I> elements must run in <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time, even with an unlimited number of processors and unlimited memory. Their lower bound also holds for the problem of computing the AND of <I>n</I> boolean values.<P>
<P>







<h2>Simulating a CRCW algorithm with an EREW algorithm</h2><P>
<a name="0957_19e4"><a name="0957_19e5">We now know that CRCW algorithms can solve some problems more quickly than can EREW algorithms. Moreover, any EREW algorithm can be executed on a CRCW PRAM. Thus, the CRCW model is strictly more powerful than the EREW model. But how much more powerful is it? In Section 30.3, we shall show that a <I>p</I>-processor EREW PRAM can sort <I>p </I>numbers in <I>O</I>(lg <I>p</I>) time. We now use this result to provide a theoretical upper bound on the power of a CRCW PRAM over an EREW PRAM.<P>
<a name="0957_19e6">Theorem 30.1<a name="0957_19e6"><P>
A <I>p</I>-processor CRCW algorithm can be no more than <I>O</I>(lg <I>p</I>) times faster than the best <I>p</I>-processor EREW algorithm for the same problem.<P>
<I><B>Proof</I></B>     The proof is a simulation argument. We simulate each step of the CRCW algorithm with an <I>O</I>(lg <I>p</I>)-time EREW computation. Because the processing power of both machines is the same, we need only focus on memory accessing. We only present the proof for simulating concurrent writes here. Implementation of concurrent reading is left as Exercise 30.2-8.<P>
The <I>p</I> processors in the EREW PRAM simulate a concurrent write of the CRCW algorithm using an auxiliary array <I>A</I> of length <I>p</I>. Figure 30.7 illustrates the idea. When CRCW processor P<I><SUB>i</I></SUB>, for <I>i</I> = 0, 1, . . . , <I>p</I> - 1, desires to write a datum <I>x<SUB>i</I></SUB> to a location <I>l<SUB>i</I></SUB>,<SUB> </SUB>each corresponding EREW processor <I>P<SUB>i</I></SUB> instead writes the ordered pair (<I>l<SUB>i</I></SUB>, <I>x<SUB>i</I></SUB>) to location <I>A</I>[<I><SUB>i</I></SUB>]. These writes are exclusive, since each processor writes to a distinct memory location. Then, the array <I>A</I> is sorted by the first coordinate of the ordered pairs in <I>O</I>(lg <I>p</I>) time, which causes all data written to the same location to be brought together in the output.<P>
<img src="707_a.gif"><P>
<h4><a name="0957_19e7">Figure 30.7 Simulating a concurrent write on an EREW PRAM. (a) A step of a common-CRCW algorithm in which 6 processors write concurrently to global memory. (b) Simulating the step on an EREW PRAM. First, ordered pairs containing location and data are written to an array A. The array is then sorted. By comparing adjacent elements in the array, we ensure that only the first of each group of identical writes into global memory is implemented. In this case, processors P<SUB>0</SUB>, P<SUB>2</SUB>, and P<SUB>5</SUB> perform the write.<a name="0957_19e7"></sub></sup></h4><P>
Each EREW processor <I>P<SUB>i</I></SUB>, for <I>i</I> = 1, 2, . . . , <I>p</I> - 1, now inspects <I>A</I>[<I>i</I>] = (<I>l<SUB>j</I></SUB>, <I>x<SUB>j</I></SUB>) and <I>A</I>[<I>i </I>- 1] = (<I>l<SUB>k</I></SUB>, <I>x<SUB>k</I></SUB>), where <I>j</I> and <I>k</I> are values in the range 0 <IMG SRC="../IMAGES/lteq12.gif"> <I>j</I>, <I>k</I> <IMG SRC="../IMAGES/lteq12.gif"> <I>p </I>- 1. If <I>l<SUB>j </I></SUB><IMG SRC="../IMAGES/noteq.gif"> <I>l<SUB>k</SUB> </I>or <I>i</I> = 0, then processor <I>P<SUB>i</I></SUB>, for <I>i</I> = 0, 1, . . . , <I>p</I> - 1, writes the datum <I>x<SUB>j</I></SUB> to location <I>l<SUB>j</I></SUB> in global memory. Otherwise, the processor does nothing. Since the array <I>A</I> is sorted by first coordinate, only one of the processors writing to any given location actually succeeds, and thus the write is exclusive. This process thus implements each step of concurrent writing in the common-CRCW model in <I>O</I>(lg <I>p</I>) time.      <P>
Other models for concurrent writing can be simulated as well. (See Exercise 30.2-9.)<P>
The issue arises, therefore, of which model is preferable--CRCW or EREW--and if CRCW, which CRCW model. Advocates of the CRCW models point out that they are easier to program than the EREW model and that their algorithms run faster. Critics contend that hardware to implement concurrent memory operations is slower than hardware to implement exc lusive memory operations, and thus the faster running time of CRCW algorithms is fictitious. In reality, they say, one cannot find the maximum of <I>n</I> values in <I>O</I>(1) time.<P>
Others say that the PRAM--either EREW or CRCW--is the wrong model entirely. Processors must be interconnected by a communication network, and the communication network should be part of the model. Processors should only be able to communicate with their neighbors in the network.<P>
It is quite clear that the issue of the &quot;right&quot; parallel model is not going to be easily settled in favor of any one model. The important thing to realize, however, is that these models are just that: models. For a given real-world situation, the various models apply to differing extents. The degree to which the model matches the engineering situation is the degree to which algorithmic analyses in the model will predict real-world phenomena. It is important to study the various parallel models and algorithms, therefore, so that as the field of parallel computing grows, an enlightened consensus on which paradigms of parallel computing are best suited for implementation can emerge.<P>
<P>







<h2><a name="0958_19f7">Exercises<a name="0958_19f7"></h2><P>
<a name="0958_19f8">30.2-1<a name="0958_19f8"><P>
<a name="0958_19e6"><a name="0958_19e7"><a name="0958_19e8">Suppose we know that a forest of binary trees consists of only a single tree with <I>n</I> nodes. Show that with this assumption, a CREW implementation of <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS</FONT> can be made to run in <I>O</I>(1) time, independent of the depth of the tree. Argue that any EREW algorithm takes <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time.<P>
<a name="0958_19f9">30.2-2<a name="0958_19f9"><P>
<a name="0958_19e9"><a name="0958_19ea"><a name="0958_19eb"><a name="0958_19ec">Give an EREW algorithm for <FONT FACE="Courier New" SIZE=2>FIND</FONT>-<FONT FACE="Courier New" SIZE=2>ROOTS</FONT> that runs in <I>O</I>(lg <I>n</I>) time on a forest of <I>n</I> nodes.<P>
<a name="0958_19fa">30.2-3<a name="0958_19fa"><P>
<a name="0958_19ed"><a name="0958_19ee">Give an <I>n</I>-processor CRCW algorithm that can compute the OR of <I>n</I> boolean values in <I>O</I>(1) time.<P>
<a name="0958_19fb">30.2-4<a name="0958_19fb"><P>
Describe an efficient CRCW algorithm to multiply two <I>n</I> <IMG SRC="../IMAGES/mult.gif"> <I>n</I> boolean matrices using <I>n</I><SUP>3</SUP> processors.<P>
<a name="0958_19fc">30.2-5<a name="0958_19fc"><P>
<a name="0958_19ef"><a name="0958_19f0"><a name="0958_19f1"><a name="0958_19f2">Describe an <I>O</I>(lg <I>n</I>)-time EREW algorithm to multiply two <I>n</I> <IMG SRC="../IMAGES/mult.gif"> <I>n</I> matrices of real numbers using <I>n</I><SUP>3</SUP> processors. Is there a faster common-CRCW algorithm? Is there a faster algorithm in one of the stronger CRCW models?<P>
<a name="0958_19fd">30.2-6<a name="0958_19fd"><P>
<a name="0958_19f3"><a name="0958_19f4">Prove that for any constant <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/memof12.gif"></FONT> &gt; 0, there is an <I>O</I>(1)-time CRCW algorithm using <I>O</I>(<I>n</I><SUP>1+</SUP><IMG SRC="../IMAGES/memof12.gif">) processors to find the maximum element of an <I>n</I>-element array.<P>
<a name="0958_19fe">30.2-7<a name="0958_19fe"><P>
<a name="0958_19f5"><a name="0958_19f6">Show how to merge two sorted arrays, each with <I>n</I> numbers, in <I>O</I>(1) time using a priority-CRCW algorithm. Describe how to use this algorithm to sort in <I>O</I>(lg <I>n</I>) time. Is your sorting algorithm work-efficient?<P>
<a name="0958_19ff">30.2-8<a name="0958_19ff"><P>
Complete the proof of Theorem 30.1 by describing how a concurrent read on a <I>p</I>-processor CRCW PRAM is implemented in <I>O</I>(lg <I>p</I>) time on a <I>p</I>-processor EREW PRAM.<P>
<a name="0958_1a00">30.2-9<a name="0958_1a00"><P>
Show how a <I>p</I>-processor EREW PRAM can implement a <I>p</I>-processor combining-CRCW PRAM with only <I>O</I>(lg <I>p</I>) performance loss. (<I>Hint:</I>Use a parallel prefix computation.)<P>
<P>


<P>







<h1><a name="0959_1a0a">30.3 Brent's theorem and work efficiency<a name="0959_1a0a"></h1><P>
Brent's theorem shows how we can efficiently simulate a combinational circuit by a PRAM. Using this theorem, we can adapt many of the results for sorting networks from Chapter 28 and many of the results for arithmetic circuits from Chapter 29 to the PRAM model. Readers unfamiliar with combinational circuits may wish to review Section 29.1.<P>
<a name="0959_19f7"><a name="0959_19f8"><a name="0959_19f9"><a name="0959_19fa"><a name="0959_19fb"><a name="0959_19fc"><a name="0959_19fd"><a name="0959_19fe"><a name="0959_19ff">A <I><B>combinational circuit</I></B> is an acyclic network of <I><B>combinational elements</I></B>. Each combinational element has one or more inputs, and in this section, we shall assume that each element has exactly one output. (Combinational elements with <I>k</I> &gt; 1 outputs can be considered to be <I>k</I> separate elements.) The number of inputs is the <I><B>fan-in</I></B> of the element, and the number of places to which its output feeds is its <I><B>fan-out.</I></B> We generally assume in this section that every combinational element in the circuit has bounded (<I>O</I>(1)) fan-in. It may, however, have unbounded fan-out.<P>
The <I><B>size</I></B> of a combinational circuit is the number of combinational elements that it contains. The number of combinational elements on a longest path from an input of the circuit to an output of a combinational element is the element's <I><B>depth.</I></B> The <I><B>depth</I></B> of the entire circuit is the maximum depth of any of its elements.<P>
<a name="0959_1a0b">Theorem 30.2<a name="0959_1a0b"><P>
<a name="0959_1a00">Any depth-<I>d</I>, size-<I>n</I> combinational circuit with bounded fan-in can be stimulated by a <I>p</I>-processor CREW algorithm in <I>O</I>(<I>n/p</I> + <I>d</I>) time.<P>
<I><B>Proof</I></B>     We store the inputs to the combinational circuit in the PRAM's global memory, and we reserve a location for each combinational element in the circuit to store its output value when it is computed. A given  combinational element can then be simulated by a single PRAM processor in <I>O</I>(1) time as follows. The processor simply reads the input values for the element from the values in memory corresponding to circuit inputs or  element outputs that feed it, thereby simulating the wires in the circuit. It then computes the function of the combinational element and writes the result in the appropriate position in memory. Since the fan-in of each circuit element is bounded, each function can be computed in <I>O</I>(1) time.<P>
Our job, therefore, is to find a schedule of the <I>p</I> processors of the PRAM such that all combinational elements are simulated in <I>O</I>(<I>n/p</I>+<I>d</I>) time. The main constraint is that an element cannot be simulated until the outputs from any elements that feed it have been computed. Concurrent reads are employed whenever several combinational elements being simulated in parallel require the same value.<P>
Since all elements at depth 1 depend only on circuit inputs, they are the only ones that can be simulated initially. Once they have been simulated, all elements at depth 2 can be simulated, and so forth, until we finish with all elements at depth <I>d</I>. The key idea is that if all elements from depths 1 to <I>i</I> have been simulated, we can simulate any subset of elements at depth <I>i</I> + 1 in parallel, since their computations are independent of one another.<P>
Our scheduling strategy, therefore, is quite naive. We simulate all the elements at depth <I>i</I> before proceeding to simulate those at depth <I>i</I> + 1. Within a given depth <I>i</I>, we simulate the elements <I>p</I> at a time. Figure 30.8 illustrates such a strategy for <I>p</I> = 2.<P>
Let us analyze this simulation strategy. For <I>i</I> = 1, 2, . . . , <I>d</I>, let <I>n<SUB>i</I></SUB> be the number of elements at depth <I>i</I> in the circuit. Thus,<P>
<img src="711_a.gif"><P>
<h4><a name="0959_1a0c">Figure 30.8 Brent's theorem. The combinational circuit of size 15 and depth 5 is simulated by a 2-processor CREW PRAM in 9 <IMG SRC="../IMAGES/lteq12.gif"> 15/2 + 5 steps. The simulation proceeds from top to bottom through the circuit. The shaded groups of circuit elements indicate which elements are simulated at the same time, and each group is labeled with a number corresponding to the time step when its elements are simulated.<a name="0959_1a0c"></sub></sup></h4><P>
<img src="711_b.gif"><P>
<a name="0959_1a01"><a name="0959_1a02">Consider the <I>n<SUB>i</I></SUB> combinational elements at depth <I>i</I>. By grouping them into <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>n<I><SUB>i</I></SUB>/<I>p</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"></FONT> groups, where the first <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrdl12.gif"><I>n<SUB>i</I></FONT></SUB>/<I>p</I><FONT FACE="Times New Roman" SIZE=2><IMG SRC="../IMAGES/hfbrdr12.gif"></FONT> groups have <I>p</I> elements each and the leftover elements, if any, are in the last group, the PRAM can simulate the computations performed by these combinational elements in <I>O</I>(<FONT FACE="Times New Roman" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"><I>n<SUB>i</I></FONT></SUB>/<I>p<FONT FACE="Times New Roman" SIZE=2></I><IMG SRC="../IMAGES/hfbrur14.gif"><I></I></FONT>)  time. The total simulation time is therefore on the order of<P>
<img src="711_c.gif"><P>
Brent's theorem can be extended to EREW simulations when a combinational circuit has <I>O</I>(1) fan-out for each combinational element.<P>
<a name="0959_1a0d">Corollary 30.3<a name="0959_1a0d"><P>
<a name="0959_1a03"><a name="0959_1a04"><a name="0959_1a05">Any depth-<I>d</I>, size-<I>n</I> combinational circuit with bounded fan-in and fan-out can be simulated on a <I>p</I>-processor EREW PRAM in <I>O</I>(<I>n</I>/<I>p</I> + <I>d</I>) time.<P>
<I><B>Proof</I></B>     We perform a simulation similar to that in the proof of Brent's theorem. The only difference is in the simulation of wires, which is where Theorem 30.2 requires concurrent reading. For the EREW simulation, after the output of a combinational element is computed, it is not directly read by processors requiring its value. Instead, the output value is copied by the processor simulating the element to the <I>O</I>(1) inputs that require it. The processors that need the value can then read it without interfering with each other.      <P>
This EREW simulation strategy does not work for elements with unbounded fan-out, since the copying can take more than constant time at each step. Thus, for circuits having elements with unbounded fan-out, we need the power of concurrent reads. (The case of unbounded fan-in can sometimes be handled by a CRCW simulation if the combinational elements are simple enough. See Exercise 30.3-1.)<P>
<a name="0959_1a06"><a name="0959_1a07">Corollary 30.3 provides us with a fast EREW sorting algorithm. As explained in the chapter notes of Chapter 28, the AKS sorting network can sort <I>n</I> numbers in <I>O</I>(lg <I>n</I>) depth using <I>O</I>(<I>n </I>lg <I>n</I>) comparators. Since comparators have bounded fan-in, there is an EREW algorithm to sort <I>n</I> numbers in <I>O</I>(lg <I>n</I>) time using <I>n</I> processors. (We used this result in Theorem 30.1 to show that an EREW PRAM can simulate a CRCW PRAM with at most logarithmic slowdown.) Unfortunately, the constants hidden by the <I>O</I>-notation are so large that this sorting algorithm has solely theoretical interest. More practical EREW sorting algorithms have been discovered, however, notably the parallel merge-sorting algorithm due to Cole [46].<P>
<a name="0959_1a08"><a name="0959_1a09">Now suppose that we have a PRAM algorithm that uses at most <I>p </I>processors, but we have a PRAM with only <I>p</I><I>'</I> &lt; <I>p</I> processors. We would like to be able to run the <I>p</I>-processor algorithm on the smaller <I>p</I>'-processor PRAM in a work-efficient fashion. By using the idea in the proof of Brent's theorem, we can give a condition for when this is possible.<P>
<a name="0959_1a0e">Theorem 30.4<a name="0959_1a0e"><P>
If a <I>p</I>-processor PRAM algorithm <I>A</I> runs in time <I>t</I>, then for any <I>p</I><I>'</I> &lt; <I>p</I>, there is an <I>p</I>'-processor PRAM algorithm <I>A</I>' for the same problem that runs in time <I>O</I>(<I>pt</I>/<I>p</I>').<P>
<I><B>Proof</I></B>     Let the time steps of algorithm <I>A</I> be numbered 1, 2, . . . , <I>t</I>. Algorithm <I>A</I>' simulates the execution of each time step <I>i = </I>1, 2, <I>. . . </I>,<I> t</I> in time <I>O</I>(<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"><I>p</I></FONT>/<I>p</I>'<I><FONT FACE="Courier New" SIZE=2></I><IMG SRC="../IMAGES/hfbrur14.gif"><I></I></FONT> ). There are <I>t</I> steps, and so the entire simulation takes time <I>O</I>(<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"><I>p</I></FONT>/<I>p</I>'<I><FONT FACE="Courier New" SIZE=2></I><IMG SRC="../IMAGES/hfbrur14.gif"></FONT><I> </I>t<I>) = </I>O<I>(</I>pt<I>/</I>p<I></I>'), since <I>p</I>' &lt; <I>p</I>.      <P>
The work performed by algorithm <I>A</I> is <I>pt</I>, and the work performed by algorithm <I>A</I>' is (<I>pt</I>/<I>p</I>'<I>)</I>p<I>'</I> = <I>pt;</I> the simulation is therefore work-efficient. Consequently, if algorithm <I>A</I> is itself work-efficient, so is algorithm <I>A</I>'<I>.</I><P>
When developing work-efficient algorithms for a problem, therefore, one needn't necessarily create a different algorithm for each different number of processors. For example, suppose that we can prove a tight lower bound of <I>t</I> on the running time of any parallel algorithm, no matter how many processors, for solving a given problem, and suppose further that the be st serial algorithm for the problem does work <I>w</I>. Then, we need only develop a work-efficient algorithm for the problem that uses <I>p</I> = <IMG SRC="../IMAGES/bound.gif">(<I>w</I>/<I>t</I>) processors in order to obtain work-efficient algorithms for all numbers of processors for which a work-efficient algorithm is possible. For <I>p</I><I>'</I> = <I>o</I>(<I>p</I>), Theorem 30.4 guarantees that there is a work-efficient algorithm. For <I>p</I>' = <I>w</I> (<I>p</I>), no work-efficient algorithms exist, since if <I>t</I> is a lower bound on the time for any parallel algorithm, <I>p</I>'t<I> = </I>w<I>(</I>pt<I>) = </I>w<I>(</I>w<I>).</I><P>





<h2><a name="095a_1a1c">Exercises<a name="095a_1a1c"></h2><P>
<a name="095a_1a1d">30.3-1<a name="095a_1a1d"><P>
<a name="095a_1a0a"><a name="095a_1a0b"><a name="095a_1a0c"><a name="095a_1a0d"><a name="095a_1a0e"><a name="095a_1a0f"><a name="095a_1a10">Prove a result analogous to Brent's theorem for a CRCW simulation of boolean combinational circuits having AND and OR gates with unbounded fan-in. (<I>Hint:</I> Let the &quot;size&quot; be the total number of inputs to gates in the circuit.)<P>
<a name="095a_1a1e">30.3-2<a name="095a_1a1e"><P>
<a name="095a_1a11"><a name="095a_1a12"><a name="095a_1a13"><a name="095a_1a14"><a name="095a_1a15">Show that a parallel prefix computation on <I>n</I> values stored in an array of memory can be implemented in <I>O</I>(lg <I>n</I>) time on an EREW PRAM using <I>O</I>(<I>n</I>/lg <I>n</I>) processors. Why does this result not extend immediately to a list of <I>n</I> values?<P>
<a name="095a_1a1f">30.3-3<a name="095a_1a1f"><P>
<a name="095a_1a16"><a name="095a_1a17"><a name="095a_1a18">Show how to multiply an <I>n</I> <IMG SRC="../IMAGES/mult.gif"> <I>n</I> matrix <I>A</I> by an <I>n</I>-vector <I>b</I> in <I>O</I>(lg <I>n</I>) time with a work-efficient EREW algorithm. (<I>Hint:</I> Construct a combinational circuit for the problem.)<P>
<a name="095a_1a20">30.3-4<a name="095a_1a20"><P>
<a name="095a_1a19"><a name="095a_1a1a">Give a CRCW algorithm using <I>n</I><SUP>2</SUP> processors to multiply two <I>n</I> <IMG SRC="../IMAGES/mult.gif"> <I>n</I> matrices. The algorithm should be work-efficient with respect to the normal <IMG SRC="../IMAGES/bound.gif">(<I>n</I><SUP>3</SUP>)-time serial algorithm for multiplying matrices. Can you make the algorithm EREW?<P>
<a name="095a_1a21">30.3-5<a name="095a_1a21"><P>
<a name="095a_1a1b">Some parallel models allow processors to become inactive, so that the number of processors executing at any step varies. Define the work in this model as the total number of steps executed during an algorithm by active processors. Show that any CRCW algorithm that performs <I>w </I>work and runs in <I>t</I> time can be run on a <I>p</I>-processor EREW PRAM in <I>O</I>((<I>w/p</I> + <I>t</I>) lg <I>p</I>) time. (<I>Hint:</I> The hard part is scheduling the active processors <I>while</I> the computation is proceeding.)<P>
<P>


<P>







<h1><a name="095b_1a21">* 30.4 Work-efficient parallel prefix computation<a name="095b_1a21"></h1><P>
<a name="095b_1a1c"><a name="095b_1a1d"><a name="095b_1a1e"><a name="095b_1a1f">In Section 30.1.2, we examined an <I>O</I>(lg <I>n</I>)-time EREW algorithm <FONT FACE="Courier New" SIZE=2>LIST</FONT>- <FONT FACE="Courier New" SIZE=2>RANK</FONT> that can perform a prefix computation on an <I>n-</I>object linked list. The algorithm uses<I> n</I> processors and performs <IMG SRC="../IMAGES/bound.gif">(<I>n </I>lg <I>n</I>) work. Since we can easily perform a prefix computation in <IMG SRC="../IMAGES/bound.gif">(<I>n</I>) time on a serial machine, <FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>RANK</FONT> is not work-efficient.<P>
<a name="095b_1a20">This section presents a randomized EREW parallel prefix algorithm that is work-efficient. The algorithm uses <IMG SRC="../IMAGES/bound.gif">(<I>n</I>/lg <I>n</I>) processors, and it runs in <I>O</I>(lg <I>n</I>) time with high probability. Thus, it is work-efficient with high probability. Moreover, by Theorem 30.4, this algorithm immediately yields work-efficient algorithms for any number <I>p</I> = <I>O</I>(<I>n</I>/lg <I>n</I>) of processors.<P>





<h2>Recursive parallel prefix computation</h2><P>
<a name="095c_1a21">The randomized parallel prefix algorithm <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> operates on a linked list of <I>n</I> objects using <I>p</I> = <IMG SRC="../IMAGES/bound.gif">(<I>n</I>/ lg <I>n</I>) processors. During the algorithm, each processor is responsible for <I>n/p</I> = <IMG SRC="../IMAGES/bound.gif">(lg <I>n</I>) of the objects in the original list. The objects are assigned to processors arbitrarily (not necessarily contiguously) before the recursion begins, and "ownership" of objects never changes. For convenience, we assume that the list is doubly linked, since doubly linking a single list takes <I>O</I>(1) time.<P>
The idea of <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> is to eliminate some of the objects in the list, perform a recursive prefix computation on the resulting list, and then expand it by splicing in the eliminated objects to yield a prefix computation on the original list. Figure 30.9 illustrates the recursive process, and Figure 30.10 shows how the recursion unfolds. We shall show a little later that each stage of the recursion obeys two properties:<P>
1.     At most one object of those belonging to a given processor is selected for elimination.<P>
2.     No two adjacent objects are selected for elimination.<P>
Before we show how to select objects that satisfy these properties, let us examine in more detail how the prefix computation is performed. Suppose that at the first step of the recursion, the <I>k</I>th object in the list is selected for elimination. This object contains the value [<I>k, k</I>], which is fetched by the (<I>k</I> + 1)st object in the list. (Boundary situations, such as the one here when <I>k</I> is at the end of the list, can be handled straightforwardly and are not described.) The (<I>k</I> + 1)st object, which holds the value [<I>k</I> + 1, <I>k</I> + 1], then computes and stores [<I>k, k </I>+ 1] = [<I>k, k</I>] <IMG SRC="../IMAGES/circx.gif"> [<I>k </I>+ 1, <I>k </I>+ 1]. The <I>k</I>th object is then eliminated from the list by splicing it out.<P>
<img src="715_a.gif"><P>
<h4><a name="095c_1a22">Figure 30.9 The work-efficient, randomized, recursive, parallel algorithm <FONT FACE="Courier New" SIZE=2>RANDOMIZED-LIST-PREFIX</FONT> for performing prefix computations on a linked list of n = 9 objects. (a)-(b) A set of nonadjacent objects (blackened) are selected for elimination. The value in each black object is used to update the value in the next object in the list, and then the black object is spliced out. The algorithm is called recursively to compute a parallel prefix on the contracted list. (c)-(d) The resulting values are the correct final values for objects in the contracted list. The eliminated objects are then spliced back in, and each uses the value of the previous object to compute its final value.<a name="095c_1a22"></sub></sup></h4><P>
The procedure <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> then calls itself recursively to perform a prefix computation on the &quot;contracted&quot; list. (The recursion bottoms out when the entire list is empty.) The key observation is that after returning from the recursive call, each object in the contracted list has the correct final value it needs for the parallel prefix computation on the original list. It remains only to splice back in the previously eliminated objects, such as the <I>k</I>th object, and update their values.<P>
After the <I>k</I>th object is spliced in, its final prefix value can be computed using the value in the (<I>k</I> - 1)st object. After the recursion, the (<I>k</I> - 1)st object contains [1, <I>k</I> - 1], and thus the <I>k</I>th object--which still has the value [<I>k, k</I>]--needs only to fetch the value [ 1, <I>k</I> - 1] and compute [1,<I>k</I>] = [1, <I>k</I> - 1] <IMG SRC="../IMAGES/circx.gif"> [<I>k, k</I>].<P>
Because of property 1, each selected object has a distinct processor to perform the work needed to splice it out or in. Property 2 ensures that no confusion between processors arises when splicing objects out and in (see Exercise 30.4-1). The two properties together ensure that each step of the recursion can be implemented in O(1) time in an EREW fashion.<P>
<img src="716_a.gif"><P>
<h4><a name="095c_1a23">Figure 30.10 The recursive stages of <FONT FACE="Courier New" SIZE=2>RANDOMIZED-LIST-PREFIX</FONT>, shown for n = 9 original objects. In each stage, the blackened objects are eliminated. The procedure recurses until the list is empty, and then the eliminated objects are spliced back in.<a name="095c_1a23"></sub></sup></h4><P>
<P>







<h2>Selecting objects for elimination</h2><P>
How does <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> select objects for elimination? It must obey the two properties above, and in addition, we want the time to select objects to be short (and preferably constant). Moreover, we would like as many objects as possible to be selected.<P>
The following method for randomized selection satisfies these conditions. Objects are selected by having each processor execute the following steps:<P>
1.     The processor picks an object <I>i</I> that has not previously been selected from among those it owns.<P>
<a name="095d_1a22">2.     It then &quot;flips a coin,&quot; choosing the values <FONT FACE="Courier New" SIZE=2>HEAD</FONT> and <FONT FACE="Courier New" SIZE=2>TAIL</FONT> with equal probability.<P>
3.     If it chooses <FONT FACE="Courier New" SIZE=2>HEAD</FONT>, it marks object <I>i</I> as selected, unless <I>next</I>[<I>i</I>] has been picked by another processor whose coin is also <FONT FACE="Courier New" SIZE=2>HEAD</FONT>.<P>
This randomized method takes only <I>O</I>(1) time to select objects for elimination, and it does not require concurrent memory accesses.<P>
We must show that this procedure obeys the two properties above. That property 1 holds can be seen easily, since only one object is chosen by a processor for possible selection. To see that property 2 holds, suppose to the contrary that two consecutive objects <I>i</I> and <I>next</I>[<I>i</I>] are selected. This occurs only if both were picked by their processors, and both processors flipped <FONT FACE="Courier New" SIZE=2>HEAD</FONT>. But object <I>i</I> is not selected if the processor responsible for <I>next</I>[<I>i</I>] flipped <FONT FACE="Courier New" SIZE=2>HEAD</FONT>, which is a contradiction.<P>
<P>







<h2>Analysis</h2><P>
<a name="095e_1a23">Since each recursive step of <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> runs in <I>O</I>(1) time, to analyze the algorithm we need only determine how many steps it takes to eliminate all the objects in the original list. At each step, a processor has at least probability 1/4 of eliminating the object <I>i</I> it picks. Why? It flips <FONT FACE="Courier New" SIZE=2>HEAD</FONT> with probability 1/2, and the probability that it either does not pick <I>next</I>[<I>i</I>] or picks it and flips <FONT FACE="Courier New" SIZE=2>TAIL</FONT> is at least 1/2. Since the two coin flips are independent events, we can multiply their probabilities, yielding the probability of at least 1/4 of a processor eliminating the object it picks. Since each processor owns <IMG SRC="../IMAGES/bound.gif"> (lg <I>n</I>) objects, the expected time for a processor to eliminate all its objects is <IMG SRC="../IMAGES/bound.gif"> (lg <I>n</I>).<P>
Unfortunately, this simple analysis does not show that the expected running time of <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> is <IMG SRC="../IMAGES/bound.gif">(1g <I>n</I>). For example, if most of the processors eliminate all their objects quickly and a few processors take much, much longer, the average time for a processor to eliminate all its objects might still be <IMG SRC="../IMAGES/bound.gif">(lg <I>n</I>), but the running time of the algorithm could be large.<P>
The expected running time of the procedure <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> is indeed <IMG SRC="../IMAGES/bound.gif">(lg <I>n</I>), even though the simple analysis does not show it. We shall use a high-probability argument to prove that with probability at least 1 - 1/<I>n</I>, all objects are eliminated within <I>c</I> lg <I>n</I> stages of the recursion, for some constant <I>c</I>. Exercises 30.4-4 and 30.4-5 ask you to generalize this argument to prove the <IMG SRC="../IMAGES/bound.gif">(lg <I>n</I>) bound on the expected running time.<P>
<a name="095e_1a24">Our high-probability argument is based on observing that the experiment of a given processor eliminating the objects it picks can be viewed as a sequence of Bernoulli trials (see Chapter 6). The experiment is a success if the object is selected for elimination, and it is a failure otherwise. Since we are interested in showing that the probability is small that very few successes are obtained, we can assume that successes occur with probability exactly 1/4, rather than with probability at least 1/4. (See Exercises 6.4-8 and 6.4-9 for a formal justification of similar assumptions.)<P>
To further simplify the analysis, we assume that there are exactly <I>n</I>/ 1g <I>n</I> processors, each with lg <I>n</I> list objects. We are conducting <I>c </I>lg <I>n</I> trials, for some constant <I>c</I> that we shall determine, and we are interested in the event that fewer than lg <I>n</I> successes occur. Let <I>X</I> be the random variable denoting the total number of successes. By Corollary 6.3, the probability that a processor eliminates fewer than lg <I>n</I> objects in the <I>c</I> lg <I>n</I> trials is at most<P>
<img src="718_a.gif"><P>
as long as <I>c</I> <IMG SRC="../IMAGES/gteq.gif"> 20. (The second line follows from inequality (6.9).) Thus, the probability that all objects belonging to a given processor have not been eliminated after <I>c</I> lg <I>n</I> steps is at most 1/<I>n</I><SUP>2</SUP>.<P>
We now wish to bound the probability that all objects belonging to all processors have not been eliminated after <I>c</I> lg <I>n</I> steps. By Boole's inequality (6.22), this probability is at most the sum of the probabilities that each of processors has not eliminated its objects. Since there are <I>n</I>/ lg <I>n</I> processors, and each has probability at most 1/<I>n</I><SUP>2</SUP> of not eliminating all its objects, the probability that any processor has not finished all its objects is at most<P>
<img src="719_a.gif"><P>
We have thus proven that with probability at least 1 - 1/<I>n</I>, every object is spliced out after <I>O</I>(lg <I>n</I>) recursive calls. Since each recursive call takes <I>O</I>(1) time, <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> takes <I>O</I>(lg <I>n</I>) time with high probability.<P>
The constant <I>c</I> <IMG SRC="../IMAGES/gteq.gif"> 20 in the <I>c</I> 1g <I>n</I> running time may seem a bit large for practicality. In fact, this constant is more an artifact of the analysis than a reflection of the algorithm's performance. In practice, the algorithm tends to be fast. The constant factors in the analysis are large because the event that one processor finishes eliminating all its list objects is dependent on the event that another processor finishes all its work. Because of these dependencies, we used Boole's inequality, which does not require independence but results in a weaker constant than would generally be experienced in practice.<P>
<P>







<h2><a name="095f_1a26">Exercises<a name="095f_1a26"></h2><P>
<a name="095f_1a27">30.4-1<a name="095f_1a27"><P>
<a name="095f_1a25">Draw figures to illustrate what can go wrong in <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> if two adjacent list objects are selected for elimination.<P>
<a name="095f_1a28">30.4-2<a name="095f_1a28"><P>
Suggest a simple change to make <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> run in <I>O</I>(n) worst-case time on a list of <I>n</I> objects. Use the definition of expectation to prove that with this modification, the algorithm runs in <I>O</I>(lg <I>n</I>) expected time.<P>
<a name="095f_1a29">30.4-3<a name="095f_1a29"><P>
Show how to implement <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> so that it uses at most <I>O</I>(<I>n/p</I>) space per processor in the worst case, independent of how deep the recursion goes.<P>
<a name="095f_1a2a">30.4-4<a name="095f_1a2a"><P>
Show that for any constant <I>k </I><IMG SRC="../IMAGES/gteq.gif"> <I>1</I>, <I><FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-P<FONT FACE="Courier New" SIZE=2>REFIX </FONT>runs in</I> O<I>(lg </I>n<I>) time with probability at least 1 - 1/</I>n<I><SUP>k</SUP>. Show how the constant in the running-time bound is influenced by </I>k<I>.</I><P>
<a name="095f_1a2b">30.4-5<a name="095f_1a2b"><P>
Using the result of Exercise 30.4-4, show that the expected running time of <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT> is <I>O</I>(lg <I>n</I>).<P>
<P>


<P>







<h1><a name="0960_1a29">30.5 Deterministic symmetry breaking<a name="0960_1a29"></h1><P>
<a name="0960_1a26"><a name="0960_1a27">Consider a situation in which two processors wish to acquire mutually exclusive access to an object. How can the processors determine which should acquire access first? We wish to avoid the scenario in which both are granted access, as well as the scenario in which neither is granted access. The problem of choosing one of the processors is an example of <I><B>symmetry breaking</I></B>. We have all seen the momentary confusion and diplomatic impasses that arise when two people attempt to go through a door simultaneously. Similar symmetry-breaking problems are pervasive in the design of parallel algorithms, and efficient solutions are extremely useful.<P>
One method for breaking symmetry is to flip coins. On a computer, coin flipping can be implemented by means of a random-number generator. For the two-processor example, both processors can flip coins. If one obtains <FONT FACE="Courier New" SIZE=2>HEAD</FONT> and the other <FONT FACE="Courier New" SIZE=2>TAIL</FONT>, the one obtaining <FONT FACE="Courier New" SIZE=2>HEAD</FONT> proceeds. If both flip the same value, they try again. With this strategy, symmetry is broken in constant expected time (see Exercise 30.5-1).<P>
We saw the effectiveness of a randomized strategy in Section 30.4. In <FONT FACE="Courier New" SIZE=2>RANDOMIZED</FONT>-<FONT FACE="Courier New" SIZE=2>LIST</FONT>-<FONT FACE="Courier New" SIZE=2>PREFIX</FONT>, adjacent list objects must not be selected for elimination, but as many picked objects as possible should be selected. In the midst of a list of picked objects, however, all objects look pretty much the same. As we saw, randomization provides a simple and effective way to break the symmetry between adjacent list objects while guaranteeing that, with high probability, many objects are selected.<P>
In this section, we investigate a deterministic method for breaking symmetry. The key to the algorithm is to employ processor indices or memory addresses rather than random coin flips. For instance, in the two-processor example, we can break the symmetry by allowing the processor with smaller processor index to go first--clearly a constant-time process.<P>
<a name="0960_1a28">We shall use the same idea, but in a much more clever fashion, in an algorithm to break symmetry in an <I>n</I>-object linked list. The goal is to choose a constant fraction of the objects in the list but to avoid picking two adjacent objects. This algorithm can be performed with <I>n</I> processors in <I>O</I>(lg<SUP>*</SUP> <I>n</I>) time by a deterministic EREW algorithm. Since lg<SUP>*</SUP> <I>n</I> <IMG SRC="../IMAGES/lteq12.gif"> 5 for all <I>n</I> <IMG SRC="../IMAGES/lteq12.gif"> 2<SUP>65536</SUP>, the value lg<SUP>*</SUP> <I>n</I> can be viewed as a small constant for all practical purposes (see page 36).<P>
Our deterministic algorithm has two parts. The first part computes a &quot;6-coloring&quot; of the linked list in <I>O</I>(lg<SUP>*</SUP><I>n</I>) time. The second part converts the 6-coloring to a <FONT FACE="CG Times (W1)" SIZE=2>&quot;</FONT>maximal independent set<FONT FACE="CG Times (W1)" SIZE=2>&quot;</FONT> of the list in <I>O</I>(1) time. The maximal independent set will contain a constant fraction of the <I>n</I> objects of the list, and no two objects in the set will be adjacent.<P>





<h2>Colorings and maximal independent sets</h2><P>
<a name="0961_1a29"><a name="0961_1a2a"><a name="0961_1a2b"><a name="0961_1a2c">A <I><B>coloring</I></B> of an undirected graph <I>G</I> = (<I>V, E</I>) is a function <I>C : V </I><IMG SRC="../IMAGES/arrow12.gif"><I> </I><B>N</B> such that for all <I>u, v </I><IMG SRC="../IMAGES/memof12.gif"><I> V</I>, if <I>C</I>(<I>u</I>) = <I>C</I>(<I>v</I>), then (<I>u, v</I>)<I> </I><IMG SRC="../IMAGES/notmem.gif"><I> E</I>; that is, no adjacent vertices have the same color. In a 6-coloring of a linked list, all colors are in the range {0, 1, 2, 3, 4, 5} and no two consecutive vertices have the same color. In fact, any linked list has a 2-coloring, since we can color objects whose ranks are odd with color 0 and objects whose ranks are even with color 1. We can compute such a coloring in <I>O</I>(lg <I>n</I>) time using a parallel prefix computation, but for many applications, it suffices to compute only an <I>O</I>(1)-coloring. We shall show that a 6-coloring can be computed in <I>O</I>(lg<SUP>*</SUP> <I>n</I>) time without using randomization.<P>
<a name="0961_1a2d"><a name="0961_1a2e"><a name="0961_1a2f"><a name="0961_1a30"><a name="0961_1a31">An <I><B>independent</I></B> <I><B>set</I></B> of a graph <I>G = </I>(<I>V, E</I>) is a subset <I>V</I>'<I> <IMG SRC="../IMAGES/rgtubar.gif"></I><I> V</I> of vertices such that each edge in <I>E</I> is incident on at most one vertex in <I>V</I><I>'</I>. A <I><B>maximal independent set</I></B>, or <I><B>MIS</I></B>, is an independent set <I>V</I><I>'</I> such that for all vertices <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I> - <I>V</I>'<I></I>, the set <I>V</I><I>'</I> <IMG SRC="../IMAGES/wideu.gif"> {<I>v</I>} is not independent--every vertex not in <I>V</I><I>'</I> is adjacent to some vertex in <I>V</I><I>'</I>. Do not confuse the problem of computing a <I>maximal</I> independent set--an easy problem--with the problem of computing a <I>maximum</I> independent set--a hard problem. The problem of finding an independent set of maximum size in a general graph is NP-complete. (See Chapter 36 for a discussion of NP-completeness. Problem 36-1 concerns maximum independent sets.)<P>
For <I>n</I>-object lists, a maximum (and hence maximal) independent set can be determined in <I>O(</I>lg <I>n</I>) time by using a parallel prefix computation, as in the 2-coloring just mentioned, to identify the odd-ranked objects. This method selects <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"><I>n/2</I><IMG SRC="../IMAGES/hfbrur14.gif"><I> </I></FONT>objects. Observe, however, that any maximal independent set of a linked list contains at least<I> n</I>/3 objects, since for any 3 consecutive objects, at least one must be in the set. We shall show, however, that a maximal independent set of a list can be determined in <I>O</I>(1) time given an <I>O</I>(1)-coloring of the list.<P>
<P>







<h2>Computing a 6-coloring</h2><P>
<a name="0962_1a32">The algorithm <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> computes a 6-coloring of a list. We won't give pseudocode for the algorithm, but we shall describe it in some detail. We assume that initially each object <I>x</I> in the linked list is associated with a distinct processor <I>P</I>(<I>x</I>)<I> </I><IMG SRC="../IMAGES/memof12.gif"> <I>{0, 1, . . . , </I>n<I> - 1}.</I><P>
The idea of <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> is to compute a sequence <I>C</I><SUB>0</SUB>[<I>x</I>], <I>C</I><SUB>1</SUB>[<I>x</I>], . . . , <I>C<SUB>m</I></SUB>[<I>x</I>] of colors for each object <I>x</I> in the list. The initial coloring <I>C</I><SUB>0</SUB> is a <I>n-</I>coloring. Each iteration of the algorithm defines a new coloring <I>C<SUB>k + </I>1</SUB> based on the previous coloring <I>C<SUB>k</I></SUB>, for <I>k</I> = 0, 1, . . . , <I>m</I> - 1. The final coloring <I>C<SUB>m</I></SUB> is a 6-coloring, and we shall prove that <I>m</I> = <I>O</I>(lg* <I>n</I>).<P>
The initial coloring is the trivial <I>n</I>-coloring in which <I>C</I><SUB>0</SUB>[<I>x</I>] = <I>P</I>(<I>x</I>). Since no two list objects have the same color, no two adjacent list objects have the same color, and so the coloring is legal. Note that each of the initial colors can be described with <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>n</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"></FONT> bits, which means that it can be stored in an ordinary computer word.<P>
The subsequent colorings are obtained as follows. The <I>k</I>th iteration, for <I>k</I> = 0, 1, . . . , <I>m</I> - 1, starts with a coloring<I> C<SUB>k</I></SUB> and ends with a coloring <I>C<SUB>k </I>+ 1</SUB> using fewer bits per object, as the first part of Figure 30.11 shows. Suppose that at the start of an iteration, each object's color <I>C<SUB>k</I></SUB> takes <I>r</I> bits. We determine the new color of an object <I>x</I> by looking forward in the list at the color of <I>next</I>[<I>x</I>].<P>
To be more precise, suppose that for each object <I>x</I>, we have <I>C<SUB>k</I></SUB>[<I>x</I>] = <I>a</I> and <I>C<SUB>k</I></SUB>[<I>next</I>[<I>x</I>]]<I> = b</I>, where <I>a</I> = <IMG SRC="../IMAGES/lftwdchv.gif"><I>a<SUB>r</I></SUB>-<SUB>1</SUB>, <I>a<SUB>r<FONT FACE="CG Times (W1)" SIZE=1></I></SUB>-<SUB>2</FONT></SUB>, . . . , <I>a</I><SUB>0</SUB><IMG SRC="../IMAGES/wdrtchv.gif"> and <I>b = </I><IMG SRC="../IMAGES/lftwdchv.gif"><I>b<SUB>r</I></SUB>-<SUB>1</SUB>,<I> b<SUB>r<FONT FACE="CG Times (W1)" SIZE=1></I></SUB>-<SUB>2</FONT></SUB>, . . . ,<I> b</I><SUB>0</SUB><IMG SRC="../IMAGES/wdrtchv.gif"> are <I>r</I>-bit colors. Since <I>C<SUB>k</I></SUB>[<I>x</I>] <IMG SRC="../IMAGES/noteq.gif"><I> C<SUB>k</I></SUB>[<I>next</I>[<I>x</I>]], there is some least index <I>i</I> at which the bits of the two colors differ: <I>a<SUB>i </SUB></I><IMG SRC="../IMAGES/noteq.gif"><I> b<SUB>i</I></SUB>. Because 0 <IMG SRC="../IMAGES/lteq12.gif"> <I>i </I><IMG SRC="../IMAGES/lteq12.gif"> <I>r </I>- 1, we can write <I>i</I> with only [lg<I> r</I>] bits: <I>i = </I><IMG SRC="../IMAGES/lftwdchv.gif"><I>i </I><IMG SRC="../IMAGES/hfbrul14.gif"><I>lg</I> r<I><SUB><IMG SRC="../IMAGES/hfbrur14.gif"></I></SUB>-<SUB>1</SUB>, <I>i</I><IMG SRC="../IMAGES/hfbrul14.gif"><I>lg</I> r<I><SUB><IMG SRC="../IMAGES/hfbrur14.gif"></SUB>-<SUB>2</SUB>, . . . , </I>i<I><SUB>0</SUB><IMG SRC="../IMAGES/wdrtchv.gif"></I><I>. </I>We recolor<I> x</I> with the value of <I>i</I> concatenated with the bit <I>a<SUB>i</I></SUB>. That is, we assign<P>
<pre>C<I><SUB>k</I>+1</SUB>[<I>x</I>]  =  <IMG SRC="../IMAGES/lftwdchv.gif"><I>i, a<SUB>i</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"></sub></sup></pre><P>
<pre>=  <IMG SRC="../IMAGES/lftwdchv.gif"><I>i</I><IMG SRC="../IMAGES/hfbrul14.gif">lg <I>r</I><IMG SRC="../IMAGES/hfbrur14.gif"> - 1, <I>i</I> <IMG SRC="../IMAGES/hfbrul14.gif">lg <I>r</I><IMG SRC="../IMAGES/hfbrur14.gif">-2, . . . , <I>i</I>0, <I>ai</I><IMG SRC="../IMAGES/wdrtchv.gif">.</sub></sup></pre><P>
The tail of the list gets the new color (0, <I>a</I><SUB>0</SUB>). The number of bits in each new color is therefore at most <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg<I> r<FONT FACE="Courier New" SIZE=2></I><IMG SRC="../IMAGES/hfbrur14.gif"></FONT><I> + 1.</I><P>
We must show that if each iteration of <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> starts with a coloring, the new &quot;coloring&quot; it produces is indeed a legal coloring. To do this, we prove that <I>C<SUB>k</I></SUB>[<I>x</I>] <IMG SRC="../IMAGES/noteq.gif"> <I>C<SUB>k</I></SUB> <I>next</I>[<I>x</I>]] implies <I>C<SUB>k+</I>1</SUB>[<I>x</I>] <IMG SRC="../IMAGES/noteq.gif"> <I>C<SUB>k+</I>1</SUB>[<I>next</I>[<I>x</I>]]. Suppose that <I>C<SUB>k</I></SUB>[<I>x</I>] = <I>a</I> and <I>C<SUB>k</I></SUB>[<I>next</I>[<I>x</I>]] = <I>b,</I> and that <I>C<SUB>k+</I>1</SUB>[<I>x</I>] = <IMG SRC="../IMAGES/lftwdchv.gif"><I>i, a<SUB>i</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"> and <I>C<SUB>k+</I>1</SUB>[<I>next</I>[<I>x</I>]] = <IMG SRC="../IMAGES/lftwdchv.gif"><I>j, b<SUB>j</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif">. There are two cases to consider. If <I>i </I><IMG SRC="../IMAGES/noteq.gif"><I> j</I>, then <IMG SRC="../IMAGES/lftwdchv.gif"><I>i, a<SUB>i</SUB></I><IMG SRC="../IMAGES/wdrtchv.gif"> <I><IMG SRC="../IMAGES/noteq.gif"></I> <I><IMG SRC="../IMAGES/lftwdchv.gif">j, b<SUB>j</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif">, and so the new colors are different. If <I>i = j</I>, however, then <I>a<SUB>i</I></SUB> <IMG SRC="../IMAGES/noteq.gif"> <I>b<SUB>i</I></SUB> = <I>b<SUB>j</I></SUB> by our recoloring method, and thus the new colors are once again different. (The situation at the tail of the list can be handled similarly.)<P>
The recoloring method used by <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> takes an <I>r</I>-bit color and replaces it with a (<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>r</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"> </FONT>+ 1)-bit color, which means that the number of bits is strictly reduced as long as <I>r</I> <IMG SRC="../IMAGES/gteq.gif"> 4. When <I>r</I> = 3, two colors can differ in bit position 0, 1, or 2. Each new color, therefore, is <IMG SRC="../IMAGES/lftwdchv.gif">00<IMG SRC="../IMAGES/wdrtchv.gif">, <IMG SRC="../IMAGES/lftwdchv.gif">01<IMG SRC="../IMAGES/wdrtchv.gif">, or <IMG SRC="../IMAGES/lftwdchv.gif">10<IMG SRC="../IMAGES/wdrtchv.gif"> concatenated with either 0 or 1, thus leaving a 3-bit number once again. Only 6 of the 8 possible values for 3-bit numbers are used, however, so that <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> indeed terminates with a 6-coloring.<P>
Assuming that each processor can determine the appropriate index <I>i</I> in <I>O</I>(1) time and perform a shift-left operation in <I>O</I>(1) time--operations commonly supported on many actual machines--each iteration takes <I>O</I>(1) time. The <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT> procedure is an EREW algorithm: for each object <I>x,</I> its processor accesses only <I>x</I> and <I>next</I>[<I>x</I>].<P>
Finally, let us see why only <I>O</I>(lg<SUP>*</SUP> <I>n</I>) iterations are required to bring the initial <I>n</I>-coloring down to a 6-coloring. We have defined lg<SUP>*</SUP> <I>n</I> as the number of times the algorithm function lg needs to be applied to <I>n</I> to reduce it to at most 1 or, letting lg<SUP>(<I>i</I>) </SUP><I>n</I> denote <I>i</I> successive applications of the lg function,<P>
<img src="723_a.gif"><P>
<h4><a name="0962_1a33">Figure 30.11 The algorthms <FONT FACE="Courier New" SIZE=2>SIX-COLOR</FONT> and <FONT FACE="Courier New" SIZE=2>LIST-MIS</FONT> that break symmetry in a list. Together, the algorithms find a large set of nonadjacent objects in O(lg<SUP>*</SUP><FONT FACE="Times New Roman" SIZE=2> n)</FONT> time using n processors. The initial list of n = 20 objects is shown on the left, running vertically. Each object has an initial, distinct 5-bit color. For these parameters, the algorithm <FONT FACE="Courier New" SIZE=2>SIX-COLOR</FONT> needs only the two iterations shown to recolor each object with a color in the range {0, 1, 2, 3, 4, 5}. White objects are placed into the MIS by <FONT FACE="Courier New" SIZE=2>LIST</FONT>-MIS as the colors are processed, and black objects are killed.<a name="0962_1a33"></sub></sup></h4><P>
<pre>lg<SUP>*</SUP> <I>n</I> = min {<I>i</I> <IMG SRC="../IMAGES/gteq.gif"> 0 : lg<SUP>(<I>i</I>) </SUP><I>n </I><IMG SRC="../IMAGES/lteq12.gif"> 1} .</sub></sup></pre><P>
Let <I>r<SUB>i</SUB> </I>be the number of bits in the coloring just before the<I> i</I>th iteration. We shall prove by induction that if  <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif">l</FONT>g<SUP>(<I>i</I>) </SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> <IMG SRC="../IMAGES/gteq.gif"> 2, then <I>r<SUB>i </I></SUB><IMG SRC="../IMAGES/lteq12.gif"> <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg<SUP>(<I>i</I>) </SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> + 2. Initially, we have <I>r</I><SUB>1 </SUB><IMG SRC="../IMAGES/lteq12.gif"> <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>n</I><FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrur14.gif"></FONT>. The <I>i</I>th iteration brings the number of bits in the coloring down to <I>r<SUB>i+</I>1</SUB><I> = </I><IMG SRC="../IMAGES/hfbrul14.gif">lg <I>r<SUB>i</I></SUB><IMG SRC="../IMAGES/hfbrur14.gif"> + 1. Assuming that the inductive hypothesis holds for <I>r<SUB>i - </I>1</SUB>, we obtain<P>
<pre><I>r<SUB>i  </I></SUB>=    <IMG SRC="../IMAGES/hfbrul14.gif">lg <I>r<SUB>i</I></SUB>-<SUB>1</SUB><IMG SRC="../IMAGES/hfbrur14.gif"> + 1</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/lteq12.gif"><I>     </I><IMG SRC="../IMAGES/hfbrul14.gif">lg(<IMG SRC="../IMAGES/hfbrul14.gif">lg<I><SUP>(i<FONT FACE="CG Times (W1)" SIZE=2></I></SUP>-<SUP>1<I>)</SUP>n</I><IMG SRC="../IMAGES/hfbrur14.gif"></FONT> + 2)<IMG SRC="../IMAGES/hfbrur14.gif"> + 1</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/lteq12.gif">     <IMG SRC="../IMAGES/hfbrul14.gif">lg(lg<SUP>(<I>i</I><FONT FACE="CG Times (W1)" SIZE=2></SUP>-<SUP>1)</SUP><I>n </I></FONT>+ 3)<IMG SRC="../IMAGES/hfbrur14.gif"> + 1</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/lteq12.gif">     <IMG SRC="../IMAGES/hfbrul14.gif">lg(2 lg<SUP>(<I>i</I><FONT FACE="CG Times (W1)" SIZE=2></SUP>-<SUP>1)</SUP><I>n</I></FONT>)<IMG SRC="../IMAGES/hfbrur14.gif"> + 1</sub></sup></pre><P>
<pre>=     <IMG SRC="../IMAGES/hfbrul14.gif">lg(lg<SUP>(<I>i</I><FONT FACE="CG Times (W1)" SIZE=2></SUP>-<SUP>1)</SUP><I>n</I></FONT>) + 1<IMG SRC="../IMAGES/hfbrur14.gif"> + 1</sub></sup></pre><P>
<pre>=     <IMG SRC="../IMAGES/hfbrul14.gif">lg <SUP>(<I>i</I>)</SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> + 2.</sub></sup></pre><P>
The fourth line follows from the assumption that <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif">l</FONT>g<SUP>(<I>i</I>) </SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> <IMG SRC="../IMAGES/gteq.gif"> 2, which means that <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg<SUP>(<I>i</I>-1)</SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> <IMG SRC="../IMAGES/gteq.gif"> 3. Therefore, after <I>m</I> = lg* <I>n</I> steps, the number of bits in the coloring is <I>r<SUB>m </I></SUB><IMG SRC="../IMAGES/lteq12.gif"><I><SUB> </I></SUB><IMG SRC="../IMAGES/hfbrul14.gif">lg<SUP>(<I>m</I>) </SUP><I>n</I><IMG SRC="../IMAGES/hfbrur14.gif"> + 2 = 3, since lg <SUP>(<I>m</I>)</SUP> <I>n </I><IMG SRC="../IMAGES/lteq12.gif"> 1 by defination of the lg<SUP>*</SUP> function. Thus, at most one more iteration suffices to produce a 6-coloring. The total time of SIX-COLOR is therefore <I>O</I>(lg<SUP>*</SUP> <I>n</I>).<P>
<P>







<h2>Computing an MIS from a 6-coloring</h2><P>
<a name="0963_1a33"><a name="0963_1a34"><a name="0963_1a35"><a name="0963_1a36">Coloring is the hard part of symmetry breaking. The EREW algorithm <FONT FACE="Courier New" SIZE=2>LIST</FONT>-MIS uses <I>n </I>processors to find a maximal independent set in <I>O</I>(<I>c</I>) time given a <I>c</I>-coloring of an <I>n</I>-object list. Thus, once we have computed a 6-coloring of a list, we can find a maximal independent set of the linked list in <I>O</I>(1) time.<P>
The latter part of Figure 30.11 illustrates the idea behind <FONT FACE="Courier New" SIZE=2>LIST</FONT>-MIS. We are given a <I>c</I>-coloring <I>C</I>. With each object <I>x</I>, we keep a bit <I>alive</I>[<I>x</I>], which tells us whether <I>x</I> is still a candidate for inclusion in the MIS. Initially, <I>alive</I>[<I>x</I>] = TRUE for all objects <I>x</I>.<P>
The algorithm then iterates through each of the <I>c</I> colors. In the iteration for color <I>i</I>, each processor responsible for an object <I>x</I> checks whether <I>C</I>[<I>x</I>]<I> = i</I> and <I>alive</I>[<I>x</I>]<I> =</I> <FONT FACE="Courier New" SIZE=2>TRUE</FONT>. If both conditions hold, then the processor marks <I>x</I> as belonging to the MIS being constructed. All objects adjacent to those added in the MIS--those immediately preceding or following--have their <I>alive</I> bits set to <FONT FACE="Courier New" SIZE=2>FALSE</FONT>; they cannot be in the MIS because they are adjacent to an object in the MIS. after all <I>c</I> iterations, each object has either been &quot;killed&quot;--its <I>alive</I> bit has been set to <FONT FACE="Courier New" SIZE=2>FALSE</FONT>--or placed into the MIS.<P>
We must show that the resulting set is independent and maximal. To see that it is independent, suppose that two adjacent objects <I>x</I> and <I>next</I>[<I>x</I>] are placed into the set. Since they are adjacent, <I>C</I>[<I>x</I>] <IMG SRC="../IMAGES/noteq.gif"> <I>C</I>[<I>next</I>[<I>x</I>]]<I>,</I> because <I>C</I> is a coloring. Without loss of generality, we assume that <I>C</I>[<I>x</I>] <I>&lt; C</I>[<I>next</I>[<I>x</I>]], so that <I>x</I> is placed into the set before <I>next</I>[<I>x</I>] is. But then <I>alive</I>[<I>next</I>[<I>x</I>]] has been set to <FONT FACE="Courier New" SIZE=2>FALSE</FONT> by the time objects of color <I>C</I>[<I>next</I>[<I>x</I>]] are considered, and <I>next</I>[<I>x</I>] could not have been place into the set.<P>
To see that the set is maximal, suppose that none of three consecutive objects <I>x, y,</I> and <I>z</I> has been placed into the set. The only way that <I>y</I> could have avoided being placed into the set, though, is if it had been killed when an adjacent object was placed into the set. Since, by our supposition, neither <I>x</I> nor <I>z</I> was placed into the set, the object <I>y</I> must have been still alive at the time when objects of color <I>C</I>[<I>y</I>] were processed. It must have been placed into the MIS.<P>
Each iteration of <FONT FACE="Courier New" SIZE=2>LIST</FONT>-MIS takes <I>O</I>(1) time on a PRAM. The algorithm is EREW since each object accesses only itself, its predecessor, and its successor in the list. Combining <FONT FACE="Courier New" SIZE=2>LIST</FONT>-MIS with <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT>, we can break symmetry in a linked list in <I>O</I>(lg<SUP>*</SUP> <I>n</I>) time deterministically.<P>
<P>







<h2><a name="0964_1a3b">Exercises<a name="0964_1a3b"></h2><P>
<a name="0964_1a3c">30.5-1<a name="0964_1a3c"><P>
For the 2-processor symmetry-breaking example at the beginning of this section, show that symmetry is broken in constant expected time.<P>
<a name="0964_1a3d">30.5-2<a name="0964_1a3d"><P>
Given a 6-coloring of an <I>n</I>-object list, show how to 3-color the list in <I>O</I>(1) time using <I>n</I> processors in an EREW PRAM.<P>
<a name="0964_1a3e">30.5-3<a name="0964_1a3e"><P>
Suppose that every nonroot node in an <I>n</I>-node tree has a pointer to its parent. Give a CREW algorithm to <I>O</I>(1)-color the tree in <I>O</I>(lg<SUP>*</SUP> <I>n</I>) time.<P>
<a name="0964_1a3f">30.5-4<a name="0964_1a3f"><P>
Give an efficient PRAM algorithm to <I>O</I>(1)-color a degre-3 graph. Analyze your algorithm.<P>
<a name="0964_1a40">30.5-5<a name="0964_1a40"><P>
<a name="0964_1a37"><a name="0964_1a38"><a name="0964_1a39"><a name="0964_1a3a">A <I><B>k-ruling set</I></B> of a linked list is a set of objects (rulers) in the list such that no rulers are adjacent and at most <I>k</I> nonrulers (subjects) separate rulers. Thus, an MIS is a 2-ruling set. Show how an <I>O</I>(lg <I>n</I>)-ruling set of an <I>n</I>-object list can be computed in <I>O</I>(1) time using <I>n</I> processors. Show how an <I>O</I>(lg lg <I>n</I>) ruling set can be computed in <I>O</I>(1) time under the same assumptions.<P>
<a name="0964_1a41">30.5-6<a name="0964_1a41"><P>
Show how to find a 6-coloring of an <I>n</I>-object linked list in <I>O</I>(lg(lg<SUP>*</SUP> <I>n</I>)) time. Assume that each processor can store a precomputed table of size <I>O</I>(lg <I>n</I>). (<I>Hint:</I> In <FONT FACE="Courier New" SIZE=2>SIX</FONT>-<FONT FACE="Courier New" SIZE=2>COLOR</FONT>, upon how many values does the final color of an object depend?)<P>
<P>


<P>







<h1><a name="0965_1a4d">Problems<a name="0965_1a4d"></h1><P>
<a name="0965_1a4e">30-1     Segmented parallel prefix<a name="0965_1a4e"><P>
<a name="0965_1a3b"><a name="0965_1a3c"><a name="0965_1a3d">Like an ordinary prefix computation, a <I><B>segmented prefix computation</I></B> is defined in terms of a binary, associative operator <IMG SRC="../IMAGES/circx.gif">. It takes an input sequence <I>x</I> = <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . , <I>x<SUB>n</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"> whose elements are drawn from a domains and a <I><B>segment</I></B> sequence <I>b = </I><IMG SRC="../IMAGES/lftwdchv.gif"><I>b</I><SUB>1</SUB>, <I>b</I><SUB>2</SUB>, . . . , <I>b<SUB>n</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"><I> </I>whose elements are drawn from the domain {0,1}, with<I> b</I><SUB>1</SUB> = 1. It produces an output sequence <I>y</I> = <IMG SRC="../IMAGES/lftwdchv.gif"><I>y</I><SUB>1</SUB>, <I>y</I><SUB>2</SUB>, . . . , <I>y<SUB>n</I></SUB><IMG SRC="../IMAGES/wdrtchv.gif"> over the domain <I>S</I>. The bits of <I>b</I> determine a partitioning of <I>x</I> and <I>y</I> into segments; a new segment begins wherever <I>b<SUB>i</I> </SUB>= 1, and the current one continues if <I>b<SUB>i</I></SUB> = 0. The segmented prefix computation performs an independent prefix computation within each segment of <I>x</I> to produce the corresponding segment of <I>y</I>. Figure 30.12 illustrates a segmented prefix computation using ordinary addition.<P>
<I><B>a.</I></B>     Define the operator <img src="726_a.gif"> on ordered pairs (<I>a, z</I>), (<I>a</I>',<I> z</I>'<I>) <IMG SRC="../IMAGES/memof12.gif"></I> {0, 1} X <I>S</I> as follows:<P>
<img src="726_b.gif"><P>
Prove that <img src="726_c.gif"> is associative.<P>
<I><B>b.</I></B>     Show how to implement any segmented prefix computation on an <I>n</I>-element list in <I>O</I>(lg <I>n</I>) time on an EREW PRAM.<P>
<I><B>c.</I></B>     Describe an <I>O</I>(<I>k</I> lg <I>n</I>)-time EREW algorithm to sort a list of <I>n k</I>-bit numbers.<P>
<a name="0965_1a4f">30-2     Processor-efficient maximum algorithm<a name="0965_1a4f"><P>
<a name="0965_1a3e"><a name="0965_1a3f">We wish to find the maximum of <I>n</I> numbers on a CRCW PRAM with <I>p</I> = <I>n</I> processors.<P>
<I><B>a.</I></B>     Show that the problem of finding the maximum of <I>m </I><IMG SRC="../IMAGES/lteq12.gif"><I> p</I>/2 numbers can be reduced to the problem of finding the maximum of at most <I>m</I><SUP>2</SUP><I>/p </I>numbers in <I>O</I>(1) time on a <I>p</I>-processor CRCW PRAM.<P>
<I><B>b.</I></B>     If we start with <I>m</I> = <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrdl12.gif"><I>p/</I></FONT>2<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrdr12.gif"></FONT> numbers, how many numbers remain after <I>k</I> iterations of the algorithm in part (a)?<P>
<img src="726_d.gif"><P>
<h4><a name="0965_1a50">Figure 30.12 A segmented prefix computation with segment sequence b, input sequence x, and output sequence y. There are 5 segments.<a name="0965_1a50"></sub></sup></h4><P>
<I><B>c</I>.</B>     Show that the problem of finding the maximum of <I>n</I> numbers can be solved in <I>O</I>(lg lg<I> n</I>)<I> </I>time on a CRCW PRAM with<I> p = n</I> processors.<P>
<a name="0965_1a51">30-3     Connected components<a name="0965_1a51"><P>
<a name="0965_1a40"><a name="0965_1a41"><a name="0965_1a42"><a name="0965_1a43"><a name="0965_1a44"><a name="0965_1a45"><a name="0965_1a46"><a name="0965_1a47">In this problem, we investigate an arbitrary-CRCW algorithm for computing the connected components of an undirected graph <I>G = </I>(<I>V, E</I>) that uses |<I>V</I> + <I>E</I>| processors. The data structure used is a disjoint-set forest (see Section 22.3). Each vertex <I>v </I><IMG SRC="../IMAGES/memof12.gif"><I> V</I> maintains a pointer <I>p</I>[<I>v</I>] to a parent. Initially, <I>p</I>[<I>v</I>]<I> = v:</I> the vertex points to itself. At the end of the algorithm, for any two vertices <I>u, v </I><IMG SRC="../IMAGES/memof12.gif"><I> V,</I> we have <I>p</I>[<I>u</I>]<I> = p</I>[<I>v</I>] if and only if <img src="727_a.gif"> in <I>G</I>. During the algorithm, the <I>p</I> pointers form a forest of rooted <I><B>pointer </I></B>trees. A <I><B>star</I></B> is a pointer tree in which <I>p</I>[<I>u</I>]<I> = p</I>[<I>v</I>] for all vertices <I>u</I> and <I>v </I>in the tree. <P>
The connected-components algorithm assumes that each edge (<I>u, v</I>)<I> </I><IMG SRC="../IMAGES/memof12.gif"><I> E </I>appears twice: once as (<I>u,v</I>) and once as (<I>v,u</I>). The algorithm uses two basic operations, <FONT FACE="Courier New" SIZE=2>HOOK</FONT> and <FONT FACE="Courier New" SIZE=2>JUMP</FONT>, and a subroutine <FONT FACE="Courier New" SIZE=2>STAR</FONT> that sets <I>star</I>[<I>v</I>]<I> =</I> <FONT FACE="Courier New" SIZE=2>TRUE </FONT>if <I>v</I> belongs to a star.<P>
<pre><a name="0965_1a48">HOOK(<I>G</I>)</sub></sup></pre><P>
<pre><a name="0965_1a49">1 STAR (<I>G</I>)</sub></sup></pre><P>
<pre>2 <B>for</B> each edge (<I>u, v</I>)<I> </I><IMG SRC="../IMAGES/memof12.gif"> E<I>[</I>G<I>], in parallel</I></sub></sup></pre><P>
<pre>3      <B>do if</B> <I>star</I>[<I>u</I>]<I> </I>and<I> p</I>[<I>u</I>]<I> &gt; p</I>[<I>v</I>]</sub></sup></pre><P>
<pre>4            <B>then</B> <I>p</I>[<I>p</I>[<I>u</I>]] <IMG SRC="../IMAGES/arrlt12.gif"> <I>p</I>[<I>v</I>]</sub></sup></pre><P>
<pre>5 STAR(<I>G</I>)</sub></sup></pre><P>
<pre>6 <B>for</B> each edge (<I>u, v</I>)<I> </I><IMG SRC="../IMAGES/memof12.gif"> E<I>[</I>G<I>], in parallel</I></sub></sup></pre><P>
<pre>7      <B>do if</B> <I>star</I>[<I>u</I>] and <I>p</I>[<I>u</I>] <IMG SRC="../IMAGES/noteq.gif"> <I>p</I>[<I>v</I>]</sub></sup></pre><P>
<pre>8            <B>then</B> <I>p</I>[<I>p</I>[<I>u</I>]] <IMG SRC="../IMAGES/arrlt12.gif"> <I>p</I>[<I>v</I>]</sub></sup></pre><P>
<pre></sub></sup></pre><P>
<pre><a name="0965_1a4a">JUMP(<I>G</I>)</sub></sup></pre><P>
<pre>1  <B>for</B> each <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>[<I>G</I>], in parallel</sub></sup></pre><P>
<pre>2 <B>     do</B> <I>p</I>[<I>v</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>p</I>[<I>p</I>[<I>v</I>]]</sub></sup></pre><P>
The connected-components algorithm performs an initial <FONT FACE="Courier New" SIZE=2>HOOK</FONT>, and then it repeatedly performs <FONT FACE="Courier New" SIZE=2>HOOK</FONT>, <FONT FACE="Courier New" SIZE=2>JUMP</FONT>, H<FONT FACE="Courier New" SIZE=2>OOK,</FONT> <FONT FACE="Courier New" SIZE=2>JUMP</FONT>, and so on, until no pointer is changed by a <FONT FACE="Courier New" SIZE=2>JUMP</FONT> operation. (Note that two H<FONT FACE="Courier New" SIZE=2>OOK'S</FONT> are performed before the first <FONT FACE="Courier New" SIZE=2>JUMP</FONT>.) <P>
<I><B>a.</I></B>     Give pseudocode for <FONT FACE="Courier New" SIZE=2>STAR</FONT>(<I>G</I>).<P>
<I><B>b.</I></B>     Show that the <I>p</I> pointers indeed form rooted trees, with the root of a tree pointing to itself. Show that if <I>u and v</I> are in the same pointer tree, then <img src="727_b.gif"> in <I>G</I>.<P>
<I><B>c.</I></B>     Show that the algorithm is correct: it terminates, and when it terminates, <I>p</I>[<I>u</I>]<I> = p</I>[<I>v</I>] if and only if <img src="727_c.gif"> in <I>G</I>.<P>
To analyze the connected-components algorithm, let us examine a single connected component <I>C</I>, which we assume has at least two vertices. Suppose that at some point during the algorithm, <I>C</I> is made up of a set {<I>T<SUB>i</I></SUB>} of pointer trees. Define the potential of <I>C</I> as<P>
<img src="728_a.gif"><P>
The goal of our analysis is to prove that each iteration of hooking and jumping decreases <IMG SRC="../IMAGES/phicap12.gif">(<I>C</I>) by a constant factor.<P>
<I><B>d.</I></B>     Prove that after the initial <FONT FACE="Courier New" SIZE=2>HOOK</FONT>, there are no pointer trees of height 0 and <IMG SRC="../IMAGES/phicap12.gif">(<I>C</I>) <IMG SRC="../IMAGES/lteq12.gif"> |<I>V</I>|.<P>
<I><B>e.</I></B>     Argue that after the initial <FONT FACE="Courier New" SIZE=2>HOOK</FONT>, subsequent <FONT FACE="Courier New" SIZE=2>HOOK</FONT> operations never increase <IMG SRC="../IMAGES/phicap12.gif">(<I>C</I>).<P>
<I><B>f.</I></B>     Show that after every noninitial <FONT FACE="Courier New" SIZE=2>HOOK</FONT> operation, no pointer tree is a star unless the pointer tree contains all vertices in <I>C</I>.<P>
<I><B>g.</I></B>     Argue that if <I>C</I> has not been collapsed into a single star, then after a <FONT FACE="Courier New" SIZE=2>JUMP</FONT> operation, <IMG SRC="../IMAGES/phicap12.gif">(<I>C</I>) is at most 2/3 its previous value. Illustrate the worst case.<P>
<I><B>h.</I></B>     Conclude that the algorithm determines all the connected components of <I>G </I>in<I> O</I>(l<I>g V</I>) time.<P>
<a name="0965_1a52">30-4.     Transposing a raster image<a name="0965_1a52"><P>
<a name="0965_1a4b"><a name="0965_1a4c">A raster-graphics frame buffer can be viewed as a <I>p </I>X<I> p</I> matrix <I>M</I> of bits. The raster-graphics display hardware makes the <I>n</I> X <I>n</I> upper left submatrix of <I>M</I> visible on the user's screen. A B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT operation (BLock Transfer of BITs) is used to move a rectangle of bits from one position to another. Specifically, B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT(<I>r</I><SUB>1</SUB>, <I>c</I><SUB><FONT FACE="Times New Roman" SIZE=2>1</SUB><FONT FACE="Courier New" SIZE=2>,</FONT> <I>r</I><SUB>2</FONT></SUB>, <I>c</I><SUB>2</SUB>, <I>nr</I>, <I>nc</I>, *) sets<P>
<pre><I>M</I>[<I>r</I><SUB>2 </SUB>+ <I>i</I>, <I>c</I><SUB>2 </SUB>+ <I>j</I>] <IMG SRC="../IMAGES/arrlt12.gif"> <I>M</I>[<I>r</I><SUB>2 </SUB>+ <I>i</I>, <I>c</I><SUB>2 </SUB>+<SUB> <I>j</I>] * </SUB><I>M</I>[<I>r</I><SUB>1</SUB> + <I>i</I>, <I>c</I><SUB>1</SUB> + <I>j</I>]</sub></sup></pre><P>
for <I>i =</I> 0, 1,<I> . . . , nr - </I>1<I> and j = </I>0, 1,<I> . . . </I>, <I>nc -</I> 1, where * is any of the 16 boolean functions on two inputs.<P>
We are interested in transposing the image (<I>M</I>[<I>i</I>,<I> j</I>]<I> </I><IMG SRC="../IMAGES/arrlt12.gif"> <I>M</I>[<I>j</I>,<I> i</I>]) in the visible portion of the frame buffer. We assume that the cost of copying the bits is less than that of calling the B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT primitive, and hence we are interested in using as few B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT operations as possible.<P>
Show that any image on the screen can be transposed with <I>O</I>(lg <I>n</I>) B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT operations. Assume that <I>p</I> is sufficiently larger than <I>n</I> so that the nonvisible portion of the frame buffer provides enough working storage. How much additional storage do you need? (<I>Hint</I>: Use a parallel divide-and-conquer approach in which some of the B<FONT FACE="Times New Roman" SIZE=1>IT</FONT>BLT's are performed with boolean AND's.)<P>
<P>







<h1>Chapter notes</h1><P>
Akl [9], Karp and Ramachandran [118], and Leighton [135] survey parallel algorithms for combinatorial problems. Various parallel machine architectures are described by Hwang and Briggs [109] and Hwang and DeGroot [110].<P>
<a name="0966_1a4d"><a name="0966_1a4e">The theory of parallel computing began in the late 1940's when J. Von Neumann [38] introduced a restricted model of parallel computing called a cellular automaton, which is essentially a two-dimensional array of finite-state processors interconnected in meshlike fashion. The PRAM model was formalized in 1978 by Fortune and Wyllie [73], although many other authors had previously discussed essentially similar models.<P>
Pointer jumping was introduced by Wyllie [204]. The study of parallel prefix computations arose from the work of Ofman [152] in the context of carry-lookahead addition. The Euler-tour technique is due to Tarjan and Vishkin [191].<P>
Processor-time trade-offs for computing the maximum of a set of <I>n </I>numbers were provided by Valiant [193], who also showed that an <I>O</I>(1)-time work-efficient algorithm does not exist. Cook, Dwork, and Reischuk [50] proved that the problem of computing the maximum requires <IMG SRC="../IMAGES/omega12.gif">(lg <I>n</I>) time on a CREW PRAM. The simulation of a CRCW algorithm with an EREW algorithm is due to Vishkin [195].<P>
Theorem 30.2 is due to Brent [34]. The randomized algorithm for work-efficient list ranking was discovered by Anderson and Miller [11]. They also have a deterministic, work-efficient algorithm for the same problem [10]. The algorithm for deterministic symmetry breaking is due to Goldberg and Plotkin [84]. It is based on a similar algorithm with the same running time due to Cole and Vishkin [47].<P>
<P>


<P>
<P>
<center>Go to <a href="chap31.htm">Chapter 31</A>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Back to <a href="toc.htm">Table of Contents</A>
</P>
</center>


</BODY></HTML>