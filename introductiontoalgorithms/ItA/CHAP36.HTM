<HTML><HEAD>

<TITLE>Intro to Algorithms: CHAPTER 36: NPCOMPLETENESS</TITLE></HEAD><BODY BGCOLOR="#FFFFFF">

<a href="chap37.htm"><img align=right src="../../images/next.gif" alt="Next Chapter" border=0></A>
<a href="toc.htm"><img align=right src="../../images/toc.gif" alt="Return to Table of Contents" border=0></A>
<a href="chap35.htm"><img align=right src="../../images/prev.gif" alt="Previous Chapter" border=0></A>


<h1><a name="09f9_1c6f">CHAPTER 36: NP-COMPLETENESS<a name="09f9_1c6f"></h1><P>
<a name="09f9_1c67"><a name="09f9_1c68"><a name="09f9_1c69"><a name="09f9_1c6a"><a name="09f9_1c6b"><a name="09f9_1c6c"><a name="09f9_1c6d"><a name="09f9_1c6e">All of the algorithms we have studied thus far have been <I><B>polynomial-time</I></B> <I><B>algorithms</I></B>: on inputs of size <I>n</I>, their worst-case running time is <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>. It is natural to wonder whether <I>all</I> problems can be solved in polynomial time. The answer is no. For example, there are problems, such as Turing's famous "Halting Problem," that cannot be solved by any computer, no matter how much time is provided. There are also problems that can be solved, but not in time <I>O</I>(<I>n<SUP>k</I></SUP>) for any constant <I>k</I>. Generally, we think of problems that are solvable by polynomial-time algorithms as being tractable, and problems that require superpolynomial time as being intractable.<P>
The subject of this chapter, however, is an interesting class of problems, called the "NP-complete" problems, whose status is unknown. No polynomial-time algorithm has yet been discovered for an NP-complete problem, nor has anyone yet been able to prove a superpolynomial-time lower bound for any of them. This so-called P <IMG SRC="../IMAGES/noteq.gif"> NP question has been one of the deepest, most perplexing open research problems in theoretical computer science since it was posed in 1971.<P>
Most theoretical computer scientists believe that the NP-complete problems are intractable. The reason is that if any single NP-complete problem can be solved in polynomial time, then <I>every</I> NP-complete problem has a polynomial-time algorithm. Given the wide range of NP-complete problems that have been studied to date, without any progress toward a polynomial-time solution, it would be truly astounding if all of them could be solved in polynomial time.<P>
To become a good algorithm designer, you must understand the rudiments of the theory of NP-completeness. If you can establish a problem as NP-complete, you provide good evidence for its intractability. As an engineer, you would then do better spending your time developing an approximation algorithm (see Chapter 37) rather than searching for a fast algorithm that solves the problem exactly. Moreover, many natural and interesting problems that on the surface seem no harder than sorting, graph searching, or network flow are in fact NP-complete. Thus, it is important to become familiar with this remarkable class of problems.<P>
This chapter studies the aspects of NP-completeness that bear most directly on the analysis of algorithms. In Section 36.1, we formalize our notion of "problem" and define the complexity class P of polynomial-time solvable decision problems. We also see how these notions fit into the framework of formal-language theory. Section 36.2 defines the class NP of decision problems whose solutions can be verified in polynomial time. It also formally poses the P <IMG SRC="../IMAGES/noteq.gif"> NP question.<P>
Section 36.3 shows how relationships between problems can be studied via polynomial-time "reductions." It defines NP-completeness and sketches a proof that one problem, called "circuit satisfiability," is NP-complete. Having found one NP-complete problem, we show in Section 36.4 how other problems can be proven to be NP-complete much more simply by the methodology of reductions. The methodology is illustrated by showing that two formula-satisfiability problems are NP-complete. A variety of other problems are shown to be NP-complete in Section 36.5.<P>





<h1><a name="09fb_0001">36.1 Polynomial time<a name="09fb_0001"></h1><P>
We begin our study of NP-completeness by formalizing our notion of polynomial-time solvable problems. These problems are generally regarded as tractable. The reason why is a philosophical, not a mathematical, issue. We can offer three supporting arguments.<P>
First, although it is reasonable to regard a problem that requires time <IMG SRC="../IMAGES/bound.gif">(<I>n</I><SUP>100</SUP>) as intractable, there are very few practical problems that require time on the order of such a high-degree polynomial. The polynomial-time computable problems encountered in practice typically require much less time.<P>
Second, for many reasonable models of computation, a problem that can be solved in polynomial time in one model can be solved in polynomial time in another. For example, the class of problems solvable in polynomial time by the serial random-access machine used throughout most of this book is the same as the class of problems solvable in polynomial time on abstract Turing machines.<SUP>1 </SUP>It is also the same as the class of problems solvable in polynomial time on a parallel computer, even if the number of processors grows polynomially with the input size.<P>
<SUP>1</SUP>See Hopcroft and Ullman [104] or Lewis and Papadimitriou [139] for a thorough treatment of the Turing-machine model. of calls to polynomial-time subroutines, the running time of the composite algorithm is polynomial.<P>
Third, the class of polynomial-time solvable problems has nice closure properties, since polynomials are closed under addition, multiplication, and composition. For example, if the output of one polynomial-time algorithm is fed into the input of another, the composite algorithm is polynomial. If an otherwise polynomial-time algorithm makes a constant number of calls to polynomial-time subroutines, the running time of the composite algorithm is polynomial.<P>





<h2>Abstract problems</h2><P>
<a name="09fc_1c6f"><a name="09fc_1c70"><a name="09fc_1c71"><a name="09fc_1c72"><a name="09fc_1c73"><a name="09fc_1c74">To understand the class of polynomial-time solvable problems, we must first have a formal notion of what a "problem" is. We define an <I><B>abstract problem</I></B><I> Q</I> to be a binary relation on a set <I>I</I> of problem <I><B>instances</I></B> and a set <I>S </I>of problem <I><B>solutions</I></B>. For example, consider the problem SHORTEST-PATH of finding a shortest path between two given vertices in an unweighted, undirected graph <I>G =</I> (<I>V, E</I>). An instance for SHORTEST-PATH is a triple consisting of a graph and two vertices. A solution is a sequence of vertices in the graph, with perhaps the empty sequence denoting that no path exists. The problem SHORTEST-PATH itself is the relation that associates each instance of a graph and two vertices with a shortest path in the graph that connects the two vertices. Since shortest paths are not necessarily unique, a given problem instance may have more than one solution.<P>
<a name="09fc_1c75"><a name="09fc_1c76">This formulation of an abstract problem is more general than is required for our purposes. For simplicity, the theory of NP-completeness restricts attention to<B> </B><I><B>decision problems</I></B>: those having a yes/no solution. In this case, we can view an abstract decision problem as a function that maps the instance set <I>I</I> to the solution set {0, 1}. For example, a decision problem PATH related to the shortest-path problem is, "Given a graph <I>G = </I>(<I>V, E</I>), two vertices <I>u, v </I><IMG SRC="../IMAGES/memof12.gif"> <I>V</I>, and a nonnegative integer <I>k</I>, does a path exist in <I>G</I> between <I>u</I> and <I>v</I> whose length is at most <I>k</I>?" If <I>i</I> = &lt;<I>G, u, v, k</I>&gt; is an instance of this shortest-path problem, then PATH(<I>i</I>) = 1 (yes) if a shortest path from <I>u</I> to <I>v</I> has length at most <I>k</I>, and PATH(<I>i</I>) = 0 (no) otherwise.<P>
<a name="09fc_1c77"><a name="09fc_1c78">Many abstract problems are not decision problems, but rather <I><B>optimization problems</I></B>, in which some value must be minimized or maximized. In order to apply the theory of NP-completeness to optimization problems, we must recast them as decision problems. Typically, an optimization problem can be recast by imposing a bound on the value to be optimized. As an example, in recasting the shortest-path problem as the decision problem PATH, we added a bound <I>k</I> to the problem instance.<P>
Although the theory of NP-completeness compels us to recast optimization problems as decision problems, this requirement does not diminish the impact of the theory. In general, if we can solve an optimization  problem quickly, we can also solve its related decision problem quickly. We simply compare the value obtained from the solution of the optimization problem with the bound provided as input to the decision problem. If an optimization problem is easy, therefore, its related decision problem is easy as well. Stated in a way that has more relevance to NP-completeness, if we can provide evidence that a decision problem is hard, we also provide evidence that its related optimization problem is hard. Thus, even though it restricts attention to decision problems, the theory of NP-completeness applies much more widely.<P>
<P>







<h2>Encodings</h2><P>
<a name="09fd_1c79">If a computer program is to solve an abstract problem, problem instances must must be represented in a way that the program understands. An <I><B>encoding</I> </B>of a set <I>S</I> of abstract objects is a mapping <I>e</I> from <I>S</I> to the set of binary strings.<SUP>2 </SUP>For example, we are all familiar with encoding the natural numbers <I>N</I> = {0, 1, 2, 3, 4, . . .} as the strings {0, 1, 10, 11, 100, . . .}. Using this encoding, <I>e</I>(l7) = 10001. Anyone who has looked at computer representations of keyboard characters is familiar with either the ASCII or EBCDIC codes. In the ASCII code, <I>e</I>(<FONT FACE="Courier New" SIZE=2>A</FONT>) = 1000001. Even a compound object can be encoded as a binary string by combining the representations of its constituent parts. Polygons, graphs, functions, ordered pairs, programs--all can be encoded as binary strings.<P>
<SUP>2 </SUP>The codomain of <I>e</I> need not be <I>binary</I> strings; any set of strings over a finite alphabet having at least 2 symbols will do.<P>
<a name="09fd_1c7a"><a name="09fd_1c7b"><a name="09fd_1c7c"><a name="09fd_1c7d"><a name="09fd_1c7e">Thus, a computer algorithm that "solves" some abstract decision  problem actually takes an encoding of a problem instance as input. We call a problem whose instance set is the set of binary strings a <I><B>concrete problem</I></B>. We say that an algorithm <I><B>solves </I></B>a concrete problem in time <I>O</I>(<I>T</I>(<I>n</I>)) if, when it is provided a problem instance<I> i</I> of length <I>n</I> = |<I>i|</I>, the algorithm can produce the solution in at most <I>O</I>(<I>T</I>(<I>n</I>)) time. A concrete problem is <I><B>polynomial-time solvable</I></B>, therefore, if there exists an algorithm to solve it in time <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>.<P>
<a name="09fd_1c7f"><a name="09fd_1c80">We can now formally define the <I><B>complexity class</I> P</B> as the set of concrete decision problems that are solvable in polynomial time.<P>
We can use encodings to map abstract problems to concrete problems. Given an abstract decision problem <I>Q</I> mapping an instance set <I>I</I> to {0, 1}, an encoding <I>e : I</I> <IMG SRC="../IMAGES/arrow12.gif"> {0, 1}<SUP>*</SUP> can be used to induce a related concrete decision problem, which we denote by <I>e</I>(<I>Q</I>). If the solution to an abstract-problem instance <I>i </I><IMG SRC="../IMAGES/memof12.gif"><I> </I>I<I> is </I>Q<I>(</I>i<I>) <IMG SRC="../IMAGES/memof12.gif"></I> {0, 1}, then the solution to the concrete-problem instance <I>e</I>(<I>i</I>) <IMG SRC="../IMAGES/memof12.gif"><I> </I>{0, 1}<SUP>* </SUP>is also <I>Q</I>(<I>i</I>). As a technicality, there may be some binary strings that represent no meaningful abstract-problem instance. For convenience, we shall assume that any such string is mapped arbitrarily to 0. Thus, the concrete problem produces the same solutions as the abstract problem on binary-string instances that represent the encodings of abstract-problem instances.<P>
<a name="09fd_1c81">We would like to extend the definition of polynomial-time solvability from concrete problems to abstract problems using encodings as the bridge, but we would like the definition to be independent of any particular encoding. That is, the efficiency of solving a problem should not depend on how the problem is encoded. Unfortunately, it depends quite heavily. For example, suppose that an integer <I>k</I> is to be provided as the sole input to an algorithm, and suppose that the running time of the algorithm is <IMG SRC="../IMAGES/bound.gif">(<I>k</I>). If the integer <I>k</I> is provided in <I><B>unary</I></B>--a string of <I>k</I> 1's--then the running time of the algorithm is <I>O</I>(<I>n</I>) on length-<I>n</I> inputs, which is polynomial time. If we use the more natural binary representation of the integer <I>k</I>, however, then the input length is <I>n</I> = <FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/hfbrul14.gif"></FONT>lg <I>k<FONT FACE="Courier New" SIZE=2></I><IMG SRC="../IMAGES/hfbrur14.gif"><I></I>.</FONT> In this case, the running time of the algorithm is <IMG SRC="../IMAGES/bound.gif">(<I>k</I>) = <IMG SRC="../IMAGES/bound.gif">(2<I><SUP>n</I></SUP>), which is exponential in the size of the input. Thus, depending on the encoding, the algorithm runs in either polynomial or superpolynomial time.<P>
The encoding of an abstract problem is therefore quite important to our understanding of polynomial time. We cannot really talk about solving an abstract problem without first specifying an encoding. Nevertheless, in practice, if we rule out "expensive" encodings such as unary ones, the actual encoding of a problem makes little difference to whether the problem can be solved in polynomial time. For example, representing integers in base 3 instead of binary has no effect on whether a problem is solvable in polynomial time, since an integer represented in base 3 can be converted to an integer represented in base 2 in polynomial time.<P>
<a name="09fd_1c82"><a name="09fd_1c83">We say that a function <I>f </I>: {0, 1}<SUP>* </SUP><IMG SRC="../IMAGES/arrow12.gif"> {0, 1}<SUP>*</SUP> is <I><B>polynomial-time computable</I></B> if there exists a polynomial-time algorithm <I>A</I> that, given any input <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}<SUP>*</SUP>, produces as output <I>f</I>(<I>x</I>). For some set <I>I</I> of problem instances, we say that two encodings <I>e</I><SUB>  </SUB> and <I>e</I><SUB>  </SUB> are <I><B>polynomially related</I></B> if there exist two polynomial-time computable functions <I>f</I><SUB>12</SUB> and <I>f</I><SUB>21</SUB> such that for any <I>i </I><IMG SRC="../IMAGES/memof12.gif"><I> I</I>, we have <I>f</I><SUB>12</SUB>(<I>e</I><SUB>1</SUB>(<I>i</I>)) = <I>e</I><SUB>2</SUB>(<I>i</I>) and <I>f</I><SUB>21</SUB>(<I>e</I><SUB>2</SUB>(<I>i</I>)) = <I>e</I><SUB>1</SUB>(<I>i</I>). That is, the encoding <I>e</I><SUB>2</SUB>(<I>i</I>) can be computed from the encoding <I>e</I><SUB>1</SUB>(<I>i</I>) by a polynomial-time algorithm, and vice versa. If two encodings <I>e</I><SUB>1</SUB> and <I>e</I><SUB>2</SUB> of an abstract problem are polynomially related, which we use makes no difference to whether the problem is polynomial-time solvable or not, as the following lemma shows.<P>
<a name="09fd_1c84">Lemma 36.1<a name="09fd_1c84"><P>
Let <I>Q</I> be an abstract decision problem on an instance set <I>I</I>, and let <I>e</I><SUB>1</SUB> and <I>e</I><SUB>2</SUB> be polynomially related encodings on <I>I</I>. Then, <I>e</I><SUB>1</SUB>(<I>Q</I>) <IMG SRC="../IMAGES/memof12.gif"> P if and only if <I>e</I><SUB>2</SUB>(<I>Q</I>) <IMG SRC="../IMAGES/memof12.gif"> P.<P>
<I><B>Proof</I></B><I>     </I>We need only prove the forward direction, since the backward  direction is symmetric. Suppose, therefore, that <I>e</I><SUB>1</SUB>(<I>Q</I>) can be solved in time <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>. Further, suppose that for any problem instance <I>i</I>, the encoding <I>e<SUB>1</I></SUB>(<I>i</I>) can be computed from the encoding <I>e</I><SUB>2</SUB>(<I>i</I>) in time <I>O</I>(<I>n<SUP>c</I></SUP>) for some constant <I>c</I>, where <I>n</I> = |<I>e</I><SUB>1</SUB>(<I>i</I>)|. To solve problem <I>e</I><SUB>2</SUB>(<I>Q</I>), on input <I>e</I><SUB>2</SUB>(<I>i</I>), we first compute <I>e</I><SUB>1</SUB>(<I>i</I>) and then run the algorithm for <I>e</I><SUB>1</SUB>(<I>Q</I>) on <I>e</I><SUB>1</SUB>(<I>i</I>). How long does this take? The conversion of encodings takes time <I>O</I>(<I>n<SUP>c</I></SUP>), and therefore |<I>e</I><SUB>1</SUB>(<I>i</I>)| = <I>O</I>(<I>n<SUP>c</I></SUP>), since the output of a serial computer cannot be longer than its running time. Solving the problem on <I>e</I><SUB>1</SUB> (<I>i</I>) takes time <I>O</I>(<I>|e</I><SUB>1</SUB>(<I>i</I>)|<I><SUP>k</I></SUP>) = <I>O</I>(<I>n<SUP>ck</I></SUP>), which is polynomial since both <I>c</I> and <I>k</I> are constants.      <P>
Thus, whether an abstract problem has its instances encoded in binary or base 3 does not affect its "complexity," that is, whether it is polynomial-time solvable or not, but if instances are encoded in unary, its complexity may change. In order to be able to converse in an encoding-independent fashion, we shall generally assume that problem instances are encoded in any reasonable, concise fashion, unless we specifically say otherwise. To be precise, we shall assume that the encoding of an integer is polynomially related to its binary representation, and that the encoding of a finite set is polynomially related to its encoding as a list of its elements, enclosed in braces and separated by commas. (ASCII is one such encoding scheme.) With such a "standard" encoding in hand, we can derive reasonable encodings of other mathematical objects, such as tuples, graphs, and formulas. To denote the standard encoding of an object, we shall enclose the object in angle braces. Thus, <IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I><IMG SRC="../IMAGES/wdrtchv.gif"> denotes the standard encoding of a graph <I>G</I>.<P>
As long as we implicitly use an encoding that is polynomially related to this standard encoding, we can talk directly about abstract problems without reference to any particular encoding, knowing that the choice of encoding has no effect on whether the abstract problem is polynomial-time solvable. Henceforth, we shall generally assume that all problem instances are binary strings encoded using the standard encoding, unless we explicitly specify the contrary. We shall also typically neglect the distinction between abstract and concrete problems. The reader should watch out for problems that arise in practice, however, in which a standard encoding is not obvious and the encoding does make a difference.<P>
<P>







<h2>A formal-language framework</h2><P>
<a name="09fe_1c84"><a name="09fe_1c85"><a name="09fe_1c86"><a name="09fe_1c87">One of the convenient aspects of focusing on decision problems is that they make it easy to use the machinery of formal-language theory. It is worthwhile at this point to review some definitions from that theory. An <I><B>alphabet</I></B> <IMG SRC="../IMAGES/sum14.gif"> is a finite set of symbols. A <I><B>language</I></B><I> L</I> over <IMG SRC="../IMAGES/sum14.gif"> is any set of strings made up of symbols from <IMG SRC="../IMAGES/sum14.gif">. For example, if <IMG SRC="../IMAGES/sum14.gif"> = {0, 1}, the set <I>L</I> = {10, 11, 101, 111, 1011, 1101, 10001, . . .} is the language of binary representations of prime numbers. We denote the <I><B>empty string</I></B> by <IMG SRC="../IMAGES/epsilon.gif">, and the <I><B>empty language</I></B> by <img src="921_a.gif">. The language of all strings over <IMG SRC="../IMAGES/sum14.gif"> is denoted <IMG SRC="../IMAGES/sum14.gif">*. For example, if <IMG SRC="../IMAGES/sum14.gif"> = {0, 1}, then <IMG SRC="../IMAGES/sum14.gif">* = {<IMG SRC="../IMAGES/epsilon.gif">, 0, 1, 00, 01, 10, 11, 000, . . .} is the set of all binary strings. Every language <I>L</I> over <IMG SRC="../IMAGES/sum14.gif"> is a subset of <IMG SRC="../IMAGES/sum14.gif">*.<P>
<a name="09fe_1c88"><a name="09fe_1c89"><a name="09fe_1c8a"><a name="09fe_1c8b">There are a variety of operations on languages. Set-theoretic operations, such as <I><B>union</I></B> and <I><B>intersection</I></B>, follow directly from the set-theoretic definitions. We define the <I><B>complement</I></B> of <I>L</I> by <img src="921_b.gif">. The <I><B>concatenation </I></B>of two languages<I> L</I><SUB>1</SUB> and <I>L</I><SUB>2</SUB> is the language<P>
<pre><I>L</I> = {<I>x</I><SUB>1</SUB><I>x</I><SUB>2</SUB> : <I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>1</SUB> and <I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>2</SUB>} .</sub></sup></pre><P>
<a name="09fe_1c8c"><a name="09fe_1c8d"><a name="09fe_1c8e">The<B> </B><I><B>closure</I></B> or <I><B>Kleene star</I></B> of a language <I>L</I> is the language<P>
<pre><I>L</I><SUP>*</SUP> = {<IMG SRC="../IMAGES/epsilon.gif">} <IMG SRC="../IMAGES/wideu.gif"> <I>L</I> <IMG SRC="../IMAGES/wideu.gif"> <I>L</I><SUP>2</SUP> <IMG SRC="../IMAGES/wideu.gif"><I>L</I><SUP>3</SUP> <IMG SRC="../IMAGES/wideu.gif"> <SUP> . . </SUP> ,</sub></sup></pre><P>
where <I>L<SUP>k</I></SUP> is the language obtained by concatenating <I>L</I> to itself <I>k</I> times.<P>
From the point of view of language theory, the set of instances for any decision problem <I>Q</I> is simply the set <IMG SRC="../IMAGES/sum14.gif">*, where <IMG SRC="../IMAGES/sum14.gif"> = {0, 1}. Since <I>Q</I> is entirely characterized by those problem instances that produce a 1 (yes) answer, we can view <I>Q</I> as a language <I>L</I> over <IMG SRC="../IMAGES/sum14.gif"> = {0, 1}, where<P>
<pre><I>L</I> = {<I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <IMG SRC="../IMAGES/sum14.gif">* : <I>Q</I>(<I>x</I>) = 1} .</sub></sup></pre><P>
For example, the decision problem PATH has the corresponding language<P>
<pre><a name="09fe_1c8f">PATH = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G,u,v,k</I><IMG SRC="../IMAGES/wdrtchv.gif"><I> : G</I> = (<I>V,E</I>) is an undirected graph,</sub></sup></pre><P>
<pre><I>u</I>,<I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>,</sub></sup></pre><P>
<pre><I>k</I> <IMG SRC="../IMAGES/gteq.gif"> 0 is an integer, and</sub></sup></pre><P>
<pre>there exists a path from <I>u</I> to <I>v</I> in <I>G</I></sub></sup></pre><P>
<pre>whose length is at most <I>k</I>}.</sub></sup></pre><P>
(Where convenient, we shall sometimes use the same name--PATH in this case--to refer to both a decision problem and its corresponding language.) <P>
<a name="09fe_1c90"><a name="09fe_1c91"><a name="09fe_1c92">The formal-language framework allows us to express the relation between decision problems and algorithms that solve them concisely. We say that an algorithm A <I><B>accepts </I></B>a string<I> x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}* if, given input <I>x</I>, the algorithm outputs <I>A</I>(<I>x</I>) = 1. The language<B> </B><I><B>accepted</I></B> by an algorithm <I>A</I> is the set <I>L</I> = {<I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}* :  <I>A</I>(<I>x</I>) = 1}, that is, the set of strings that the algorithm accepts. An algorithm <I>A <B>rejects</I></B> a string <I>x</I> if <I>A</I>(<I>x</I>) = 0.<P>
<a name="09fe_1c93"><a name="09fe_1c94">Even if language <I>L</I> is accepted by an algorithm <I>A</I>, the algorithm will not necessarily reject a string <I>x</I> <IMG SRC="../IMAGES/notmem.gif"> <I>L</I> provided as input to it. For example, the algorithm may loop forever. A language <I>L</I> is <I><B>decided</I></B> by an algorithm <I>A</I> if every binary string is either accepted or rejected by the algorithm. A language <I>L</I> is <I><B>accepted in polynomial time</I></B> by an algorithm <I>A</I> if for any length-<I>n</I> string <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I>, the algorithm accepts <I>x</I> in time <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>. A language <I>L</I> is <I><B>decided in polynomial time</I></B> by an algorithm <I>A</I> if for any length-<I>n</I> string <I>x</I> <IMG SRC="../IMAGES/memof12.gif">{0, 1 }*, the algorithm decides <I>x</I> in time <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>. Thus, to accept a language, an algorithm need only worry about strings in <I>L</I>, but to decide a language, it must accept or reject every string in {0, 1}*.<P>
As an example, the language PATH can be accepted in polynomial time. One polynomial-time accepting algorithm computes the shortest path from <I>u</I> to <I>v</I> in <I>G</I>, using breadth-first search, and then compares the distance obtained with <I>k</I>. If the distance is at most <I>k</I>, the algorithm outputs 1 and halts. Otherwise, the algorithm runs forever. This algorithm does not decide PATH, however, since it does not explicitly output 0 for instances in which the shortest path has length greater than <I>k</I>. A decision algorithm for PATH must explicitly reject binary strings that do not belong to PATH. For a decision problem such as PATH, such a decision algorithm is easy to design. For other problems, such as Turing's Halting Problem, there exists an accepting algorithm, but no decision algorithm exists.<P>
<a name="09fe_1c95"><a name="09fe_1c96"><a name="09fe_1c97"><a name="09fe_1c98">We can informally define a <I><B>complexity class</I></B> as a set of languages, membership in which is determined by a <I><B>complexity measure</I></B>, such as running time, on an algorithm that determines whether a given string <I>x</I> belongs to language <I>L</I>. The actual definition of a complexity class is somewhat more technical--the interested reader is referred to the seminal paper by Hartmanis and Stearns [95].<P>
Using this language-theoretic framework, wee can provide an alternative definition of the complexity class P:<P>
<pre>P = {<I>L</I> <IMG SRC="../IMAGES/rgtubar.gif"> {0,1}* : there exists an algorithm <I>A</I></sub></sup></pre><P>
<pre>that decides <I>L</I> in polynomial time} .</sub></sup></pre><P>
In fact, P is also the class of languages that can be accepted in polynomial time.<P>
<a name="09fe_1c99">Theorem 36.2<a name="09fe_1c99"><P>
P = {<I>L : L </I>is accepted by a polynomial-time algorithm}<I> .</I><P>
<I><B>Proof</I></B>     Since the class of languages decided by polynomial-time algorithms is a subset of the class of languages accepted by polynomial-time algorithms, we need only show that if <I>L</I> is accepted by a polynomial-time algorithm, it is decided by a polynomial-time algorithm. Let <I>L</I> be the language accepted by some polynomial-time algorithm <I>A</I>. We shall use a classic "simulation" argument to construct another polynomial-time algorithm <I>A</I>' that decides <I>L</I>. Because <I>A</I> accepts <I>L</I> in time <I>O</I>(<I>n<SUP>k</I></SUP>) for some constant <I>k</I>, there also exists a constant <I>c</I> such that <I>A</I> accepts <I>L </I>in at most<I> T</I> = <I>cn<SUP>k</I></SUP> steps. For any input string <I>x</I>, the algorithm <I>A</I>' simulates the action of <I>A</I> for time <I>T</I>. At the end of time <I>T</I>, algorithm <I>A</I>' inspects the behavior of <I>A</I>. If <I>A</I> has accepted <I>x</I>, then <I>A</I>' accepts <I>x</I> by outputting a 1. If<I> A</I> has not accepted <I>x</I>, then <I>A</I>' rejects <I>x</I> by outputting a 0. The overhead of <I>A</I>' simulating <I>A</I> does not increase the running time by more than a polynomial factor, and thus <I>A</I>' is a polynomial-time algorithm that decides <I>L.     </I> <P>
Note that the proof of Theorem 36.2 is nonconstructive. For a given language <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> P, we may not actually know a bound on the running time for the algorithm <I>A</I> that accepts <I>L</I>. Nevertheless, we know that such a bound exists, and therefore, that an algorithm <I>A</I>' exists that can check the bound, even though we may not be able to find the algorithm <I>A</I>' easily.<P>
<P>







<h2><a name="09ff_1c9e">Exercises<a name="09ff_1c9e"></h2><P>
<a name="09ff_1c9f">36.1-1<a name="09ff_1c9f"><P>
<a name="09ff_1c99"><a name="09ff_1c9a">Define the optimization problem LONGEST-PATH-LENGTH as the relation that associates each instance of a undirected graph and two vertices with the length of the longest simple path between the two vertices. Define the decision problem LONGEST-PATH = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G, u, v, k</I><IMG SRC="../IMAGES/wdrtchv.gif"><I> </I>: <I>G</I> = (<I>V, E</I>) is an undirected graph, <I>u, v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>, <I>k</I> <IMG SRC="../IMAGES/gteq.gif"> 0 is an integer, and there exists a simple path from <I>u</I> to <I>v</I> in <I>G</I> whose length is at least <I>k</I>}. Show that the optimization problem LONGEST-PATH-LENGTH can be solved in polynomial time if and only if LONGEST-PATH <IMG SRC="../IMAGES/memof12.gif"> P.<P>
<a name="09ff_1ca0">36.1-2<a name="09ff_1ca0"><P>
<a name="09ff_1c9b">Give a formal definition for the problem of finding the longest simple cycle in an undirected graph. Give a related decision problem. Give the language corresponding to the decision problem.<P>
<a name="09ff_1ca1">36.1-3<a name="09ff_1ca1"><P>
Give a formal encoding of directed graphs as binary strings using an adjacency-matrix representation. Do the same using an adjacency-list representation. Argue that the two representations are polynomially related.<P>
<a name="09ff_1ca2">36.1-4<a name="09ff_1ca2"><P>
<a name="09ff_1c9c"><a name="09ff_1c9d">Is the dynamic-programming algorithm for the 0-1 knapsack problem that is asked for in Exercise 17.2-2 a polynomial-time algorithm? Explain your answer.<P>
<a name="09ff_1ca3">36.1-5<a name="09ff_1ca3"><P>
Suppose that a language <I>L</I> can accept any string <I>x </I><IMG SRC="../IMAGES/memof12.gif"><I> L </I>in polynomial time, but that the algorithm that does this runs in superpolynomial time if <I>x </I><IMG SRC="../IMAGES/notmem.gif"><I> L. </I>Argue that<I> L</I> can be decided in polynomial time.<P>
<a name="09ff_1ca4">36.1-6<a name="09ff_1ca4"><P>
Show that an algorithm that makes at most a constant number of calls to polynomial-time subroutines runs in polynomial time, but that a polynomial number of calls to polynomial-time subroutines may result in an exponential-time algorithm. <P>
<a name="09ff_1ca5">36.1-7<a name="09ff_1ca5"><P>
Show that the class P, viewed as a set of languages, is closed under union, intersection, concatenation, complement, and Kleene star. That is, if <I>L</I><SUB>l</SUB>, <I>L</I><SUB>2</SUB> <IMG SRC="../IMAGES/memof12.gif"> P, then <I>L</I><SUB>l</SUB> <IMG SRC="../IMAGES/wideu.gif"> <I>L</I><SUB>2</SUB> <IMG SRC="../IMAGES/memof12.gif"> P, etc.<P>
<P>


<P>







<h1><a name="0a00_1ca0">36.2 Polynomial-time verification<a name="0a00_1ca0"></h1><P>
<a name="0a00_1c9e"><a name="0a00_1c9f">We now look at algorithms that "verify" membership in languages. For example, suppose that for a given instance <IMG SRC="../IMAGES/lftwdchv.gif"><I>G, u, v, k</I><IMG SRC="../IMAGES/wdrtchv.gif"> of the decision problem PATH, we are also given a path <I>p</I> from <I>u</I> to <I>v</I>. We can easily check whether the length of <I>p</I> is at most <I>k</I>, and if so, we can view <I>p</I> as a "certificate" that the instance indeed belongs to PATH. For the decision problem PATH, this certificate doesn't seem to buy us much. After all, PATH belongs to P--in fact, PATH can be solved in linear time--and so verifying membership from a given certificate takes as long as solving the problem from scratch. We shall now examine a problem for which we know of no polynomial-time decision algorithm yet, given a certificate, verification is easy.<P>
<img src="925_a.gif"><P>
<h4><a name="0a00_1ca1">Figure 36.1 (a) A graph representing the vertices, edges, and faces of a dodecahedron, with a hamiltonian cycle shown by shaded edges. (b) A bipartite graph with an odd number of vertices. Any such graph is nonhamiltonian.<a name="0a00_1ca1"></sub></sup></h4><P>





<h2>Hamiltonian cycles</h2><P>
<a name="0a01_1ca0"><a name="0a01_1ca1"><a name="0a01_1ca2"><a name="0a01_1ca3"><a name="0a01_1ca4"><a name="0a01_1ca5">The problem of finding a hamiltonian cycle in an undirected graph has been studied for over a hundred years. Formally, a <I><B>hamiltonian cycle</I></B> of an undirected graph <I>G</I> = (<I>V, E</I>) is a simple cycle that contains each vertex in <I>V</I>. A graph that contains a hamiltonian cycle is said to be <I><B>hamiltonian; </I></B>otherwise, it is<I><B> nonhamiltonian.</I></B> Bondy and Murty [31] cite a letter by W. R. Hamilton describing a mathematical game on the dodecahedron (Figure 36.1(a)) in which one player sticks five pins in any five consecutive vertices and the other player must complete the path to form a cycle containing all the vertices. The dodecahedron is hamiltonian, and Figure 36.1 (a) shows one hamiltonian cycle. Not all graphs are hamiltonian, however. For example, Figure 36.1 (b) shows a bipartite graph with an odd number of vertices. (Exercise 36.2-2 asks you to show that all such graphs are nonhamiltonian.)<P>
<a name="0a01_1ca6">We can define the <I><B>hamiltonian-cycle problem,</I></B> "Does a graph <I>G</I> have a hamiltonian cycle?" as a formal language:<P>
<pre><a name="0a01_1ca7">HAM-CYCLE = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I><IMG SRC="../IMAGES/wdrtchv.gif"><I> : G</I> is a hamiltonian graph}<I> .</I></sub></sup></pre><P>
How might an algorithm decide the language HAM-CYCLE? Given a problem instance<I> </I><IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I><IMG SRC="../IMAGES/wdrtchv.gif">, one possible decision algorithm lists all permutations of the vertices of <I>G</I> and then checks each permutation to see if it is a hamiltonian path. What is the running time of this algorithm? If we use the "reasonable" encoding of a graph as its adjacency matrix, the number <I>m</I> of vertices in the graph is <img src="926_a.gif"> , where <I>n</I> = |<IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I><IMG SRC="../IMAGES/wdrtchv.gif">| is the length of the encoding of <I>G</I>. There are <I>m</I>! possible permutations of the vertices, and therefore the running time is <img src="926_b.gif">, which is not <I>O</I>(<I>n<SUP>k</I></SUP>) for any constant <I>k</I>. Thus, this naive algorithm does not run in polynomial time, and in fact, the hamiltonian-cycle problem is NP-complete, as we shall prove in Section 36.5.<P>
<P>







<h2>Verification algorithms</h2><P>
Consider a slightly easier problem, however. Suppose that a friend tells you that a given graph <I>G</I> is hamiltonian, and then offers to prove it by giving you the vertices in order along the hamiltonian cycle. It would certainly be easy enough to verify the proof: simply verify that the provided cycle is hamiltonian by checking whether it is a permutation of the vertices of <I>V</I> and whether each of the consecutive edges along the cycle actually exists in the graph. This verification algorithm can certainly be implemented to run in <I>O</I>(<I>n<SUP>2</I></SUP>) time, where <I>n</I> is the length of the encoding of <I>G</I> . Thus, a proof that a hamiltonian cycle exists in a graph can be verified in polynomial time.<P>
<a name="0a02_1ca8"><a name="0a02_1ca9">We define a <I><B>verification algorithm </I></B>as being a two-argument algorithm <I>A<B>, </I></B>where one argument is an ordinary input string <I>x </I>and the other is a binary string <I>y </I>called a <I><B>certificate</I></B>. A two-argument algorithm<I><B> </I></B><I>A<B> verifies </I></B>an input string <I>x </I>if there exists a certificate<I> y</I> such that <I>A</I>(<I>x, y</I>) = 1. The <I><B>language verified</I></B> by a verification algorithm<B> </B><I>A</I> is<P>
<pre><I>L</I> = {<I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}* : there exists <I>y</I> <IMG SRC="../IMAGES/memof12.gif">{0, 1}* such that <I>A</I>(<I>x, y</I>) = 1} .</sub></sup></pre><P>
Intuitively, an algorithm <I>A</I> verifies a language <I>L</I> if for any string <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I>, there is a certificate <I>y</I> that A can use to prove that <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I>. Moreover, for any string <I>x</I> <IMG SRC="../IMAGES/notmem.gif"> <I>L</I> there must be no certificate proving that <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L.</I> For example, in the hamiltonian-cycle problem, the certificate is the list of vertices in the hamiltonian cycle. If a graph is hamiltonian, the hamiltonian cycle itself offers enough information to verify this fact. Conversely, if a graph is not hamiltonian, there is no list of vertices that can fool the verification algorithm into believing that the graph is hamiltonian, since the verification algorithm carefully checks the proposed "cycle" to be sure.<P>
<P>







<h2>The complexity class NP</h2><P>
<a name="0a03_1caa"><a name="0a03_1cab">The <I><B>complexity class</I> NP</B> is the class of languages that can be verified by a polynomial-time algorithm.<SUP>3 </SUP>More precisely, a language <I>L</I> belongs to NP if and only if there exists a two-input polynomial-time algorithm <I>A</I> and constant <I>c</I> such that<P>
<pre><I>L</I> = {<I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0,1}* : there exists a certificate <I>y</I> with |<I>y</I>| = <I>0</I>(|<I>x</I>|<I><SUP>c</I></SUP>)</sub></sup></pre><P>
<pre>such that <I>A</I>(<I>x,y</I>) = 1} .</sub></sup></pre><P>
We say that algorithm <I>A</I> <I><B>verifies</I></B> language <I>L</I> <I><B>in polynomial time</I></B><I>.</I><P>
<a name="0a03_1cac"><SUP>3</SUP>The name "NP" stands for "nondeterministic polynomial time." The class NP was originally studied in the context of nondeterminism, but this book uses the somewhat simpler yet equivalent notion of verification. Hopcroft and Ullman [104] give a good presentation of NP-completeness in terms of nondeterministic models of computation.<P>
From our earlier discussion on the hamiltonian-cycle problem, it follows that HAM-CYCLE <IMG SRC="../IMAGES/memof12.gif"> NP. (It is always nice to know that an important set is nonempty.) Moreover, if <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> P, then <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP, since if there is a polynomial-time algorithm to decide <I>L</I>, the algorithm can be easily converted to a two-argument verification algorithm that simply ignores any certificate and accepts exactly those input strings it determines to be in <I>L</I>. Thus, P <IMG SRC="../IMAGES/rgtubar.gif"> NP.<P>
It is unknown whether P = NP, but most researchers believe that P and NP are not the same class. Intuitively, the class P consists of problems that can be solved quickly. The class NP consists of problems for which a solution can be verified quickly. You may have learned from experience that it is often more difficult to solve a problem from scratch than to verify a clearly presented solution, especially when working under time constraints. Theoretical computer scientists generally believe that this analogy extends to the classes P and NP, and thus that NP includes languages that are not in P.<P>
There is more compelling evidence that P <IMG SRC="../IMAGES/noteq.gif"> NP--the existence of "NP-complete" languages. We shall study this class in Section 36.3.<P>
<a name="0a03_1cad"><a name="0a03_1cae">Many other fundamental questions beyond the P <IMG SRC="../IMAGES/noteq.gif"> NP question remain unresolved. Despite much work by many researchers, no one even knows if the class NP is closed under complement. That is, does <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP imply <img src="927_a.gif">? We can define the <I><B>complexity class</I> co-NP</B> as the set of languages <I>L</I> such that <img src="927_b.gif">. The question of whether NP is closed under complement can be rephrased as whether NP = co-NP. Since P is closed under complement (Exercise 36.1-7), it follows that P <IMG SRC="../IMAGES/rgtubar.gif"> NP <IMG SRC="../IMAGES/dome.gif"> co-NP. Once again, however, it is not known whether P = NP <IMG SRC="../IMAGES/dome.gif"> co-NP or whether there is some language in NP <IMG SRC="../IMAGES/dome.gif"> co-NP - P. Figure 36.2 shows the four possible scenarios.<P>
Thus, our understanding of the precise relationship between P and NP is woefully incomplete. Nevertheless, by exploring the theory of NP-completeness, we shall find that our disadvantage in proving problems to be intractable is, from a practical point of view, not nearly so great as we might suppose.<P>
<img src="928_a.gif"><P>
<h4><a name="0a03_1caf">Figure 36.2 Four possibilities for relationships among complexity classes. In each diagram, one region enclosing another indicates a proper-subset relation. (a) P = NP = co-NP. Most researchers regard this possibility as the most unlikely. (b) If NP is closed under complement, then NP = co-NP, but it need not be the case that P = NP. (c) P = NP <IMG SRC="../IMAGES/dome.gif"> co-NP, but NP is not closed under complement. (d) NP <IMG SRC="../IMAGES/noteq.gif"> co-NP and P <IMG SRC="../IMAGES/noteq.gif"> NP <IMG SRC="../IMAGES/dome.gif"> co-NP. Most researchers regard this possibility as the most likely.<a name="0a03_1caf"></sub></sup></h4><P>
<P>







<h2><a name="0a04_1cb8">Exercises<a name="0a04_1cb8"></h2><P>
<a name="0a04_1cb9">36.2-1<a name="0a04_1cb9"><P>
<a name="0a04_1caf"><a name="0a04_1cb0">Consider the language GRAPH-ISOMORPHISM = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I><SUB>1</SUB>, <I>G</I><SUB>2</SUB><IMG SRC="../IMAGES/wdrtchv.gif"> : <I>G</I><SUB>1</SUB> and <I>G</I><SUB>2 </SUB>are isomorphic graphs}. Prove that GRAPH-ISOMORPHISM <IMG SRC="../IMAGES/memof12.gif"> NP by describing a polynomial-time algorithm to verify the language.<P>
<a name="0a04_1cba">36.2-2<a name="0a04_1cba"><P>
Prove that if <I>G</I> is an undirected bipartite graph with an odd number of vertices, then <I>G</I> is nonhamiltonian.<P>
<a name="0a04_1cbb">36.2-3<a name="0a04_1cbb"><P>
Show that if HAM-CYCLE <IMG SRC="../IMAGES/memof12.gif"> P, then the problem of listing the vertices of a hamiltonian cycle, in order, is polynomial-time solvable.<P>
<a name="0a04_1cbc">36.2-4<a name="0a04_1cbc"><P>
Prove that the class NP of languages is closed under union, intersection, concatenation, and Kleene star. Discuss the closure of NP under complement.<P>
<a name="0a04_1cbd">36.2-5<a name="0a04_1cbd"><P>
Show that any language in NP can be decided by an algorithm running in time 2<I><SUP>O</I>(<I>nk</I>)</SUP> for some constant <I>k</I>.<P>
<a name="0a04_1cbe">36.2-6<a name="0a04_1cbe"><P>
<a name="0a04_1cb1"><a name="0a04_1cb2"><a name="0a04_1cb3"><a name="0a04_1cb4"><a name="0a04_1cb5">A <I><B>hamiltonian path</I> </B>in a graph is a simple path that visits every vertex exactly once. Show that the language HAM-PATH = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G, u, v</I><IMG SRC="../IMAGES/wdrtchv.gif"> : there is a hamiltonian path from <I>u</I> to <I>v</I> in graph <I>G</I>} belongs to NP.<P>
<a name="0a04_1cbf">36.2-7<a name="0a04_1cbf"><P>
Show that the hamiltonian-path problem can be solved in polynomial time on directed acyclic graphs. Give an efficient algorithm for the problem.<P>
<a name="0a04_1cc0">36.2-8<a name="0a04_1cc0"><P>
<a name="0a04_1cb6"><a name="0a04_1cb7">Let <IMG SRC="../IMAGES/phicap12.gif"><I></I> be a boolean formula constructed from the boolean input variables <I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . , <I>x<SUB>k</I></SUB>, negations (<IMG SRC="../IMAGES/rtdwnbrc.gif">), AND's (<IMG SRC="../IMAGES/angleup.gif">), OR's (<IMG SRC="../IMAGES/angledwn.gif">), and parentheses. The formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> is a <I><B>tautology</I></B> if it evaluates to 1 for every assignment of 1 and 0 to the input variables. Define TAUTOLOGY as the language of boolean formulas that are tautologies. Show that TAUTOLOGY <IMG SRC="../IMAGES/memof12.gif"> co-NP.<P>
<a name="0a04_1cc1">36.2-9<a name="0a04_1cc1"><P>
Prove that P <IMG SRC="../IMAGES/rgtubar.gif"> co-NP.<P>
<a name="0a04_1cc2">36.2-10<a name="0a04_1cc2"><P>
Prove that if NP <IMG SRC="../IMAGES/noteq.gif"> co-NP, then P <IMG SRC="../IMAGES/noteq.gif"> NP.<P>
<a name="0a04_1cc3">36.2-11<a name="0a04_1cc3"><P>
Let <I>G</I> be a connected, undirected graph with at least 3 vertices, and let <I>G</I><SUP>3 </SUP>be the graph obtained by connecting all pairs of vertices that are connected by a path in <I>G</I> of length at most 3. Prove that <I>G</I><SUP>3</SUP> is hamiltonian. (<I>Hint</I>: Construct a spanning tree for <I>G</I>, and use an inductive argument.)<P>
<P>


<P>







<h1><a name="0a05_0001">36.3 NP-completeness and reducibility<a name="0a05_0001"></h1><P>
Perhaps the most compelling reason why theoretical computer scientists believe that P <IMG SRC="../IMAGES/noteq.gif"> NP is the existence of the class of "NP-complete" problems. This class has the surprising property that if any <I>one</I> NP-complete problem can be solved in polynomial time, then <I>every</I> problem in NP has a polynomial-time solution, that is, P = NP. Despite years of study, though, no polynomial-time algorithm has ever been discovered for any NP-complete problem.<P>
The language HAM-CYCLE is one NP-complete problem. If we could decide HAM-CYCLE in polynomial time, then we could solve every problem in NP in polynomial time. In fact, if NP - P should turn out to be nonempty, we could say with certainty that HAM-CYCLE <IMG SRC="../IMAGES/memof12.gif"> NP - P.<P>
<img src="930_a.gif"><P>
<h4><a name="0a05_0002">Figure 36.3 An illustration of a polynomial-time reduction from a language L<SUB>1</SUB> to a language L<SUB>2</SUB> via a reduction function f. For any input x <IMG SRC="../IMAGES/memof12.gif"> {0, 1}*, the question of whether x <IMG SRC="../IMAGES/memof12.gif"> L<SUB>1</SUB> has the same answer as the question of whether f(x) <IMG SRC="../IMAGES/memof12.gif"> L<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2>.<a name="0a05_0002"></FONT></sub></sup></h4><P>
The NP-complete languages are, in a sense, the "hardest" languages in NP. In this section, we shall show how to compare the relative "hardness" of languages using a precise notion called "polynomial-time reducibility." First, we formally define the NP-complete languages, and then we sketch a proof that one such language, called CIRCUIT-SAT, is NP-complete. In Section 36.5, shall use the notion of reducibility to show that many other problems are NP-complete.<P>





<h2>Reducibility</h2><P>
<a name="0a06_1cb8">Intuitively, a problem <I>Q</I> can be reduced to another problem <I>Q</I>' if any instance of <I>Q</I> can be "easily rephrased" as an instance of <I>Q</I>', the solution to which provides a solution to the instance of <I>Q</I>. For example, the problem of solving linear equations in an indeterminate <I>x</I> reduces to the problem of solving quadratic equations. Given an instance <I>ax</I> + <I>b</I> = 0, we transform it to 0<I>x</I><SUP>2</SUP> + <I>ax</I> + <I>b</I> = 0, whose solution provides a solution to <I>ax</I> + <I>b</I> = 0. Thus, if a problem <I>Q</I> reduces to another problem <I>Q</I>', then <I>Q</I> is, in a sense, "no harder to solve" than <I>Q</I>'.<P>
<a name="0a06_1cb9"><a name="0a06_1cba">Returning to our formal-language framework for decision problems, we say that a language <I>L</I><SUB>1</SUB> is <I><B>polynomial-time reducible</I></B> to a language <I>L</I><SUB>2</SUB>, written <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/lteq12.gif"><SUB>P</SUB> <I>L</I><SUB>2</SUB>, if there exists a polynomial-time computable function <I>f </I>: {0, 1}* <IMG SRC="../IMAGES/arrow12.gif"> {0, 1}* such that for all <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}*,<P>
<pre><I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>1 </SUB>if and only if <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>2</SUB> .</sub></sup></pre><P>
<h4><a name="0a06_1cbd">(36.1)<a name="0a06_1cbd"></sub></sup></h4><P>
<a name="0a06_1cbb"><a name="0a06_1cbc">We call the function <I>f</I> the <I><B>reduction function</I></B>, and a polynomial-time algorithm <I>F</I> that computes <I>f</I> is called a<B> </B><I><B>reduction algorithm</I></B><I>.</I><P>
Figure 36.3 illustrates the idea of a polynomial-time reduction from a language <I>L</I><SUB>1</SUB> to another language <I>L</I><SUB>2</SUB>. Each language is a subset of {0, 1}*. The reduction function <I>f</I> provides a polynomial-time mapping such that if <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>1</SUB>, then <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>2</SUB>. Moreover, if <I>x</I> <IMG SRC="../IMAGES/notmem.gif"> <I>L</I><SUB>1</SUB>, then <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/notmem.gif"> <I>L</I><SUB>2</SUB>. Thus, the reduction function maps any instance <I>x</I> of the decision problem represented by the language <I>L</I><SUB>1</SUB> to an instance <I>f</I>(<I>x</I>) of the problem represented by <I>L</I><SUB>2</SUB>. Providing an answer to whether <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>2</SUB> directly provides the answer to whether <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>1</SUB>.<P>
<img src="931_a.gif"><P>
<h4><a name="0a06_1cbe">Figure 36.4 The proof of Lemma 36.3. The algorithm F is a reduction algorithm that computes the reduction function f from L<SUB>1</SUB> to L<SUB>2</SUB> in polynomial time, and A<SUB>2 </SUB>is a polynomial-time algorithm that decides L<SUB>2</SUB>. Illustrated is an algorithm A<SUB>1</SUB> that decides whether x <IMG SRC="../IMAGES/memof12.gif"> L<SUB>1</SUB> by using F to transform any input x into f(x) and then using A<SUB>2</SUB> to decide whether f(x) <IMG SRC="../IMAGES/memof12.gif"> L<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2>.<a name="0a06_1cbe"></FONT></sub></sup></h4><P>
Polynomial-time reductions give us a powerful tool for proving that various languages belong to P.<P>
<a name="0a06_1cbf">Lemma 36.3<a name="0a06_1cbf"><P>
If <I>L</I><SUB>1</SUB>, <I>L</I><SUB>2</SUB> <IMG SRC="../IMAGES/rgtubar.gif"> {0, 1}<SUP>*</SUP> are languages such that <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/lteq12.gif"> <I>L</I><SUB>2</SUB>, then <I>L</I><SUB>2</SUB> <IMG SRC="../IMAGES/memof12.gif"> P implies <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/memof12.gif"> P.<P>
<I><B>Proof</I></B>     Let <I>A</I><SUB>2</SUB> be a polynomial-time algorithm that decides <I>L</I><SUB>2</SUB>, and let <I>F</I> be a polynomial-time reduction algorithm that computes the reduction function <I>f</I>. We shall construct a polynomial-time algorithm <I>A</I><SUB>1</SUB> that decides <I>L</I><SUB>1</SUB>.<P>
Figure 36.4 illustrates the construction of <I>A</I><SUB>1</SUB>. For a given input <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1}*, the algorithm <I>A</I><SUB>1</SUB> uses <I>F</I> to transform <I>x</I> into <I>f</I>(<I>x</I>), and then it uses <I>A</I><SUB>2</SUB> to test whether <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>L</I><SUB>2</SUB>. The output of <I>A</I><SUB>2</SUB> is the value provided as the output from <I>A</I><SUB>1</SUB>.<P>
The correctness of <I>A</I><SUB>1</SUB> follows from condition (36.1). The algorithm runs in polynomial time, since both <I>F</I> and <I>A</I><SUB>2</SUB> run in polynomial time (see Exercise 36.1-6).      <P>
<P>







<h2>NP-completeness</h2><P>
<a name="0a07_1cbd">Polynomial-time reductions provide a formal means for showing that one problem is at least as hard as another, to within a polynomial-time factor. That is, if <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I><SUB>2</SUB>, then <I>L</I><SUB>1</SUB> is not more than a polynomial factor harder than <I>L</I><SUB>2</SUB>, which is why the "less than or equal to" notation for reduction is mnemonic. We can now define the set of NP-complete languages, which are the hardest problems in NP.<P>
A language <I>L</I> <IMG SRC="../IMAGES/rgtubar.gif"> {0, 1}<SUP>*</SUP> is <I><B>NP-complete</I></B> if<P>
1.     <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP, and<P>
2.     <I>L</I>' <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I> for every <I>L</I>' <IMG SRC="../IMAGES/memof12.gif"> NP.<P>
<img src="932_a.gif"><P>
<h4><a name="0a07_1cc1">Figure 36.5 How most theoretical computer scientists view the relationships among P, NP, and NPC. Both P and NPC are wholly contained within NP, and <img src="932_b.gif">.<a name="0a07_1cc1"></sub></sup></h4><P>
<a name="0a07_1cbe"><a name="0a07_1cbf"><a name="0a07_1cc0">If a language <I>L</I> satisfies property 2, but not necessarily property 1, we say that <I>L</I> is <I><B>NP-hard</I></B>. We also define NPC to be the class of NP-complete languages.<P>
As the following theorem shows, NP-completeness is at the crux of deciding whether P is in fact equal to NP.<P>
<a name="0a07_1cc2">Theorem 36.4<a name="0a07_1cc2"><P>
If any NP-complete problem is polynomial-time solvable, then P = NP. If any problem in NP is not polynomial-time solvable, then all NP-complete problems are not polynomial-time solvable.<P>
<I><B>Proof</I></B>     Suppose that <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> P and also that <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NPC. For any <I>L</I>' <IMG SRC="../IMAGES/memof12.gif"> NP, we have <I>L</I>' <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I> by property 2 of the definition of NP-completeness. Thus, by Lemma 36.3, we also have that <I>L</I>' <IMG SRC="../IMAGES/memof12.gif"> P, which proves the first statement of the lemma.<P>
To prove the second statement, suppose that there exists an <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP such that <I>L</I> <IMG SRC="../IMAGES/notmem.gif"> P. Let <I>L</I>' <IMG SRC="../IMAGES/memof12.gif"> NPC be any NP-complete language, and for the purpose of contradiction, assume that <I>L</I>' <IMG SRC="../IMAGES/memof12.gif"> P. But then, by Lemma 36.3, we have <I>L</I> <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I>', and thus <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> P.      <P>
It is for this reason that research into the P <IMG SRC="../IMAGES/noteq.gif"> NP question centers around the NP-complete problems. Most theoretical computer scientists believe that P <IMG SRC="../IMAGES/noteq.gif"> NP, which leads to the relationships among P, NP, and NPC shown in Figure 36.5. But for all we know, someone may come up with a polynomial-time algorithm for an NP-complete problem, thus proving that P = NP. Nevertheless, since no polynomial-time algorithm for any NP-complete problem has yet been discovered, a proof that a problem is NP-compete provides excellent evidence for its intractability.<P>
<P>







<h2>Circuit satisfiability</h2><P>
<a name="0a08_1cc1"><a name="0a08_1cc2">We have defined the notion of an NP-complete problem, but up to this point, we have not actually proved that any problem is NP-complete. Once we prove that at least one problem is NP-complete, we can use polynomial-time reducibility as a tool to prove the NP-completeness of other problems. Thus, we now focus on demonstrating the existence of an NP-complete problem: the circuit-satisfiability problem.<P>
<img src="933_a.gif"><P>
<h4><a name="0a08_1cc9">Figure 36.6 Two instances of the circuit-satisfiability problem. (a) The assignment <IMG SRC="../IMAGES/lftwdchv.gif">x<SUB>1</SUB> = 1, x<SUB>2</SUB> = 1, x<SUB>3</SUB> = 0<IMG SRC="../IMAGES/wdrtchv.gif"> to the inputs of this circuit causes the output of the circuit to be 1. The circuit is therefore satisfiable. (b) No assignment to the inputs of this circuit can cause the output of the circuit to be 1. The circuit is therefore unsatisfiable.<a name="0a08_1cc9"></sub></sup></h4><P>
Unfortunately, the formal proof that the circuit-satisfiability problem is NP-complete requires technical detail beyond the scope of this text. Instead, we shall informally describe a proof that relies on a basic understanding of boolean combinational circuits. This material is reviewed at the beginning of Chapter 29.<P>
<a name="0a08_1cc3"><a name="0a08_1cc4"><a name="0a08_1cc5"><a name="0a08_1cc6"><a name="0a08_1cc7">Figure 36.6 shows two boolean combinational circuits, each with three inputs and a single output. A <I><B>truth assignment</I></B> for a boolean combinational circuit is a set of boolean input values. We say that a one-output boolean combinational circuit is <I><B>satisfiable</I></B> if it has a <I><B>satisfying assignment</I></B>: a truth assignment that causes the output of the circuit to be 1. For example, the circuit in Figure 36.6(a) has the satisfying assignment <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1</SUB> = 1, <I>x</I><SUB>2</SUB> = 1, <I>x</I><SUB>3</SUB> = 0<IMG SRC="../IMAGES/wdrtchv.gif">, and so it is satisfiable. No assignment of values to <I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, and <I>x</I><SUB>3</SUB> causes the circuit in Figure 36.6(b) to produce a 1 output; it always produces 0, and so it is unsatisfiable.<P>
The <I><B>circuit-satisfiability problem</I></B> is, "Given a boolean combinational circuit composed of AND, OR, and NOT gates, is it satisfiable?" In order to pose this question formally, however, we must agree on a standard encoding for circuits. One can devise a graphlike encoding that maps any given circuit <I>C</I> into a binary string <IMG SRC="../IMAGES/lftwdchv.gif"><I>C</I><IMG SRC="../IMAGES/wdrtchv.gif"> whose length is not much larger than the size of the circuit itself. As a formal language, we can therefore define<P>
<pre><a name="0a08_1cc8">CIRCUIT-SAT =</sub></sup></pre><P>
<pre>{<IMG SRC="../IMAGES/lftwdchv.gif"><I>C</I><IMG SRC="../IMAGES/wdrtchv.gif"> : <I>C</I> is a satisfiable boolean combinational circuit} .</sub></sup></pre><P>
The circuit-satisfiability problem has great importance in the area of computer-aided hardware optimization. If a circuit always produces 0, it can be replaced by a simpler circuit that omits all logic gates and provides the constant 0 value as its output. A polynomial-time algorithm for the problem would have considerable practical application.<P>
Given a circuit <I>C</I>, we might attempt to determine whether it is satisfiable by simply checking all possible assignments to the inputs. Unfortunately, if there are <I>k</I> inputs, there are 2<I><SUP>k</I></SUP> possible assignments. When the size of <I>C</I> is polynomial in <I>k</I>, checking each one leads to a superpolynomial-time algorithm. In fact, as has been claimed, there is strong evidence that no polynomial-time algorithm exists that solves the circuit-satisfiability problem because circuit satisfiability is NP-complete. We break the proof of this fact into two parts, based on the two parts of the definition of NP-completeness.<P>
<a name="0a08_1cca">Lemma 36.5<a name="0a08_1cca"><P>
The circuit-satisfiability problem belongs to the class NP.<P>
<I><B>Proof</I></B>     We shall provide a two-input, polynomial-time algorithm <I>A</I> that can verify CIRCUIT-SAT. One of the inputs to <I>A</I> is (a standard encoding of) a boolean combinational circuit <I>C</I>. The other input is a certificate corresponding to an assignment of boolean values to the wires in <I>C</I>.<P>
The algorithm <I>A</I> is constructed as follows. For each logic gate in the circuit, it checks that the value provided by the certificate on the output wire is correctly computed as a function of the values on the input wires. Then, if the output of the entire circuit is 1, the algorithm outputs 1, since the values assigned to the inputs of <I>C</I> provide a satisfying assignment. Otherwise, <I>A</I> outputs 0.<P>
Whenever a satisfiable circuit <I>C</I> is input to algorithm <I>A</I>, there is a certificate whose length is polynomial in the size of <I>C</I> and that causes <I>A</I> to output a 1. Whenever an unsatisfiable circuit is input, no certificate can fool <I>A </I>into believing that the circuit is satisfiable. Algorithm <I>A</I> runs in polynomial time: with a good implementation, linear time suffices. Thus, CIRCUIT-SAT can be verified in polynomial time, and CIRCUIT-SAT <IMG SRC="../IMAGES/memof12.gif"> NP.      <P>
The second part of proving that CIRCUIT-SAT is NP-complete is to show that the language is NP-hard. That is, we must show that every language in NP is polynomial-time reducible to CIRCUIT-SAT. The actual proof of this fact is full of technical intricacies, and so we shall settle for a sketch of the proof based on some understanding of the workings of computer hardware.<P>
A computer program is stored in the computer memory as a sequence of instructions. A typical instruction encodes an operation to be performed, addresses of operands in memory, and an address where the result is to be stored. A special memory location, called the <I><B>program counter</I></B>, keeps track of which instruction is to be executed next. The program counter is automatically incremented whenever an instruction is fetched, thereby causing the computer to execute instructions sequentially. The execution of an instruction can cause a value to be written to the program counter, however, and then the normal sequential execution can be altered, allowing the computer to loop and perform conditional branches.<P>
At any point during the execution of a program, the entire state of the computation is represented in the computer's memory. (We take the memory to include the program itself, the program counter, working storage, and any of the various bits of state that a computer maintains for bookkeeping.) We call any particular state of computer memory a <I><B>configuration</I></B>. The execution of an instruction can be viewed as mapping one configuration to another. Importantly, the computer hardware that accomplishes this mapping can be implemented as a boolean combinational circuit, which we denote by <I>M</I> in the proof of the following lemma.<P>
<a name="0a08_1ccb">Lemma 36.6<a name="0a08_1ccb"><P>
The circuit-satisfiability problem is NP-hard.<P>
<I><B>Proof</I></B>     Let <I>L</I> be any language in NP. We shall describe a polynomial-time algorithm <I>F</I> computing a reduction function &acirc; that maps every binary string <I>x</I> to a circuit <I>C = &acirc;</I>(<I>x</I>) such that <I>x </I><IMG SRC="../IMAGES/memof12.gif"> L<I> if and only if </I>C <I><IMG SRC="../IMAGES/memof12.gif"> </I>CIRCUIT-SAT.<P>
Since <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP, there must exist an algorithm <I>A</I> that verifies <I>L</I> in polynomial-time. The algorithm <I>F</I> that we shall construct will use the two-input algorithm <I>A</I> to compute the reduction function &acirc;.<P>
Let <I>T</I>(<I>n</I>) denote the worst-case running time of algorithm <I>A</I> on length-<I>n </I>input strings, and let <I>k</I> <IMG SRC="../IMAGES/gteq.gif"> 1 be a constant such that <I>T</I>(<I>n</I>)<I> = O</I>(<I>n<SUP>k</I></SUP>) and the length of the certificate is <I>O</I>(<I>n<SUP>k</I></SUP>). (The running time of <I>A</I> is actually a polynomial in the total input size, which includes both an input string and a certificate, but since the length of the certificate is polynomial in the length <I>n</I> of the input string, the running time is polynomial in <I>n</I>.)<P>
The basic idea of the proof is to represent the computation of <I>A</I> as a sequence of configurations. As shown in Figure 36.7, each configuration can be broken into parts consisting of the program for <I>A</I>, the program counter and auxiliary machine state, the input <I>x</I>, the certificate <I>y</I>, and working storage. Starting with an initial configuration <I>c</I><SUB>0</SUB>, each configuration <I>c<SUB>i</I></SUB> is mapped to a subsequent configuration <I>c<SUB>i+</I>1</SUB> by the combinational circuit <I>M </I>implementing the computer hardware. The output of the algorithm <I>A</I>--0 or 1--is written to some designated location in the working storage when <I>A</I> finishes executing, and if we assume that thereafter <I>A</I> halts, the value never changes. Thus, if the algorithm runs for at most <I>T</I>(<I>n</I>) steps, the output appears as one of the bits in <I>c<SUB>T</I>(<I>n</I>)</SUB>.<P>
<img src="936_a.gif"><P>
<h4><a name="0a08_1ccc">Figure 36.7 The sequence of configurations produced by an algorithm A running on an input x and certificate y. Each configuration represents the state of the computer for one step of the computation and, besides A, x, and y, includes the program counter (PC), auxiliary machine state, and working storage. Except for the certificate y, the initial configuration c<SUB>0</SUB> is constant. Each configuration is mapped to the next configuration by a boolean combinational circuit M. The output is a distinguished bit in the working storage.<a name="0a08_1ccc"></sub></sup></h4><P>
The reduction algorithm <I>F</I> constructs a single combinational circuit that computes all configurations produced by a given initial configuration. The idea is to paste together <I>T</I>(<I>n</I>) copies of the circuit <I>M</I>. The output of the <I>i</I>th circuit, which produces configuration <I>c<SUB>i</I></SUB>, is fed directly into the input of the (<I>i</I> + 1)st circuit. Thus, the configurations, rather than ending up in a state register, simply reside as values on the wires connecting copies of <I>M</I>.<P>
Recall what the polynomial-time reduction algorithm <I>F</I> must do. Given an input <I>x</I>, it must compute a circuit <I>C = &acirc;</I>(<I>x</I>) that is satisfiable if and only if there exists a certificate <I>y</I> such that <I>A</I>(<I>x</I>,<I> y</I>) = 1. When <I>F </I>obtains an input <I>x</I>, it first computes <I>n = |x|</I> and constructs a combinational circuit <I>C</I><I>'</I> consisting of <I>T</I>(<I>n</I>) copies of <I>M</I>. The input to <I>C</I><I>'</I> is an initial configuration corresponding to a computation on <I>A</I>(<I>x, y</I>), and the output is the configuration <I>c<SUB>T</I>(<I>n</I>)</SUB>.<P>
The circuit <I>C = <FONT FACE="CG Times (W1)" SIZE=2>&acirc;</I></FONT>(<I>x</I>) that <I>F</I> computes is obtained by modifying <I>C</I>' <I>slightly. First, the inputs to </I>C<I>'</I> corresponding to the program for <I>A</I>, the initial program counter, the input <I>x</I>, and the initial state of memory are wired directly to these known values. Thus, the only remaining inputs to the circuit correspond to the certificate <I>y</I>. Second, all outputs to the circuit are ignored, except the one bit of <I>c<SUB>T</I>(<I>n</I>)</SUB> corresponding to the output of <I>A</I>. This circuit <I>C</I>, so constructed, computes <I>C</I>(<I>y</I>)<I> = A</I>(<I>x, y</I>) for any input <I>y</I> of length <I>O</I>(<I>n<SUP>k</I></SUP>). The reduction algorithm <I>F</I>, when provided an input string <I>x</I>, computes such a circuit <I>C</I> and outputs it.<P>
Two properties remain to be proved. First, we must show that <I>F </I>correctly computes a reduction function <FONT FACE="CG Times (W1)" SIZE=2>&acirc;</FONT>. That is, we must show that <I>C</I> is satisfiable if and only if there exists a certificate <I>y</I> such that <I>A</I>(<I>x, y</I>) = 1. Second, we must show that <I>F</I> runs in polynomial time.<P>
To show that <I>F</I> correctly computes a reduction function, let us suppose that there exists a certificate <I>y</I> of length <I>O</I>(<I>n<SUP>k</I></SUP>) such that <I>A</I>(<I>x, y</I>) = 1. Then, if we apply the bits of <I>y</I> to the inputs of <I>C</I>, the output of <I>C</I> is <I>C</I>(<I>y</I>)<I> = A</I>(<I>x, y</I>) = 1. Thus, if a certificate exists, then <I>C</I> is satisfiable. For the other direction, suppose that <I>C</I> is satisfiable. Hence, there exists an input <I>y</I> to <I>C</I> such that <I>C</I>(<I>y</I>) = 1, from which we conclude that <I>A</I>(<I>x, y</I>) = 1. Thus, <I>F</I> correctly computes a reduction function.<P>
To complete the proof, we need only show that <I>F</I> runs in time polynomial in <I>n = </I>|<I>x</I><FONT FACE="CG Times (W1)" SIZE=2>|</FONT>. The first observation we make is that the number of bits required to represent a configuration is polynomial in <I>n</I>. The program for <I>A</I> itself has constant size, independent of the length of its input <I>x</I>. The length of the input <I>x</I> is <I>n</I>, and the length of the certificate <I>y</I> is <I>O</I>(<I>n<SUP>k</I></SUP>). Since the algorithm runs for at most <I>O</I>(<I>n<SUP>k</I></SUP>) steps, the amount of working storage required by <I>A</I> is polynomial in <I>n</I> as well. (We assume that this memory is contiguous; Exercise 36.3-4 asks you to extend the argument to the situation in which the locations accessed by <I>A</I> are scattered across a much larger region of memory and the particular pattern of scattering can differ for each input <I>x</I>.)<P>
The combinational circuit <I>M</I> implementing the computer hardware has size polynomial in the length of a configuration, which is polynomial in <I>O</I>(<I>n<SUP>k</I></SUP>) and hence is polynomial in <I>n</I>. (Most of this circuitry implements the logic of the memory system.) The circuit <I>C</I> consists of at most <I>t = O</I>(<I>n<SUP>k</I></SUP>) copies of <I>M</I>, and hence it has size polynomial in <I>n</I>. The construction of <I>C</I> from <I>x</I> can be accomplished in polynomial time by the reduction algorithm <I>F</I>, since each step of the construction takes polynomial time.      <P>
The language CIRCUIT-SAT is therefore at least as hard as any language in NP, and since it belongs to NP, it is NP-complete.<P>
<a name="0a08_1ccd">Theorem 36.7<a name="0a08_1ccd"><P>
The circuit-satisfiability problem is NP-complete.<P>
<I><B>Proof</I></B>     Immediate from Lemmas 36.5 and 36.6 and the definition of NP-completeness.      <P>
<P>







<h2><a name="0a09_1ccb">Exercises<a name="0a09_1ccb"></h2><P>
<a name="0a09_1ccc">36.3-1<a name="0a09_1ccc"><P>
Show that the <IMG SRC="../IMAGES/lteq12.gif"><FONT FACE="Courier New" SIZE=2>p</FONT> relation is a transitive relation on languages. That is, show that if <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/lteq12.gif"><FONT FACE="Courier New" SIZE=2>p</FONT> <I>L</I><SUB>2</SUB> and <I>L</I><SUB>2</SUB> <IMG SRC="../IMAGES/lteq12.gif"><FONT FACE="Courier New" SIZE=2>p</FONT> <I>L</I><SUB>3</SUB>, then <I>L</I><SUB>1</SUB> <IMG SRC="../IMAGES/lteq12.gif"><FONT FACE="Courier New" SIZE=2>p</FONT> <I>L</I><SUB>3</SUB>.<P>
<a name="0a09_1ccd">36.3-2<a name="0a09_1ccd"><P>
Prove that <img src="938_a.gif"> if and only if <img src="938_b.gif">.<P>
<a name="0a09_1cce">36.3-3<a name="0a09_1cce"><P>
Show that a satisfying assignment can be used as a certificate in an alternative proof of Lemma 36.5. Which certificate makes for an easier proof?<P>
<a name="0a09_1ccf">36.3-4<a name="0a09_1ccf"><P>
The proof of Lemma 36.6 assumes that the working storage for algorithm <I>A </I>occupies a contiguous region of polynomial size. Where in the proof is this assumption exploited? Argue that this assumption does not involve any loss of generality.<P>
<a name="0a09_1cd0">36.3-5<a name="0a09_1cd0"><P>
<a name="0a09_1cc9"><a name="0a09_1cca">A language <I>L</I> is <I><B>complete</I></B> for a language class <I>C</I> with respect to polynomial-time reductions if <I>L </I><IMG SRC="../IMAGES/memof12.gif"> C<I> and </I>L<I>' </I><IMG SRC="../IMAGES/lteq12.gif"><I><FONT FACE="Courier New" SIZE=2>p</I> L</FONT><I> for all </I>L<I>'<IMG SRC="../IMAGES/memof12.gif"> C</I>. Show that <img src="938_c.gif"> and {0, 1}* are the only languages in P that are not complete for P with respect to polynomial-time reductions.<P>
<a name="0a09_1cd1">36.3-6<a name="0a09_1cd1"><P>
Show that <I>L</I> is complete for NP if and only if <img src="939_a.gif"> is complete for co-NP.<P>
<a name="0a09_1cd2">36.3-7<a name="0a09_1cd2"><P>
The reduction algorithm <I>F</I> in the proof of Lemma 36.6 constructs the circuit <I>C</I> = <I>f</I>(<I>x</I>) based on knowledge of <I>x</I>, <I>A</I>, and <I>k</I>. Professor Sartre observes that the string <I>x</I> is input to <I>F</I>, but only the existence of <I>A</I> and <I>k</I> is known to <I>F</I> (since the language <I>L</I> belongs to NP), not their actual values. Thus, the professor concludes that <I>F</I> can't possibly construct the circuit <I>C</I> and that the language CIRCUIT-SAT is not necessarily NP-hard. Explain the flaw in the professor's reasoning.<P>
<P>


<P>







<h1><a name="0a0a_1ccd">36.4 NP-completeness proofs<a name="0a0a_1ccd"></h1><P>
<a name="0a0a_1ccb"><a name="0a0a_1ccc">The NP-completeness of the circuit-satisfiability problem relies on a direct proof that <I>L</I> <IMG SRC="../IMAGES/lteq12.gif"><SUB>P</SUB> CIRCUIT-SAT for every language <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP. In this section, we shall show how to prove that languages are NP-complete without directly reducing <I>every</I> language in NP to the given language. We shall illustrate this methodology by proving that various formula-satisfiability problems are NP-complete. Section 36.5 provides many more examples of the methodology.<P>
The following lemma is the basis of our method for showing that a language is NP-complete.<P>
<a name="0a0a_1cce">Lemma 36.8<a name="0a0a_1cce"><P>
If <I>L</I> is a language such that <I>L</I><I>'</I> <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I> for some <I>L</I><I>' <IMG SRC="../IMAGES/memof12.gif"> </I>NPC, then <I>L</I> is NP-hard. Moreover, if <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP, then <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NPC.<P>
<I><B>Proof</I></B>     Since <I>L</I>' is NP-complete, for all <I>L</I>\" <IMG SRC="../IMAGES/memof12.gif"> NP, we have <I>L</I>\" <IMG SRC="../IMAGES/lteq12.gif">p <I>L</I>'. By supposition, <I>L</I>' <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I>, and thus by transitivity (Exercise 36.3-1), we have <I>L</I>\" <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> <I>L</I>, which shows that <I>L</I> is NP-hard. If <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP, we also have <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NPC.      <P>
In other words, by reducing a known NP-complete language <I>L</I>' to <I>L</I>, we implicitly reduce every language in NP to <I>L</I>. Thus, Lemma 36.8 gives us a method for proving that a language <I>L</I> is NP-complete:<P>
1.     Prove <I>L</I> <IMG SRC="../IMAGES/memof12.gif"> NP.<P>
2.     Select a known NP-complete language <I>L</I>'.<P>
3.     Describe an algorithm that computes a function <I>f</I> mapping every instance of <I>L</I>' to an instance of <I>L</I>.<P>
4.     Prove that the function <I>f</I> satisfies <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> <I>L</I>' if and only if <I>f</I>(<I>x</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>L</I> for all <I>x</I> <IMG SRC="../IMAGES/memof12.gif"> {0, 1 }<SUP>*</SUP>.<P>
5.     Prove that the algorithm computing <I>f</I> runs in polynomial time.<P>
This methodology of reducing from a single known NP-complete language is far simpler than the more complicated process of providing reductions from every language in NP. Proving CIRCUIT-SAT <IMG SRC="../IMAGES/memof12.gif"> NPC has given us a "foot in the door." Knowing that the circuit-satisfiability problem is NP-complete now allows us to prove much more easily that other problems are NP-complete. Moreover, as we develop a catalog of known NP-complete problems, applying the methodology will become that much easier.<P>





<h2>Formula satisfiability</h2><P>
<a name="0a0b_1ccd"><a name="0a0b_1cce"><a name="0a0b_1ccf">We illustrate the reduction methodology by giving an NP-completeness proof for the problem of determining whether a boolean formula, not a circuit, is satisfiable. This problem has the historical honor of being the first problem ever shown to be NP-complete.<P>
<a name="0a0b_1cd0">We formulate the <I><B>(formula)</I></B> <I><B>satisfiability</I></B> problem in terms of the language SAT as follows. An instance of SAT is a boolean formula <IMG SRC="../IMAGES/phicap12.gif"><I> composed of</I><P>
1.     boolean variables: <I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . . ;<P>
<a name="0a0b_1cd1"><a name="0a0b_1cd2">2.     boolean connectives: any boolean function with one or two inputs and one output, such as <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> (AND), <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> (OR), <IMG SRC="../IMAGES/rtdwnbrc.gif"> (NOT), <IMG SRC="../IMAGES/arrow12.gif"> (implication), <IMG SRC="../IMAGES/dblarr12.gif"> (if and only if); and<P>
3.     parentheses.<P>
<a name="0a0b_1cd3"><a name="0a0b_1cd4"><a name="0a0b_1cd5"><a name="0a0b_1cd6"><a name="0a0b_1cd7">As in boolean combinational circuits, a <I><B>truth assignment</I></B> for a boolean formula <IMG SRC="../IMAGES/phicap12.gif"><I> is a set of values for the variables of <IMG SRC="../IMAGES/phicap12.gif"></I>, and a <I><B>satisfying assignment </I></B>is a truth assignment that causes it to evaluate to 1. A formula with a satisfying assignment is a<I><B> satisfiable</I></B> formula. The satisfiability problem asks whether a given boolean formula is satisfiable; in formal-language terms,<P>
<pre><a name="0a0b_1cd8">SAT = {<IMG SRC="../IMAGES/lftwdchv.gif"><IMG SRC="../IMAGES/phicap12.gif"><I><IMG SRC="../IMAGES/wdrtchv.gif">: <IMG SRC="../IMAGES/phicap12.gif"></I> is a satisfiable boolean formula} .</sub></sup></pre><P>
As an example, the formula<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"> = ((<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/arrow12.gif"> <I>x</I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">((<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> <I>x</I><SUB>3</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>4</SUB>)) <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</sub></sup></pre><P>
has the satisfying assignment <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1 </SUB>= 0, <I>x</I><SUB>2 </SUB>= 0, <I>x</I><SUB>3 </SUB>= 1, <I>x</I><SUB>4 </SUB>= 1<IMG SRC="../IMAGES/wdrtchv.gif">, since<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"> = ((0 <IMG SRC="../IMAGES/arrow12.gif"> 0) <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">((<IMG SRC="../IMAGES/rtdwnbrc.gif">0 <IMG SRC="../IMAGES/dblarr12.gif"> 1) <IMG SRC="../IMAGES/angledwn.gif"> 1)) <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">0</sub></sup></pre><P>
<pre>= (1 <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">(1 <IMG SRC="../IMAGES/angledwn.gif"> 1)) <IMG SRC="../IMAGES/angleup.gif"> 1</sub></sup></pre><P>
<pre>= (1 <IMG SRC="../IMAGES/angledwn.gif"> 0) <IMG SRC="../IMAGES/angleup.gif"> 1</sub></sup></pre><P>
<pre>= 1 ,</sub></sup></pre><P>
<h4><a name="0a0b_1cd9">(36.2)<a name="0a0b_1cd9"></sub></sup></h4><P>
and thus this formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> belongs to SAT.<P>
The naive algorithm to determine whether an arbitrary boolean formula is satisfiable does not run in polynomial time. There are 2<I><SUP>n</I></SUP> possible assignments in a formula <IMG SRC="../IMAGES/phicap12.gif"><I> with</I> n<I> variables. If the length of <IMG SRC="../IMAGES/lftwdchv.gif"><IMG SRC="../IMAGES/phicap12.gif"></I><IMG SRC="../IMAGES/wdrtchv.gif"> is polynomial in <I>n</I>, then checking every assignment requires superpolynomial time. As the following theorem shows, a polynomial-time algorithm is unlikely to exist.<P>
<img src="941_a.gif"><P>
<h4><a name="0a0b_1cda">Figure 36.8 Reducing circuit satisfiability to formula satisfiability. The formula produced by the reduction algorithm has a variable for each wire in the circuit.<a name="0a0b_1cda"></sub></sup></h4><P>
<a name="0a0b_1cdb">Theorem 36.9<a name="0a0b_1cdb"><P>
Satisfiability of boolean formulas is NP-complete.<P>
<I><B>Proof</I></B>     We shall argue first that SAT <IMG SRC="../IMAGES/memof12.gif"> NP. Then, we shall show that CIRCUIT-SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> SAT; by Lemma 36.8, this will prove the theorem.<P>
To show that SAT belongs to NP, we show that a certificate consisting of a satisfying assignment for an input formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> can be verified in polynomial time. The verifying algorithm simply replaces each variable in the formula with its corresponding value and then evaluates the expression, much as we did in equation (36.2) above. This task is easily doable in polynomial time. If the expression evaluates to 1, the formula is satisfiable. Thus, the first condition of Lemma 36.8 for NP-completeness holds.<P>
To prove that SAT is NP-hard, we show that CIRCUIT-SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> SAT. In other words, any instance of circuit satisfiability can be reduced in polynomial time to an instance of formula satisfiability. Induction can be used to express any boolean combinational circuit as a boolean formula. We simply look at the gate that produces the circuit output and inductively express each of the gate's inputs as formulas. The formula for the circuit is then obtained by writing an expression that applies the gate's function to its inputs' formulas.<P>
Unfortunately, this straightforward method does not constitute a polynomial-time reduction. Shared subformulas can cause the size of the generated formula to grow exponentially (see Exercise 36.4-1). Thus, the reduction algorithm must be somewhat more clever.<P>
Figure 36.8 illustrates the basic idea of the reduction from CIRCUIT-SAT to SAT on the circuit from Figure 36.6(a). For each wire <I>x<SUB>i</I></SUB> in the circuit <I>C</I>, the formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> has a variable <I>x<SUB>i</I></SUB>. The proper operation of a gate can now be expressed as a formula involving the variables of its incident wires. For example, the operation of the output AND gate is <I>x</I><SUB>10</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>7</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> <I>x</I><SUB>8 </SUB><FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> <I>x</I><SUB>9</SUB>).<P>
The formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> produced by the reduction algorithm is the AND of the circuit-output variable with the conjunction of clauses describing the operation of each gate. For the circuit in the figure, the formula is<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"> <I> =  </I>x<I><SUB>10</SUB> <IMG SRC="../IMAGES/angleup.gif"> (</I>x<I><SUB>4</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"></I>x<I><SUB>3</SUB>)</I></sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>5 </SUB><IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>2))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>6 </SUB><IMG SRC="../IMAGES/dblarr12.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>4)</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>7 </SUB><IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>4))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>8 </SUB><IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>5</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>6</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>9</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>6</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>7</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>10</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>7</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>8</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>9</SUB>)) .</sub></sup></pre><P>
Given a circuit <I>C</I>, it is straightforward to produce such a formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> in polynomial time.<P>
Why is the circuit <IMG SRC="../IMAGES/phicap12.gif"><I></I> satisfiable exactly when the formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> is satisfiable? If<I> C</I> has a satisfying assignment, each wire of the circuit has a well-defined value, and the output of the circuit is 1. Therefore, the assignment of wire values to variables in <IMG SRC="../IMAGES/phicap12.gif"><I></I> makes each clause of <IMG SRC="../IMAGES/phicap12.gif"><I></I> evaluate to 1, and thus the conjunction of all evaluates to 1. Conversely, if there is an assignment that causes <IMG SRC="../IMAGES/phicap12.gif"><I></I> to evaluate to 1, the circuit <I>C</I> is satisfiable by an analogous argument. Thus, we have shown that CIRCUIT-SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> SAT, which completes the proof.      <P>
<P>







<h2>3-CNF satisfiability</h2><P>
<a name="0a0c_1cd9"><a name="0a0c_1cda"><a name="0a0c_1cdb"><a name="0a0c_1cdc">Many problems can be proved NP-complete by reduction from formula satisfiability. The reduction algorithm must handle any input formula, though, and this can lead to a huge number of cases that must be considered. It is often desirable, therefore, to reduce from a restricted language of boolean formulas, so that fewer cases need be considered. Of course, we must not restrict the language so much that it becomes polynomial-time solvable. One convenient language is 3-CNF satisfiability, or 3-CNF-SAT.<P>
<a name="0a0c_1cdd"><a name="0a0c_1cde"><a name="0a0c_1cdf"><a name="0a0c_1ce0">We define 3-CNF satisfiability using the following terms. A<I><B> literal</I></B> in a boolean formula is an occurrence of a variable or its negation. A boolean formula is in <I><B>conjunctive normal form</I></B>, or <I><B>CNF</I></B>, if it is expressed as an AND of clauses, each of which is the OR of one or more literals. A boolean formula is in <I><B>3-conjunctive normal form</I></B>, or <I><B>3-CNF</I></B>, if each clause has exactly three distinct literals.<P>
For example, the boolean formula<P>
<pre>(<I>x</I><SUB>1 </SUB><IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1 </SUB><IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB>) <IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>3</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>4</SUB>) <IMG SRC="../IMAGES/angleup.gif"> (<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>3 </SUB><IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>4</SUB>)</sub></sup></pre><P>
is in 3-CNF. The first of its three clauses is (<I>x</I><SUB>1 </SUB><FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT><I>x</I><SUB>1 </SUB><FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"><SUB> </SUB><IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT><I>x</I><SUB>2 </SUB>), which contains the three literals <I>x</I><SUB>1</SUB>, <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1</SUB>, and <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB>.<P>
In 3-CNF-SAT, we are asked whether a given boolean formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> in 3-CNF is satisfiable. The following theorem shows that a polynomial-time algorithm that can determine the satisfiability of boolean formulas is unlikely to exist, even when they are expressed in this simple normal form.<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"><I> = ((</I>x<I><SUB>1</SUB> <IMG SRC="../IMAGES/arrow12.gif"> </I>x<I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">((<IMG SRC="../IMAGES/rtdwnbrc.gif"></I>x<I><SUB>1</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> </I>x<I><SUB>3</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> </I>x<I><SUB>4</SUB>)) <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"></I>x<I><SUB>2 .</I></sub></sup></pre><P>
<img src="943_a.gif"><P>
<h4><a name="0a0c_1ce5">Figure 36.9 The tree corresponding to the formula<a name="0a0c_1ce5"></sub></sup></h4><P>
<a name="0a0c_1ce6">Theorem 36.10<a name="0a0c_1ce6"><P>
Satisfiability of boolean formulas in 3-conjunctive normal form is NP-complete.<P>
<I><B>Proof</I></B>     The argument we used in the proof of Theorem 36.9 to show that SAT <IMG SRC="../IMAGES/memof12.gif"> NP applies equally well here to show that 3-CNF-SAT <IMG SRC="../IMAGES/memof12.gif"> NP. Thus, we need only show that 3-CNF-SAT is NP-hard. We prove this by showing that SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> 3-CNF-SAT, from which the proof will follow by Lemma 36.8.<P>
The reduction algorithm can be broken into three basic steps. Each step progressively transforms the input formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> closer to the desired 3-conjunctive normal form.<P>
<a name="0a0c_1ce1"><a name="0a0c_1ce2">The first step is similar to the one used to prove CIRCUIT-SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>p </SUB>SAT in Theorem 36.9. First, we construct a binary "parse" tree for the input formula <IMG SRC="../IMAGES/phicap12.gif"><I></I>, with literals as leaves and connectives as internal nodes. Figure 36.9 shows such a parse tree for the formula<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"><I> = ((</I>x<I><SUB>1</SUB> <IMG SRC="../IMAGES/arrow12.gif"> </I>x<I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">((<IMG SRC="../IMAGES/rtdwnbrc.gif"></I>x<I><SUB>1</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> </I>x<I><SUB>3</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> </I>x<I><SUB>4</SUB>)) <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"></I>x<I><SUB>2 </SUB>.</I></sub></sup></pre><P>
<h4><a name="0a0c_1ce7">(36.3)<a name="0a0c_1ce7"></sub></sup></h4><P>
Should the input formula contain a clause such as the OR of several literals, associativity can be used to parenthesize the expression fully so that every internal node in the resulting tree has 1 or 2 children. The binary parse tree can now be viewed as a circuit for computing the function.<P>
Mimicking the reduction in the proof of Theorem 36.9, we introduce a variable <I>y<SUB>i</I></SUB> for the output of each internal node. Then, we rewrite the original formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> as the AND of the root variable and a conjunction of clauses describing the operation of each node. For the formula (36.3), the resulting expression is<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"><I>' </I>= <I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>y3</I> <IMG SRC="../IMAGES/angledwn.gif"> <I>y</I><SUB>4</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>3</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/arrow12.gif"> <I>x</I><SUB>2</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>4</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>y</I><SUB>5</SUB>)</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>5</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<I>y</I><SUB>6</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>y</I><SUB>4</SUB>))</sub></sup></pre><P>
<pre><IMG SRC="../IMAGES/angleup.gif"> (<I>y</I><SUB>6</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> (<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/dblarr12.gif"> <I>x</I><SUB>3</SUB>)).</sub></sup></pre><P>
Observe that the formula <IMG SRC="../IMAGES/phicap12.gif"><I></I>' thus obtained is a conjunction of clauses <img src="944_a.gif">,<SUB> </SUB>each of which has at most 3 literals. The only additional requirement is that each clause be an OR of literals.<P>
<pre><I>y</I><SUB>1</SUB><B>  </B><I>y</I><SUB>2</SUB><B>  </B><I>x</I><SUB>2</SUB><B>  (</B><I>y</I><SUB>1</SUB><B> </B><IMG SRC="../IMAGES/dblarr12.gif"> (<B><I>y</I><SUB>2</SUB></B> <B><IMG SRC="../IMAGES/angleup.gif"></B> <B><IMG SRC="../IMAGES/rtdwnbrc.gif"></B><I>x</I><SUB>2</SUB><B>))</B></sub></sup></pre><P>
<pre>------------------------------</sub></sup></pre><P>
<pre>1   1   1           0</sub></sup></pre><P>
<pre>1   1   0           1</sub></sup></pre><P>
<pre>1   0   1           0</sub></sup></pre><P>
<pre>1   0   0           0</sub></sup></pre><P>
<pre>0   1   1           1</sub></sup></pre><P>
<pre>0   1   0           0</sub></sup></pre><P>
<pre>0   0   1           1</sub></sup></pre><P>
<pre>0   0   0           1</sub></sup></pre><P>
<h4><a name="0a0c_1ce8">Figure 36.10 The truth table for the clause (y<SUB>1</SUB><FONT FACE="Times New Roman" SIZE=2> <IMG SRC="../IMAGES/dblarr12.gif"> (y<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>2</SUB>))<FONT FACE="Times New Roman" SIZE=2>.<a name="0a0c_1ce8"></FONT></FONT></FONT></sub></sup></h4><P>
<a name="0a0c_1ce3"><a name="0a0c_1ce4">The second step of the reduction converts each clause <img src="944_b.gif"> into conjunctive normal form. We construct a truth table for <img src="944_c.gif"> by evaluating all possible assignments to its variables. Each row of the truth table consists of a possible assignment of the variables of the clause, together with the value of the clause under that assignment. Using the truth-table entries that evaluate to 0, we build a formula in <I><B>disjunctive normal form</I></B> (or <I><B>DNF</I></B>)--an OR of AND's--that is equivalent to <img src="944_d.gif">. We then convert this formula into a CNF formula <img src="944_e.gif"> by using DeMorgan's laws (5.2) to complement all literals and change OR's into AND's and AND's into OR's.<P>
In our example, we convert the clause <img src="944_f.gif"> into CNF as follows. The truth table for <IMG SRC="../IMAGES/phicap12.gif"><I>'<SUB>i</I></SUB> is given in Figure 36.10. The DNF formula equivalent to <img src="944_g.gif"><P>
<pre>(<I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> (<I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>x</I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> (<I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB>) <IMG SRC="../IMAGES/angledwn.gif"> (<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>y</I><SUB>1</SUB> <IMG SRC="../IMAGES/angleup.gif"> <I>y</I><SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB>) .</sub></sup></pre><P>
Applying DeMorgan's laws, we get the CNF formula<P>
<img src="944_h.gif"><P>
which is equivalent to the original clause <img src="944_i.gif">.<P>
Each clause <img src="944_j.gif"> of the formula <IMG SRC="../IMAGES/phicap12.gif"><I></I>' has now been converted into a CNF formula <img src="944_k.gif">, and thus <IMG SRC="../IMAGES/phicap12.gif"><I>'</I> is equivalent to the CNF formula <IMG SRC="../IMAGES/phicap12.gif"><I>\"</I> consisting of the conjunction of the <img src="945_a.gif">. Moreover, each clause of <IMG SRC="../IMAGES/phicap12.gif">\"<I> has at most 3 literals.</I><P>
The third and final step of the reduction further transforms the formula so that each clause has <I>exactly</I> 3 distinct literals. The final 3-CNF formula <IMG SRC="../IMAGES/phicap12.gif">''' is constructed from the clauses of the CNF formula <IMG SRC="../IMAGES/phicap12.gif"><I>\"</I>. It also uses two auxiliary variables that we shall call <I>p</I> and <I>q</I>. For each clause <I>C<SUB>i</I> </SUB>of <IMG SRC="../IMAGES/phicap12.gif"><I>\"</I>, we include the following clauses in <IMG SRC="../IMAGES/phicap12.gif">''':<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     </FONT>If <I>C<SUB>i</I></SUB> has 3 distinct literals, then simply include <I>C<SUB>i</I></SUB> as a clause of <IMG SRC="../IMAGES/phicap12.gif">'''.<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif"></FONT>     If <I>C<SUB>i</I></SUB> has 2 distinct literals, that is, if <I>Ci</I> = (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB>), where <I>l</I><SUB>1</SUB> and <I>l</I><SUB>2 </SUB>are literals, then include (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>p</I>) <IMG SRC="../IMAGES/angleup.gif"> (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"> <I>p</I>) as clauses of <I>f</I>(<IMG SRC="../IMAGES/phicap12.gif">). The literals <I>p</I> and <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>p</I> merely fulfill the syntactic requirement that there be exactly 3 distinct literals per clause: (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>p</I>) <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"> <I>p</I>) is equivalent to (<I>l</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>l</I><SUB>2</SUB>) whether <I>p</I> = 0 or <I>p</I> = 1.<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif">     </FONT>If <I>C<SUB>i</I></SUB> has just 1 distinct literal <I>l</I>, then include (<I>l</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>p</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>q</I>) <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> (<I>l</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>p</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"> <I>q</I>) <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> (<I>l</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"> <I>p</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>q</I>) <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> (<I>l</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>p</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>q</I>) as clauses of <IMG SRC="../IMAGES/phicap12.gif">'''. Note that every setting of <I>p</I> and <I>q</I> causes the conjunction of these four clauses to evaluate to <I>l</I>.<P>
We can see that the 3-CNF formula <IMG SRC="../IMAGES/phicap12.gif">''' is satisfiable if and only if <IMG SRC="../IMAGES/phicap12.gif"> is satisfiable by inspecting each of the three steps. Like the reduction from CIRCUIT-SAT to SAT, the construction of <IMG SRC="../IMAGES/phicap12.gif">' from <IMG SRC="../IMAGES/phicap12.gif"> in the first step preserves satisfiability. The second step produces a CNF formula <IMG SRC="../IMAGES/phicap12.gif">\" <I>that is algebraically equivalent to <IMG SRC="../IMAGES/phicap12.gif">'. The third step produces a 3-CNF formula <IMG SRC="../IMAGES/phicap12.gif">''' that is effectively equivalent to <IMG SRC="../IMAGES/phicap12.gif">\"</I>, since any assignment to the variables <I>p</I> and <I>q</I> produces a formula that is algebraically equivalent to <IMG SRC="../IMAGES/phicap12.gif">\"<I>.</I><P>
We must also show that the reduction can be computed in polynomial time. Constructing <IMG SRC="../IMAGES/phicap12.gif">' from <IMG SRC="../IMAGES/phicap12.gif"> introduces at most 1 variable and 1 clause per connective in <IMG SRC="../IMAGES/phicap12.gif">. Constructing <IMG SRC="../IMAGES/phicap12.gif">\" from <IMG SRC="../IMAGES/phicap12.gif">' can introduce at most 8 clauses into <IMG SRC="../IMAGES/phicap12.gif">\"<I></I> for each clause from <IMG SRC="../IMAGES/phicap12.gif">', since each clause of <IMG SRC="../IMAGES/phicap12.gif">' has at most 3 variables, and the truth table for each clause has at most 2<SUP>3</SUP> = 8 rows. The construction of <IMG SRC="../IMAGES/phicap12.gif">''' from <IMG SRC="../IMAGES/phicap12.gif">\"<I></I> introduces at most 4 clauses into <IMG SRC="../IMAGES/phicap12.gif">''' for each clause of <IMG SRC="../IMAGES/phicap12.gif">\"<I></I>. Thus, the size of the resulting formula <IMG SRC="../IMAGES/phicap12.gif">''' is polynomial in the length of the original formula. Each of the constructions can easily be accomplished in polynomial time.      <P>
<P>







<h2><a name="0a0d_1cea">Exercises<a name="0a0d_1cea"></h2><P>
<a name="0a0d_1ceb">36.4-1<a name="0a0d_1ceb"><P>
Consider the straightforward (nonpolynomial-time) reduction in the proof of Theorem 36.9. Describe a circuit of size <I>n</I> that, when converted to a formula by this method, yields a formula whose size is exponential in <I>n</I>.<P>
<a name="0a0d_1cec">36.4-2<a name="0a0d_1cec"><P>
Show the 3-CNF formula that results when we use the method of Theorem 36.10 on the formula (36.3).<P>
<a name="0a0d_1ced">36.4-3<a name="0a0d_1ced"><P>
<a name="0a0d_1ce5">Professor Jagger proposes to show that SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>P</SUB> 3-CNF-SAT by using only the truth-table technique in the proof of Theorem 36.10, and not the other steps. That is, the professor proposes to take the boolean formula <IMG SRC="../IMAGES/phicap12.gif">, form a truth table for its variables, derive from the truth table a formula in 3-DNF that is equivalent to <IMG SRC="../IMAGES/rtdwnbrc.gif"><IMG SRC="../IMAGES/phicap12.gif">, and then negate and apply DeMorgan's laws to produce a 3-CNF formula equivalent to <IMG SRC="../IMAGES/phicap12.gif">. Show that this strategy does not yield a polynomial-time reduction.<P>
<a name="0a0d_1cee">36.4-4<a name="0a0d_1cee"><P>
<a name="0a0d_1ce6"><a name="0a0d_1ce7">Show that the problem of determining whether a boolean formula is a tautology is complete for co-NP. (<I>Hint:</I> See Exercise 36.3-6.)<P>
<a name="0a0d_1cef">36.4-5<a name="0a0d_1cef"><P>
Show that the problem of determining the satisfiability of boolean formulas in disjunctive normal form is polynomial-time solvable.<P>
<a name="0a0d_1cf0">36.4-6<a name="0a0d_1cf0"><P>
Suppose that someone gives you a polynomial-time algorithm to decide formula satisfiability. Describe how to use this algorithm to find satisfying assignments in polynomial time.<P>
<a name="0a0d_1cf1">36.4-7<a name="0a0d_1cf1"><P>
<a name="0a0d_1ce8"><a name="0a0d_1ce9">Let 2-CNF-SAT be the set of satisfiable boolean formulas in CNF with exactly 2 literals per clause. Show that 2-CNF-SAT <IMG SRC="../IMAGES/memof12.gif"> P. Make your algorithm as efficient as possible. (<I>Hint:</I> Observe that <I>x</I> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> <I>y</I> is equivalent to <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I> <IMG SRC="../IMAGES/arrow12.gif"> <I>y</I>. Reduce 2-CNF-SAT to a problem on a directed graph that is efficiently solvable.)<P>
<P>


<P>







<h1><a name="0a0e_0001">36.5 NP-complete problems<a name="0a0e_0001"></h1><P>
NP-complete problems arise in diverse domains: boolean logic, graphs, arithmetic, network design, sets and partitions, storage and retrieval, sequencing and scheduling, mathematical programming, algebra and number theory, games and puzzles, automata and language theory, program optimization, and more. In this section, we shall use the reduction methodology to provide NP-completeness proofs for a variety of problems drawn from graph theory and set partitioning.<P>
Figure 36.11 outlines the structure of the NP-completeness proofs in this section and Section 36.4. Each language in the figure is proved NP-complete by reduction from the language that points to it. At the root is CIRCUIT-SAT, which we proved NP-complete in Theorem 36.7.<P>
<img src="947_a.gif"><P>
<h4><a name="0a0e_0002">Figure 36.11 The structure of NP-completeness proofs in Sections 36.4 and 36.5. All proofs ultimately follow by reduction from the NP-completeness of CIRCUIT-SAT.<a name="0a0e_0002"></sub></sup></h4><P>





<h2><a name="0a0f_1cf1">36.5.1 The clique problem<a name="0a0f_1cf1"></h2><P>
<a name="0a0f_1cea"><a name="0a0f_1ceb"><a name="0a0f_1cec"><a name="0a0f_1ced">A <I><B>clique</I></B> in an undirected graph <I>G</I> = (<I>V</I>, <I>E</I>) is a subset <I>V</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>V</I> of vertices, each pair of which is connected by an edge in <I>E</I>. In other words, a clique is a complete subgraph of <I>G</I>. The <I><B>size</I></B> of a clique is the number of vertices it contains. The <I><B>clique problem</I></B> is the optimization problem of finding a clique of maximum size in a graph. As a decision problem, we ask simply whether a clique of a given size <I>k</I> exists in the graph. The formal definition is<P>
<pre><a name="0a0f_1cee">CLIQUE = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I>,<I>k</I><IMG SRC="../IMAGES/wdrtchv.gif">: <I>G</I> is a graph with a clique of size <I>k</I>}.</sub></sup></pre><P>
A naive algorithm for determining whether a graph <I>G</I> = (<I>V</I>, <I>E</I>) with |<I>V|</I> vertices has a clique of size <I>k</I> is to list all <I>k</I>-subsets of <I>V</I>, and check each one to see whether it forms a clique. The running time of this algorithm is <img src="947_b.gif">, which is polynomial if <I>k</I> is a constant. In general, however, <I>k</I> could be proportional to |<I>V|</I>, in which case the algorithm runs in superpolynomial time. As one might suspect, an efficient algorithm for the clique problem is unlikely to exist.<P>
<a name="0a0f_1cf2">Theorem 36.11<a name="0a0f_1cf2"><P>
<a name="0a0f_1cef">The clique problem is NP-complete.<P>
<I><B>Proof     </I></B>To show that CLIQUE <IMG SRC="../IMAGES/memof12.gif"> NP, for a given graph <I>G</I> = (<I>V</I>, <I>E</I>), we use the set <I>V</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>V</I> of vertices in the clique as a certificate for <I>G</I>. Checking whether <I>V</I><I>'</I> is a clique can be accomplished in polynomial time by checking whether, for every pair <I>u</I>, <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>', the edge (<I>u</I>, <I>v</I>) belongs to <I>E</I>.<P>
We next show that the clique problem is NP-hard by proving that 3-CNF-SAT <IMG SRC="../IMAGES/lteq12.gif">p CLIQUE. That we should be able to prove this result is somewhat surprising, since on the surface logical formulas seem to have little to do with graphs.<P>
<img src="948_a.gif"><P>
<h4><a name="0a0f_1cf3">Figure 36.12 The graph G derived from the 3-CNF formula <IMG SRC="../IMAGES/phicap12.gif"> = C<SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> C<SUB>2</SUB> <IMG SRC="../IMAGES/angleup.gif"> C<SUB>3</SUB>, where C<SUB>1</SUB> = (x<SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"><FONT FACE="Times New Roman" SIZE=2> <IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT></FONT>x<SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"><FONT FACE="Times New Roman" SIZE=2> <IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT></FONT>x<SUB>3</SUB>), C<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2> =(<IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT>x<SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"><FONT FACE="Times New Roman" SIZE=2> x<SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> x<SUB>3</SUB>), </FONT></FONT>and C<SUB>3</SUB> = (x<SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> x<SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angledwn.gif"></FONT> x<SUB>3</SUB>), in reducing 3-CNF-SAT to CLIQUE. A satisfying assignment of the formula is <IMG SRC="../IMAGES/lftwdchv.gif">x<SUB>1</SUB> = 0, x<SUB>2</SUB> = 0, x<SUB>3</SUB> = 1<IMG SRC="../IMAGES/wdrtchv.gif">. This satisfying assignment satisfies C<SUB>1</SUB> with <IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>2</SUB>, and it satisfies C<SUB>2</SUB> and C<SUB>3 </SUB>with x<SUB>3, </SUB>corresponding to the clique with lightly shaded vertices.<a name="0a0f_1cf3"></sub></sup></h4><P>
The reduction algorithm begins with an instance of 3-CNF-SAT. Let <IMG SRC="../IMAGES/phicap12.gif"> =<SUB> </SUB><I>C</I><SUB>1</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> <I>C</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> . . . <FONT FACE="Times New Roman" SIZE=4><IMG SRC="../IMAGES/angleup.gif"></FONT> <I>C<SUB>k</I></SUB> be a boolean formula in 3-CNF with <I>k</I> clauses. For <I>r</I> = 1, 2, . . . , <I>k</I>, each clause <I>C<SUB>r</I></SUB> has exactly three distinct literals <img src="948_b.gif">. We shall construct a graph <I>G</I> such that <IMG SRC="../IMAGES/phicap12.gif"> is satisfiable if and only if <I>G</I> has a clique of size <I>k</I>.<P>
The graph <I>G</I> = (<I>V</I>, <I>E</I>) is constructed as follows. For each clause <img src="948_c.gif"> in <IMG SRC="../IMAGES/phicap12.gif">, we place a triple of vertices <img src="948_d.gif"> in <I>V</I>. We put an edge between two vertices <img src="948_e.gif"> if both of the following hold: <P>
<IMG SRC="../IMAGES/dot12.gif">     <img src="948_f.gif"> are in different triples, that is, <I>r</I> <IMG SRC="../IMAGES/noteq.gif"> <I>s</I>, and<P>
<a name="0a0f_1cf0"><IMG SRC="../IMAGES/dot12.gif">     their corresponding literals are <I><B>consistent</I></B>, that is, <img src="948_g.gif"> is not the negation of <img src="948_h.gif">.<P>
This graph can easily be computed from <IMG SRC="../IMAGES/phicap12.gif"> in polynomial time. As an example of this construction, if we have<P>
<pre><IMG SRC="../IMAGES/phicap12.gif"> = (<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>3</SUB>) <IMG SRC="../IMAGES/angleup.gif"> (<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>3</SUB>) <IMG SRC="../IMAGES/angleup.gif"> (<I>x</I><SUB>1</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>2</SUB> <IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>3</SUB>) ,</sub></sup></pre><P>
then <I>G</I> is the graph shown in Figure 36.12.<P>
We must show that this transformation of <IMG SRC="../IMAGES/phicap12.gif"> into <I>G</I> is a reduction. First, suppose that <IMG SRC="../IMAGES/phicap12.gif"> has a satisfying assignment. Then, each clause <I>C<SUB>r</I></SUB> contains at least one literal <img src="948_i.gif"> that is assigned 1, and each such literal corresponds to a vertex <img src="948_j.gif">. Picking one such "true" literal from each clause yields a set of <I>V</I>' <I>of </I>k<I> vertices. We claim that </I>V<I>'</I> is a clique. For any two vertices <img src="949_c.gif">, where r <IMG SRC="../IMAGES/noteq.gif"> s, both corresponding literals <img src="949_d.gif"> are mapped to 1 by the given satisfying assignment, and thus the literals cannot be complements. Thus, by the construction of <I>G</I>, the edge <img src="949_e.gif"> belongs to <I>E</I>.<P>
<img src="949_a.gif"><P>
<h4><a name="0a0f_1cf4">Figure 36.13 Reducing CLIQUE to VERTEX-COVER. (a) An undirected graph G = (V,E) with clique V' = {u,v,x,y}. (b) The graph <img src="949_h.gif"> produced by the reduction algorithm that has vertex cover V - V' = {w,z}.<a name="0a0f_1cf4"></sub></sup></h4><P>
Conversely, suppose that <I>G</I> has a clique <I>V</I><I>'</I> of size <I>k</I>. No edges in <I>G </I>connect vertices in the same triple, and so <I>V</I><I>' </I>contains exactly one vertex per triple. We can assign 1 to each literal <img src="949_f.gif"> such that <img src="949_g.gif"> without fear of assigning 1 to both a literal and its complement, since <I>G</I> contains no edges between inconsistent literals. Each clause is satisfied, and so <IMG SRC="../IMAGES/phicap12.gif"> satisfied. (Any variables that correspond to no vertex in the clique may be set arbitrarily.)      <P>
In the example of Figure 36.12, a satisfying assignment of <IMG SRC="../IMAGES/phicap12.gif"> is <IMG SRC="../IMAGES/lftwdchv.gif"><I>x</I><SUB>1</SUB> = 0, <I>x</I><SUB>2</SUB> = 0, <I>x</I><SUB>3</SUB> = 1<IMG SRC="../IMAGES/wdrtchv.gif">. A corresponding clique of size <I>k</I> = 3 consists of the vertices corresponding to <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x</I><SUB>2</SUB> from the first clause, <I>x</I><SUB>3</SUB> from the second clause, and <I>x</I><SUB>3</SUB><I> </I>from the third clause.<P>
<P>







<h2><a name="0a10_1cfa">36.5.2 The vertex-cover problem<a name="0a10_1cfa"></h2><P>
<a name="0a10_1cf1"><a name="0a10_1cf2"><a name="0a10_1cf3"><a name="0a10_1cf4">A <I><B>vertex cover</I></B> of an undirected graph <I>G</I> = (<I>V, E</I>) is a subset <I>V</I>'<I> <IMG SRC="../IMAGES/rgtubar.gif"> </I><I>V</I>such that if (<I>u, v</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>E</I>, then <I>u</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>' or <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>' (or both). That is, each vertex "covers" its incident edges, and a vertex cover for <I>G</I> is a set of vertices that covers all the edges in <I>E</I>. The <I><B>size</I></B> of a vertex cover is the number of vertices in it. For example, the graph in Figure 36.13(b) has a vertex cover {<I>w, z</I>} of size 2.<P>
<a name="0a10_1cf5"><a name="0a10_1cf6">The <I><B>vertex-cover problem</I></B> is to find a vertex cover of minimum size in a given graph. Restating this optimization problem as a decision problem, we wish to determine whether a graph has a vertex cover of a given size <I>k</I>. As a language, we define<P>
<pre><a name="0a10_1cf7">VERTEX-COVER = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G, k</I><IMG SRC="../IMAGES/wdrtchv.gif">: graph <I>G</I> has vertex cover of size <I>k</I>} .</sub></sup></pre><P>
The following theorem shows that this problem is NP-complete.<P>
<a name="0a10_1cfb">Theorem 36.12<a name="0a10_1cfb"><P>
The vertex-cover problem is NP-complete.<P>
<I><B>Proof</I></B>     We first show that VERTEX-COVER <IMG SRC="../IMAGES/memof12.gif"> NP. Suppose we are given a graph <I>G =</I> (<I>V, E</I>) and an integer <I>k</I>. The certificate we choose is the vertex cover <I>V</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>V</I> itself. The verification algorithm affirms that |<I>V</I>'<I>| = k</I>, and then it checks, for each edge (<I>u, v</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>E</I>, whether <I>u</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>' or <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>'. This verification can be performed straightforwardly in polynomial time.<P>
<a name="0a10_1cf8"><a name="0a10_1cf9">We prove that the vertex-cover problem is NP-hard by showing that CLIQUE <IMG SRC="../IMAGES/lteq12.gif"><SUB> P</SUB> VERTEX-COVER. This reduction is based on the notion of the "complement" of a graph. Given an undirected graph <I>G</I> = (<I>V, E</I>), we define the <I><B>complement</I></B> of <I>G</I> as <img src="950_a.gif">. In other words, <img src="950_b.gif"> is the graph containing exactly those edges that are not in <I>G</I>. Figure 36.13 shows a graph and its complement and illustrates the reduction from CLIQUE to VERTEX-COVER.<P>
The reduction algorithm takes as input an instance <IMG SRC="../IMAGES/lftwdchv.gif"><I>G, k</I><IMG SRC="../IMAGES/wdrtchv.gif"> of the clique problem. It computes the complement <img src="950_c.gif">, which is easily doable in polynomial time. The output of the reduction algorithm is the instance <img src="950_d.gif">, of the vertex-cover problem. To complete the proof, we show that this transformation is indeed a reduction: the graph <I>G</I> has a clique of size <I>k</I> if and only if the graph <img src="950_e.gif"> has a vertex cover of size |<I>V</I>| - <I>k</I>.<P>
Suppose that <I>G</I> has a clique <I>V</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>V</I> with |<I>V</I>'| = <I>k</I>. We claim that <I>V - V</I><I>' </I>is a vertex cover in <img src="950_f.gif">. Let (<I>u</I>, <I>v</I>) be any edge in <img src="950_g.gif">. Then, (<I>u, v</I>) <IMG SRC="../IMAGES/notmem.gif"> <I>E</I>, which implies that at least one of <I>u</I> or <I>v</I> does not belong to <I>V</I>', since every pair of vertices in <I>V</I>' is connected by an edge of <I>E</I>. Equivalently, at least one of <I>u</I> or <I>v</I> is in <I>V - V</I>', which means that edge (<I>u,v</I>) is covered by <I>V - V</I>'. Since (<I>u, v</I>) was chosen arbitrarily from <img src="950_h.gif">, every edge of <img src="950_i.gif"> is covered by a vertex in <I>V - V</I>'. Hence, the set <I>V - V</I>', which has size |<I>V| - k</I>, forms a vertex cover for <img src="950_j.gif">.<P>
Conversely, suppose that <img src="950_k.gif"> has a vertex cover <I>V</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>V</I> , where |<I>V</I>'| = |<I>V| - k</I>. Then, for all <I>u, v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>, if (<I>u, v</I>) <IMG SRC="../IMAGES/memof12.gif">, if <img src="950_l.gif">, then <I>u</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>' or <I>v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>' or both. The contrapositive of this implication is that for all <I>u, v</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>, if <I>u</I> <IMG SRC="../IMAGES/notmem.gif"> <I>V</I>' and <I>v</I> <IMG SRC="../IMAGES/notmem.gif"> <I>V</I>', then (<I>u, v</I>) <IMG SRC="../IMAGES/notmem.gif"> <I>E</I>. In other words, <I>V - V</I>' is a clique, and it has size |<I>V| - |V</I>'<I>| = k</I>.      <P>
Since VERTEX-COVER is NP-complete, we don't expect to find a polynomial-time algorithm for finding a minimum-size vertex cover. Section 37.1 presents a polynomial-time "approximation algorithm," however, which produces "approximate" solutions for the vertex-cover problem. The size of a vertex cover produced by the algorithm is at most twice the minimum size of a vertex cover.<P>
Thus, we shouldn't give up hope just because a problem is NP-complete. There may be a polynomial-time approximation algorithm that obtains near-optimal solutions, even though finding an optimal solution is NP-complete. Chapter 37 gives several approximation algorithms for NP-complete problems.<P>
<P>







<h2><a name="0a11_1d00">36.5.3 The subset-sum problem<a name="0a11_1d00"></h2><P>
<a name="0a11_1cfa"><a name="0a11_1cfb">The next NP-complete problem we consider is arithmetic. In the <I><B>subset-sum problem</I></B>, we are given a finite set <I>S</I> <IMG SRC="../IMAGES/rightu.gif"> <B>N</B> and a <I><B>target</I></B> <I>t</I> <IMG SRC="../IMAGES/memof12.gif"> <B>N</B>. We ask whether there is a subset <I>S</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>S</I> whose elements sum to <I>t</I>. For example, if <I>S</I> = {1, 4, 16, 64, 256, 1040, 1041, 1093, 1284, 1344} and <I>t</I> = 3754, then the subset <I>S</I>' = {1, 16, 64, 256, 1040, 1093, 1284} is a solution.<P>
As usual, we define the problem as a language:<P>
<pre><a name="0a11_1cfc">SUBSET-SUM<B> =</B></sub></sup></pre><P>
<pre>{<IMG SRC="../IMAGES/lftwdchv.gif"><I>S, t</I><IMG SRC="../IMAGES/wdrtchv.gif">: there exists a subset <I>S</I>' <IMG SRC="../IMAGES/rgtubar.gif"> <I>S</I> such that <I>t</I> = <IMG SRC="../IMAGES/sum14.gif"><I><SUB>s</I></SUB><IMG SRC="../IMAGES/memof12.gif">S<I><SUB>'</SUB></I>S<I>} .</I></sub></sup></pre><P>
As with any arithmetic problem, it is important to recall that our standard encoding assumes that the input integers are coded in binary. With this assumption in mind, we can show that the subset-sum problem is unlikely to have a fast algorithm.<P>
<a name="0a11_1d01">Theorem 36.13<a name="0a11_1d01"><P>
The subset-sum problem is NP-complete.<P>
<I><B>Proof</I></B>     To show that SUBSET-SUM is in NP, for an instance <IMG SRC="../IMAGES/lftwdchv.gif"><I>S, t</I><IMG SRC="../IMAGES/wdrtchv.gif"> of the problem, we let the subset <I>S</I>' be the certificate. Checking whether <I>t</I> = <IMG SRC="../IMAGES/sum14.gif"><I><SUB>s</I></SUB><IMG SRC="../IMAGES/memof12.gif">S'<I>s</I> can be accomplished by a verification algorithm in polynomial time.<P>
We now show that VERTEX-COVER <IMG SRC="../IMAGES/lteq12.gif"><SUB>P</SUB> SUBSET-SUM. Given an instance <IMG SRC="../IMAGES/lftwdchv.gif"><I>G, k</I><IMG SRC="../IMAGES/wdrtchv.gif"> of the vertex-cover problem, the reduction algorithm constructs an instance <IMG SRC="../IMAGES/lftwdchv.gif"><I>S, t</I><IMG SRC="../IMAGES/wdrtchv.gif"> of the subset-sum problem such that <I>G</I> has a vertex cover of size <I>k</I> if and only if there is a subset of <I>S</I> whose sum is exactly <I>t</I>.<P>
<a name="0a11_1cfd"><a name="0a11_1cfe"><a name="0a11_1cff">At the heart of the reduction is an incidence-matrix representation of <I>G</I>. Let <I>G</I> = (<I>V, E</I>) be an undirected graph and let <I>V</I> = {<I>v</I><SUB>0</SUB>, <I>v</I><SUB>1</SUB>, . . . ,<I>v</I><SUB>|<I></SUB>V|<SUB>-1</SUB>} and </I>E<I> = {</I>e<I><SUB>0</SUB>, </I>e<I><SUB>1</SUB>, . . . , </I>e<SUB>|E|</SUB>-1<SUB>}. The <I><B>incidence matrix</I></B> of <I>G</I> is a |<I>V| <IMG SRC="../IMAGES/mult.gif"> |</I>E| matrix <I>B</I> = (<I>b</SUB><FONT FACE="Courier New" SIZE=2>ij</I></FONT>) such that<P>
<img src="951_a.gif"><P>
For example, Figure 36.14(b) shows the incidence matrix for the undirected graph of Figure 36.14(a). The incidence matrix is shown with lower-indexed edges on the right, rather than on the left as is conventional, in order to simplify the formulas for the numbers in <I>S</I>.<P>
Given a graph <I>G</I> and an integer <I>k</I>, the reduction algorithm computes a set <I>S</I> of numbers and an integer <I>t</I>. To understand how the reduction algorithm works, let us represent numbers in a "modified base-4" fashion. The |<I>E|</I> low-order digits of a number will be in base-4 but the high-order digit can be as large as <I>k</I>. The set of numbers is constructed in such a way that no carries can be propagated from lower digits to higher digits.<P>
<img src="952_a.gif"><P>
<h4><a name="0a11_1d02">Figure 36.14 The reduction of the vertex-cover problem to the subset-sum problem. (a) An undirected graph G. A vertex cover {v<SUB>1</SUB>, v<SUB>3</SUB>, v<SUB>4</SUB>} of size 3 is lightly shaded. (b) The corresponding incidence matrix. Shading of the rows corresponds to the vertex cover of part (a). Each edge e<SUB>j</SUB> has a 1 in at least one lightly shaded row. (c) The corresponding subset-sum instance. The portion within the box is the incidence matrix. Here, the vertex cover {v<SUB>1</SUB>, v<SUB>3</SUB>, v<SUB>4</SUB>} of size k = 3 corresponds to the lightly shaded subset {1, 16, 64, 256, 1040, 1093, 1284}, which adds up to 3754.<a name="0a11_1d02"></sub></sup></h4><P>
The set <I>S</I> consists of two types of numbers, corresponding to vertices and edges respectively. For each vertex <I>v<SUB>i</I></SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>, we create a positive integer <I>x<SUB>i</I></SUB> whose modified base-4 representation consists of a leading 1 followed by |<I>E|</I> digits. The digits correspond to <I>v<SUB>i</I></SUB>'s row of the incidence matrix <I>B</I> = (<I>b<SUB>ij</I></SUB>) for <I>G</I>, as illustrated in Figure 36.14(c). Formally, for <I>i</I> = 0, 1, . . . , |<I>V| - 1,</I><P>
<img src="952_b.gif"><P>
For each edge <I>e<SUB>j</SUB> </I><IMG SRC="../IMAGES/memof12.gif"><I> E</I>, we create a positive integer <I>y<SUB>j</I></SUB> that is just a row of the "identity" incidence matrix. (The identity incidence matrix is the |<I>E| <IMG SRC="../IMAGES/mult.gif"> |</I>E| matrix with 1's only in the diagonal positions.) Formally, for <I>j</I> = 0, 1, . . . , |<I>E| - 1,</I><P>
<pre><I>y<SUB>j</I></SUB> = 4<I><SUP>j</I></SUP> .</sub></sup></pre><P>
The first digit of the target sum <I>t</I> is <I>k</I>, and all |<I>E|</I> lower-order digits are 2's. Formally,<P>
<img src="952_c.gif"><P>
All of these numbers have polynomial size when we represent them in binary. The reduction can be performed in polynomial time by manipulating the bits of the incidence matrix.<P>
We must now show that graph <I>G</I> has a vertex cover of size <I>k</I> if and only if there is a subset <I>S</I>'<I> <IMG SRC="../IMAGES/rgtubar.gif"> </I><I>S</I> whose sum is <I>t</I>. First, suppose that <I>G</I> has a vertex cover <I>V</I>' <I><IMG SRC="../IMAGES/rgtubar.gif"> </I><I>V</I> of size <I>k</I>. Let <I>V</I>' = {<I>v<SUB>i</I>1</SUB>, <I>v<SUB>i</I>2</SUB>, . . . , <I>v<SUB>ik</I></SUB>}, and define <I>S</I><I>'</I> by<P>
<pre><I>S</I>'<I> = {</I>x<SUB>i<I>1</SUB>, </I>x<SUB>i<I>2</SUB>, . . . , </I>x<SUB>ik<I></SUB>} <IMG SRC="../IMAGES/wideu.gif"></I></sub></sup></pre><P>
<pre>{<I>y<SUB>j</I></SUB> : <I>e<SUB>j</I></SUB> is incident on precisely one vertex in <I>V</I>'<I>} .</I></sub></sup></pre><P>
To see that <IMG SRC="../IMAGES/sum14.gif"><I><SUB>s</I></SUB><IMG SRC="../IMAGES/memof12.gif">S<I><SUB>'</SUB>S</I> = <I>t</I>, observe that summing the <I>k</I> leading 1's of the <I>x<SUB>im </I></SUB><IMG SRC="../IMAGES/memof12.gif"> <I>S</I><I>'</I> gives the leading digit <I>k</I> of the modified base-4 representation of <I>t</I>. To get the low-order digits of <I>t</I>, each of which is a 2, consider the digit positions in turn, each of which corresponds to an edge <I>e<SUB>j</I></SUB>. Because <I>V</I><I>'</I> is a vertex cover, <I>e<SUB>j</I></SUB> is incident on at least one vertex in <I>V</I><I>'</I>. Thus, for each edge <I>e<SUB>j</SUB>, </I>there is at least one<I> x<SUB>im</I></SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>S</I><I>'</I> with a 1 in the <I>j</I>th position. If <I>e<SUB>j</I></SUB> is incident on two vertices in <I>V</I><I>'</I>, then both contribute a 1 to the sum in the <I>j</I>th position. The <I>j</I>th digit of <I>y<SUB>j</I></SUB> contributes nothing, since <I>e<SUB>j</I></SUB> is incident on two vertices, which implies that <I>y<SUB>j</I></SUB> <IMG SRC="../IMAGES/notmem.gif"> <I>S</I><I>'</I>. Thus, in this case, the sum of <I>S</I><I>'</I> produces a 2 in the <I>j</I>th position of <I>t</I>. For the other case--when <I>e<SUB>j </I></SUB>is incident on exactly one vertex in <I>V</I><I>'</I>--we have <I>y<SUB>j</I></SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>S</I><I>'</I>, and the incident vertex and <I>y<SUB>j</I></SUB> each contribute 1 to the sum of the <I>j</I>th digit of <I>t</I>, thereby also producing a 2. Thus, <I>S</I><I>'</I> is a solution to the subset-sum instance <I>S</I>.<P>
Now, suppose that there is a subset <I>S</I>'<I> <IMG SRC="../IMAGES/rgtubar.gif"> </I><I>S</I> that sums to <I>t</I>. Let <I>S</I> = {<I>x<SUB>i</I>1</SUB>, <I>x<SUB>i</I>2</SUB>, . . . , <I>x<SUB>im</I></SUB>} <FONT FACE="Times New Roman" SIZE=3><IMG SRC="../IMAGES/wideu.gif"></FONT> {<I>y<SUB>j</I>1</SUB>, <I>y<SUB>j</I>2</SUB>, . . . , <I>y<SUB>jp</I></SUB>}. We claim that <I>m</I> = <I>k</I> and that <I>V</I><I>'</I> = {<I>v<SUB>i</I>1</SUB>, <I>v<SUB>i</I>2</SUB>, . . . , <I>v<SUB>im</I></SUB>} is a vertex cover for <I>G</I>. To prove this claim, we start by observing that for each edge <I>e<SUB>j</I></SUB> <IMG SRC="../IMAGES/memof12.gif"> <I>E</I>, there are three 1's in set <I>S</I> in the <I>e<SUB>j</I></SUB> position: one from each of the two vertices incident on <I>e<SUB>j</I></SUB>, and one from <I>y<SUB>j</I></SUB>. Because we are working with a modified base-4 representation, there are no carries from position <I>e<SUB>j</I></SUB> to position <I>e<SUB>j</I>+1</SUB>. Thus, for each of the |<I>E|</I> low-order positions of <I>t</I>, at least one and at most two <I>x<SUB>i</I></SUB> must contribute to the sum. Since at least one <I>x<SUB>i</I></SUB> contributes to the sum for each edge, we see that <I>V</I><I>'</I> is a vertex cover. To see that <I>m</I> = <I>k</I>, and thus that <I>V</I>' is a vertex cover of size <I>k</I>, observe that the only way the leading <I>k</I> in target <I>t</I> can be achieved is by including exactly <I>k</I> of the <I>x<SUB>i</I></SUB> in the sum.      <P>
In Figure 36.14, the vertex cover <I>V</I><I>'</I> = {<I>v</I><SUB>1, </SUB><I>v</I><SUB>3</SUB>, <I>v</I><SUB>4</SUB>} corresponds to the subset <I>S</I>' = {<I>x</I><SUB>1</SUB>, <I>x</I><SUB>3</SUB>, <I>x</I><SUB>4</SUB>, <I>y</I><SUB>0</SUB>, <I>y</I><SUB>2</SUB>, <I>y</I><SUB>3</SUB><I>, y</I><SUB>4</SUB>}. All of the <I>y<SUB>j</I></SUB> are included in <I>S</I><I>'</I>, with the exception of <I>y</I><SUB>1</SUB>, which is incident on two vertices in <I>V</I>'.<P>
<P>







<h2><a name="0a12_1d03">36.5.4 The hamiltonian-cycle problem<a name="0a12_1d03"></h2><P>
<a name="0a12_1d00"><a name="0a12_1d01">We now return to the hamiltonian-cycle problem defined in Section 36.2.<P>
<img src="954_a.gif"><P>
<h4><a name="0a12_1d04">Figure 36.15 (a) Widget A, used in the reduction from 3-CNF-SAT to HAM-CYCLE. (b)-(c) If A is a subgraph of some graph G that contains a hamiltonian cycle and the only connections from A to the rest of G are through the vertices a, a', b, and b', then the shaded edges represent the only two possible ways in which the hamiltonian cycle may traverse the edges of subgraph A. (d) A compact representation of the A widget.<a name="0a12_1d04"></sub></sup></h4><P>
<a name="0a12_1d05">Theorem 36.14<a name="0a12_1d05"><P>
The hamiltonian cycle problem is NP-complete.<P>
<I><B>Proof</I></B>     We first show that HAM-CYCLE belongs to NP. Given a graph <I>G</I> = (<I>V, E</I>), our certificate is the sequence of |<I>V|</I> vertices that make up the hamiltonian cycle. The verification algorithm checks that this sequence contains each vertex in <I>V</I> exactly once and that with the first vertex repeated at the end, it forms a cycle in <I>G</I>. This verification can be performed in polynomial time.<P>
<a name="0a12_1d02">We now prove that HAM-CYCLE is NP-complete by showing that 3-CNF-SAT <IMG SRC="../IMAGES/lteq12.gif"><SUB>P</SUB> HAM-CYCLE. Given a 3-CNF boolean formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> over variables <I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . , <I>x<SUB>n</I></SUB> with clauses <I>C</I><SUB>1</SUB>, <I>C</I><SUB>2</SUB>, . . . , <I>C<SUB>k</I></SUB>, each containing exactly 3 distinct literals, we construct a graph <I>G = </I>(<I>V, E</I>) in polynomial time such that <I>G</I> has a hamiltonian cycle if and only if <IMG SRC="../IMAGES/phicap12.gif"><I></I> is satisfiable. Our construction is based on <I><B>widgets</I></B>, which are pieces of graphs that enforce certain properties.<P>
Our first widget is the subgraph <I>A</I> shown in Figure 36.15(a). Suppose that <I>A</I> is a subgraph of some graph <I>G</I> and that the only connections between <I>A</I> and the remainder of <I>G</I> are through the vertices <I>a, a</I>', b, and b<I>'</I>. Furthermore, suppose that graph <I>G</I> has a hamiltonian cycle. Since any hamiltonian cycle of <I>G</I> must pass through vertices <I>z</I><SUB>1</SUB>, <I>z</I><SUB>2</SUB>, <I>z</I><SUB>3</SUB>, and <I>z</I><SUB>4</SUB> in one of the ways shown in Figures 36.15(b) and (c), we may treat subgraph <I>A</I> as if it were simply a pair of edges (<I>a, a</I>') and (<I>b, b</I>') with the restriction that any hamiltonian cycle of <I>G</I> must include exactly one of these edges. We shall represent widget <I>A</I> as shown in Figure 36.15(d).<P>
The subgraph <I>B</I> in Figure 36.16 is our second widget. Suppose that <I>B</I> is a subgraph of some graph <I>G</I> and that the only connections from <I>B</I> to the remainder of <I>G</I> are through vertices <I>b</I><SUB>1</SUB>, <I>b</I><SUB>2</SUB>, <I>b</I><SUB>3</SUB>, and <I>b</I><SUB>4</SUB>. A hamiltonian cycle of graph <I>G</I> cannot traverse <I>all</I> of the edges (<I>b</I><SUB>1</SUB>, <I>b</I><SUB>2</SUB>), (<I>b</I><SUB>2</SUB>, <I>b</I><SUB>3</SUB>), and (<I>b</I><SUB>3</SUB>, <I>b</I><SUB>4</SUB>), since then all vertices in the widget other than <I>b</I><SUB>1</SUB>, <I>b</I><SUB>2</SUB>, <I>b</I><SUB>3</SUB>, and <I>b</I><SUB>4</SUB> would be missed. A hamiltonian cycle of <I>G</I> may, however, traverse any proper subset of these edges. Figures 36.16(a)-(e) show five such subsets; the remaining two subsets can be obtained by performing a top-to-bottom flip of parts (b) and (e). We represent this widget as in Figure 36.16(f), the idea being that at least one of the paths pointed to by the arrows must be taken by a hamiltonian cycle.<P>
The graph <I>G</I> that we shall construct consists mostly of copies of these two widgets. The construction is illustrated in Figure 36.17. For each of the <I>k</I> clauses in <IMG SRC="../IMAGES/phicap12.gif"><I></I>, we include a copy of widget <I>B</I>, and we join these widgets together in series as follows. Letting <I>b<SUB>ij</I></SUB> be the copy of vertex <I>b<SUB>j</I></SUB> in the <I>i</I>th copy of widget <I>B</I>, we connect <I>b<SUB>i</I>,4</SUB> to <I>b<SUB>i</I>+1,1</SUB> for<I> i</I> = 1, 2, . . . , <I>k</I> - 1.<P>
Then, for each variable <I>x<SUB>m</I></SUB> in <IMG SRC="../IMAGES/phicap12.gif"><I></I>, we include two vertices <img src="955_a.gif">. We connect these two vertices by means of two copies of the edge <img src="955_b.gif">, which we denote by <I>e<SUB>m</I></SUB> and <img src="955_c.gif"> to distinguish them. The idea is that if the hamiltonian cycle takes edge <I>e<SUB>m</I></SUB>, it corresponds to assigning variable <I>x<SUB>m</I></SUB> the value 1. If the hamiltonian cycle takes edge <img src="955_d.gif">, the variable is assigned the value 0. Each pair of these edges forms a two-edge loop; we connect these small loops in series by adding edges <img src="955_e.gif"> for <I>m</I> = 1, 2, . . . , <I>n</I> - 1. We connect the left (clause) side of the graph to the right (variable) side by means of two edges <img src="955_f.gif">, which are the topmost and bottommost edges in Figure 36.17.<P>
We are not yet finished with the construction of graph <I>G</I>, since we have yet to relate the variables to the clauses. If the <I>j</I>th literal of clause <I>C<SUB>i</I></SUB> is <I>x<SUB>m</I></SUB>, then we use an <I>A</I> widget to connect edge (<I>b<SUB>ij</I></SUB>, <I>b<SUB>i,j</I>+1</SUB>) with edge <I>e<SUB>m</I></SUB>. If the <I>j</I>th literal of clause <I>C<SUB>i</I></SUB> is <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x<SUB>m</I></SUB>, then we instead put an <I>A</I> widget between edge (<I>b<SUB>ij</I></SUB>, <I>b<SUB>i,j</I>+1</SUB>) and edge <img src="955_g.gif">. In Figure 36.17, for example, because clause <I>C</I><SUB>2  </SUB>is (<I>x</I><SUB>1 </SUB><FONT FACE="Times New Roman" SIZE=3><IMG SRC="../IMAGES/angledwn.gif"> <IMG SRC="../IMAGES/rtdwnbrc.gif"></FONT> <I>x</I><SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=3><IMG SRC="../IMAGES/angledwn.gif"> <I>x</I><SUB>3</SUB><FONT FACE="Times New Roman" SIZE=3>)</FONT>, we place three <I>A</I> widgets as follows:</FONT><P>
<IMG SRC="../IMAGES/dot12.gif">     between (<I>b</I><SUB>2,1</SUB>, <I>b</I><SUB>2,2</SUB>) and <I>e</I><SUB>1</SUB>,<P>
<IMG SRC="../IMAGES/dot12.gif">     between (<I>b</I><SUB>2,2</SUB>, <I>b</I><SUB>2,3</SUB>) and <img src="955_h.gif">, and<P>
<IMG SRC="../IMAGES/dot12.gif">     between (<I>b</I><SUB>2,3</SUB>, <I>b</I><SUB>2,4</SUB>) and <I>e</I><SUB>3</SUB>.<P>
Note that connecting two edges by means of <I>A</I> widgets actually entails replacing each edge by the five edges in the top or bottom of Figure 36.15(a) and, of course, adding the connections that pass through the <I>z</I> vertices as well. A given literal <I>l<SUB>m</I></SUB> may appear in several clauses (<IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x<SUB>m</I></SUB> in Figure 36.17, for example), and thus an edge <I>e<SUB>m</I></SUB> or <img src="955_i.gif"> may be be influenced by several <I>A</I> widgets (edge <img src="955_j.gif">, for example). In this case, we connect the <I>A</I> widgets in series, as shown in Figure 36.18, effectively replacing edge <I>e<SUB>m</I></SUB> or <img src="955_k.gif"> by a series of edges.<P>
<img src="956_a.gif"><P>
<h4><a name="0a12_1d06">Figure 36.16 Widget B, used in the reduction from 3-CNF-SAT to HAM-CYCLE. No path from vertex b<SUB>1</SUB> to vertex b<SUB>4</SUB> containing all the vertices in the widget may use all three edges (b<SUB>1</SUB>, b<SUB>2</SUB>), (b<SUB>2</SUB>, b<SUB>3</SUB>), and (b<SUB>3</SUB>, b<SUB>4</SUB>). Any proper subset of these edges may be used, however. (a)-(e) Five such subsets. (f) A representation of this widget in which at least one of the paths pointed to by the arrows must be taken by a hamiltonian cycle.<a name="0a12_1d06"></sub></sup></h4><P>
<img src="957_a.gif"><P>
<h4><a name="0a12_1d07">Figure 36.17 The graph G constructed from the formula <IMG SRC="../IMAGES/phicap12.gif"> = (<IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>1</SUB><FONT FACE="Times New Roman" SIZE=2> V x<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2> V <IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>3</SUB><FONT FACE="Times New Roman" SIZE=2>) <IMG SRC="../IMAGES/angleup.gif"> (x<SUB>1</SUB><FONT FACE="Times New Roman" SIZE=2> V <IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2> V x<SUB>3</SUB><FONT FACE="Times New Roman" SIZE=2>) <IMG SRC="../IMAGES/angleup.gif"> (x<SUB>1</SUB><FONT FACE="Times New Roman" SIZE=2> V x<SUB>2</SUB> <FONT FACE="Times New Roman" SIZE=2>V <IMG SRC="../IMAGES/rtdwnbrc.gif">x<SUB>3</SUB><FONT FACE="Times New Roman" SIZE=2>). A satisfying assignment s to the variables of <IMG SRC="../IMAGES/phicap12.gif"> is s(x<SUB>1</SUB><FONT FACE="Times New Roman" SIZE=2>) =<SUB> </SUB>0,<SUB> </SUB>s(x<SUB>2</SUB><FONT FACE="Times New Roman" SIZE=2>) = 1, and s(x<SUB>3</SUB><FONT FACE="Times New Roman" SIZE=2>) = 1, which corresponds to the hamiltonian cycle shown. Note that if s(x<SUB>m</SUB><FONT FACE="Times New Roman" SIZE=2>) = 1, then edge e<SUB>m</SUB><FONT FACE="Times New Roman" SIZE=2> is in the hamiltonian cycle, and if s(x<SUB>m</SUB><FONT FACE="Times New Roman" SIZE=2>) = 0, then edge <img src="957_b.gif"> is in the hamiltonian cycle.<a name="0a12_1d07"></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></FONT></sub></sup></h4><P>
<img src="958_a.gif"><P>
<h4><a name="0a12_1d08">Figure 36.18 The actual construction used when an edge e<SUB>m</SUB><FONT FACE="Times New Roman" SIZE=2> or <img src="958_b.gif"> is influenced by multiple A widgets. (a) A portion of Figure 36.17. (b) The actual subgraph constructed.<a name="0a12_1d08"></FONT></sub></sup></h4><P>
We claim that formula <IMG SRC="../IMAGES/phicap12.gif"><I></I> is satisfiable if and only if graph <I>G</I> contains a hamiltonian cycle. We first suppose that <I>G</I> has a hamiltonian cycle<I> h</I> and show that <IMG SRC="../IMAGES/phicap12.gif"> is satisfiable. Cycle <I>h</I> must take a particular form:<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif"></FONT>     First, it traverses edge <img src="958_c.gif"> to go from the top left to the top right.<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif"></FONT>     It then follows all of the <img src="958_d.gif"> vertices from top to bottom, choosing either edge e<SUB>m</SUB> or edge <img src="958_e.gif">, but not both.<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif"></FONT>     It next traverses edge <img src="958_f.gif"> to get back to the left side.<P>
<FONT FACE="Courier New" SIZE=2><IMG SRC="../IMAGES/dot12.gif"></FONT>     Finally, it traverses the B widgets from bottom to top on the left.<P>
(It actually traverses edges within the <I>A</I> widgets as well, but we use these subgraphs to enforce the either/or nature of the edges it connects.)<P>
Given the hamiltonian cycle <I>h</I>, we define a truth assignment for <IMG SRC="../IMAGES/phicap12.gif"><I></I> as follows. If edge <I>e<SUB>m</I></SUB> belongs to <I>h</I>, then we set <I>x<SUB>m</I></SUB> = 1. Otherwise, edge <img src="958_g.gif"> belongs to <I>h</I>, and we set <I>x<SUB>m</I></SUB> = 0.<P>
We claim that this assignment satisfies <IMG SRC="../IMAGES/phicap12.gif"><I></I>. Consider a clause <I>C<SUB>i</I></SUB> and the corresponding <I>B</I> widget in <I>G</I>. Each edge (<I>b<SUB>i</I>,<I>j</SUB>b<SUB>i,j</I>+l</SUB>) is connected by an <I>A</I> widget to either edge <I>e<SUB>m</SUB> </I>or edge <img src="958_h.gif"><I>, </I>depending on whether<I> x<SUB>m</I></SUB> or <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x<SUB>m</I></SUB> is the <I>j</I>th literal in the clause. The edge (<I>b<SUB>i,j</I></SUB>,<I>b<SUB>i,j</I>+1</SUB>) is traversed by <I>h</I> if and only if the corresponding literal is 0. Since each of the three edges (<I>b<SUB>i</I>,1</SUB>,<I>b<SUB>i</I>,2</SUB>),(<I>b<SUB>i</I>,2</SUB>,<I>b<SUB>i</I>,3</SUB>),(<I>b<SUB>i</I>,3</SUB>,<I>b<SUB>i</I>,4</SUB>) in clause <I>C<SUB>i</I></SUB> is also in a <I>B</I> widget, all three cannot be traversed by the hamiltonian cycle <I>h</I>. One of the three edges, therefore, must have a corresponding literal whose assigned value is 1, and clause <I>C<SUB>i</I></SUB> is satisfied. This property holds for each clause <I>C<SUB>i,</SUB> i</I> = 1, 2, . . . , <I>k</I>, and thus formula &oslash; is satisfied.<P>
<img src="959_a.gif"><P>
<h4><a name="0a12_1d09">Figure 36.19 An instance of the traveling-salesman problem. Shaded edges represent a minimum-cost tour, with cost 7.<a name="0a12_1d09"></sub></sup></h4><P>
Conversely, let us suppose that formula &oslash; is satisfied by some truth assignment. By following the rules from above, we can construct a hamiltonian cycle for graph <I>G</I>: traverse edge <I>e<SUB>m</I></SUB> if <I>x<SUB>m</I></SUB> = 1, traverse edge <img src="959_b.gif"> if <I>x<SUB>m</I></SUB> = 0, and traverse edge (<I>b<SUB>i,j</I></SUB>,<I>b<SUB>i,j</I>+1</SUB>) if and only if the <I>j</I>th literal of clause <I>C<SUB>i</I></SUB> is 0 under the assignment. These rules can indeed be followed, since we assume that <I>s</I> is a satisfying assignment for formula &oslash;.<P>
Finally, we note that graph <I>G</I> can be constructed in polynomial time. It contains one <I>B</I> widget for each of the <I>k</I> clauses in &oslash;. There is one <I>A</I> widget for each instance of each literal in &oslash;, and so there are 3<I>k</I> <I>A</I> widgets. Since the <I>A</I> and <I>B</I> widgets are of fixed size, the graph <I>G</I> has <I>O</I>(<I>k</I>) vertices and edges and is easily constructed in polynomial time. Thus, we have provided a polynomial-time reduction from 3-CNF-SAT to HAM-CYCLE.      <P>
<P>







<h2><a name="0a13_1d08">36.5.5 The traveling-salesman problem<a name="0a13_1d08"></h2><P>
<a name="0a13_1d03"><a name="0a13_1d04"><a name="0a13_1d05"><a name="0a13_1d06">In the <I><B>traveling-salesman problem</I></B>, which is closely related to the hamiltonian-cycle problem, a salesman must visit <I>n</I> cities. Modeling the problem as a complete graph with <I>n</I> vertices, we can say that the salesman wishes to make a <I><B>tour</I></B>, or hamiltonian cycle, visiting each city exactly once and finishing at the city he starts from. There is an integer cost <I>c</I>(<I>i, j</I>) to travel from city <I>i</I> to city <I>j</I>, and the salesman wishes to make the tour whose total cost is minimum, where the total cost is the sum of the individual costs along the edges of the tour. For example, in Figure 36.19, a minimum-cost tour is <IMG SRC="../IMAGES/lftwdchv.gif"><I>u</I>, <I>w</I>, <I>v</I>, <I>x</I>, <I>u</I><IMG SRC="../IMAGES/wdrtchv.gif">, with cost 7. The formal language for the traveling-salesman problem is<P>
<pre><a name="0a13_1d07">TSP = {<IMG SRC="../IMAGES/lftwdchv.gif"><I>G</I>,<I>c</I>,<I>k</I><IMG SRC="../IMAGES/wdrtchv.gif"><I> </I>: <I>G</I> = (<I>V<B>,</I></B><I>E</I>) is a complete graph,</sub></sup></pre><P>
<pre><I>c</I> is a function from <I>V</I> <IMG SRC="../IMAGES/mult.gif"> <I>V</I> <IMG SRC="../IMAGES/arrow12.gif"> Z,</sub></sup></pre><P>
<pre><I>k</I> <IMG SRC="../IMAGES/memof12.gif"> Z, and</sub></sup></pre><P>
<pre><I>G</I> has a traveling-salesman tour with cost at most <I>k</I>} .</sub></sup></pre><P>
The following theorem shows that a fast algorithm for the traveling-salesman problem is unlikely to exist.<P>
<a name="0a13_1d09">Theorem 36.15<a name="0a13_1d09"><P>
The traveling-salesman problem is NP-complete.<P>
<I><B>Proof     </I></B>We first show that TSP belongs to NP. Given an instance of the problem, we use as a certificate the sequence of <I>n</I> vertices in the tour. The verification algorithm checks that this sequence contains each vertex exactly once, sums up the edge costs, and checks whether the sum is at most <I>k</I>. This process can certainly be done in polynomial time.<P>
To prove that TSP is NP-hard, we show that HAM-CYCLE <IMG SRC="../IMAGES/lteq12.gif"><SUB>p</SUB> TSP. Let <I>G</I> = (<I>V</I>, <I>E</I>) be an instance of HAM-CYCLE. We construct an instance of TSP as follows. We form the complete graph <I>G</I><I>'</I>= (<I>V,E</I><I>'</I>), where <I>E</I><I>' </I>= {(<I>i, j</I>): <I>i, j</I> <IMG SRC="../IMAGES/memof12.gif"> <I>V</I>}, and we define the cost function <I>c</I> by<P>
<img src="960_a.gif"><P>
The instance of TSP is then (<I>G</I><I>'</I>, <I>c</I>, 0), which is easily formed in polynomial time.<P>
We now show that graph <I>G</I> has a hamiltonian cycle if and only if graph <I>G</I><I>'</I> has a tour of cost at most 0. Suppose that graph <I>G</I> has a hamiltonian cycle <I>h</I>. Each edge in <I>h</I> belongs to <I>E</I> and thus has cost 0 in <I>G</I><I>'.</I> Thus, <I>h</I> is a tour in <I>G</I><I>' </I>with cost 0. Conversely, suppose that graph <I>G</I><I>' </I>has a tour <I>h</I><I>'</I> of cost at most 0. Since the costs of the edges in <I>E</I><I>'</I> are 0 and 1, the cost of tour <I>h</I><I>' </I>is exactly 0. Therefore, <I>h</I><I>' </I>contains only edges in <I>E</I>. We conclude that <I>h</I> is a hamiltonian cycle in graph <I>G</I>.      <P>
<P>







<h2><a name="0a14_1d13">Exercises<a name="0a14_1d13"></h2><P>
<a name="0a14_1d14">36.5-1<a name="0a14_1d14"><P>
<a name="0a14_1d08"><a name="0a14_1d09">The <I><B>subgraph-isomorphism problem</I></B> takes two graphs <I>G</I><SUB>1</SUB> and <I>G</I><SUB>2</SUB> and asks whether <I>G</I><SUB>1</SUB> is a subgraph of <I>G</I><SUB>2</SUB>. Show that the subgraph-isomorphism problem is NP-complete.<P>
<a name="0a14_1d15">36.5-2<a name="0a14_1d15"><P>
<a name="0a14_1d0a"><a name="0a14_1d0b">Given an integer <I>m</I>-by-<I>n</I> matrix <I>A</I> and an integer <I>m</I>-vector <I>b</I>, the <I><B>0-1 integer-programming problem</I></B> asks whether there is an integer <I>n</I>-vector <I>x</I> with elements in the set {0,1} such that <I>Ax</I> <IMG SRC="../IMAGES/lteq12.gif"> <I>b</I>. Prove that 0-1 integer programming is NP-complete. (<I>Hint:</I> Reduce from 3-CNF-SAT.)<P>
<a name="0a14_1d16">36.5-3<a name="0a14_1d16"><P>
<a name="0a14_1d0c">Show that the subset-sum problem is solvable in polynomial time if the target value <I>t</I> is expressed in unary.<P>
<a name="0a14_1d17">36.5-4<a name="0a14_1d17"><P>
<a name="0a14_1d0d"><a name="0a14_1d0e">The <I><B>set-partition problem</I></B> takes as input a set <I>S</I> of numbers. The question is whether the numbers can be partitioned into two sets <I>A</I> and <img src="960_b.gif"> such that <img src="961_a.gif">. Show that the set-partition problem is NP-complete.<P>
<a name="0a14_1d18">36.5-5<a name="0a14_1d18"><P>
<a name="0a14_1d0f"><a name="0a14_1d10">Show that the hamiltonian-path problem is NP-complete.<P>
<a name="0a14_1d19">36.5-6<a name="0a14_1d19"><P>
<a name="0a14_1d11"><a name="0a14_1d12">The <I><B>longest-simple-cycle problem</I></B> is the problem of determining a simple cycle (no repeated vertices) of maximum length in a graph. Show that this problem is NP-complete.<P>
<a name="0a14_1d1a">36.5-7<a name="0a14_1d1a"><P>
Professor Marconi proclaims that the subgraph used as widget <I>A</I> in the proof of Theorem 36.14 is more complicated than necessary: vertices <I>z</I><SUB>3</SUB> and <I>z</I><SUB>4</SUB> of Figure 36.15(a) and the vertices above and below them are not needed. Is the professor correct? That is, does the reduction work with this smaller version of the widget, or does the "either/or" property of the widget disappear?<P>
<P>


<P>







<h1><a name="0a15_1d1c">Problems<a name="0a15_1d1c"></h1><P>
<a name="0a15_1d1d">36-1     Independent set<a name="0a15_1d1d"><P>
<a name="0a15_1d13"><a name="0a15_1d14"><a name="0a15_1d15"><a name="0a15_1d16">An <I><B>independent set</I></B> of a graph <I>G</I> = (<I>V,E</I>) is a subset <I>V</I>' <I><IMG SRC="../IMAGES/rgtubar.gif"></I> <I>V</I> of vertices such that each edge in <I>E</I> is incident on at most one vertex in <I>V</I><I>'</I>. The <I><B>independent-set problem</I></B> is to find a maximum-size independent set in <I>G</I>.<P>
<I><B>a.     </I></B>Formulate a related decision problem for the independent-set problem, and prove that it is NP-complete. (<I>Hint:</I> Reduce from the clique problem.)<P>
<I><B>b.     </I></B>Suppose that you are given a subroutine to solve the decision problem you defined in part (a). Give an algorithm to find an independent set of maximum size. The running time of your algorithm should be polynomial in |<I>V| and |</I>E|, where queries to the black box are counted as a single step.<P>
Although the independent-set decision problem is NP-complete, certain special cases are polynomial-time solvable.<P>
<I><B>c.     </I></B>Give an efficient algorithm to solve the independent-set problem when each vertex in <I>G</I> has degree 2. Analyze the running time, and prove that your algorithm works correctly.<P>
<I><B>d.     </I></B>Give an efficient algorithm to solve the independent-set problem when <I>G</I> is bipartite. Analyze the running time, and prove that your algorithm works correctly. (<I>Hint:</I> Use the results of Section 27.3.)<P>
<img src="962_a.gif"><P>
<h4><a name="0a15_1d1e">Figure 36.20 The widget corresponding to a clause (x V y V z), used in Problem 36-2.<a name="0a15_1d1e"></sub></sup></h4><P>
<a name="0a15_1d1f">36-2     Graph coloring<a name="0a15_1d1f"><P>
<a name="0a15_1d17"><a name="0a15_1d18"><a name="0a15_1d19"><a name="0a15_1d1a">A <I><B>k-coloring</I></B> of an undirected graph <I>G</I> = (<I>V,E</I>) is a function <I>c</I> : <I>V</I> <IMG SRC="../IMAGES/arrow12.gif"> {1, 2, . . . , <I>k</I>} such that <I>c</I>(<I>u</I>) <IMG SRC="../IMAGES/noteq.gif"> <I>c</I>(<I>v</I>) for every edge (<I>u,v</I>) <IMG SRC="../IMAGES/memof12.gif"> <I>E</I>. In other words, the numbers 1, 2, . . . , <I>k</I> represent the <I>k</I> colors, and adjacent vertices must have different colors. The <I><B>graph-coloring problem</I></B> is to determine the minimum number of colors needed to color a given graph.<P>
<I><B>a.     </I></B>Give an efficient algorithm to determine a 2-coloring of a graph if one exists.<P>
<I><B>b.     </I></B>Cast the graph-coloring problem as a decision problem. Show that your decision problem is solvable in polynomial time if and only if the graph-coloring problem is solvable in polynomial time.<P>
<a name="0a15_1d1b"><I><B>c.     </I></B>Let the language 3-COLOR be the set of graphs that can be 3-colored. Show that if 3-COLOR is NP-complete, then your decision problem from part (b) is NP-complete.<P>
To prove that 3-COLOR is NP-complete, we use a reduction from 3-CNF-SAT. Given a formula &oslash; of <I>m</I> clauses on <I>n</I> variables <I>x</I><SUB>1</SUB>, <I>x</I><SUB>2</SUB>, . . . , <I>x<SUB>n</I></SUB>, we construct a graph <I>G</I> = (<I>V,E</I>) as follows. The set <I>V</I> consists of a vertex for each variable, a vertex for the negation of each variable, 5 vertices for each clause, and 3 special vertices: <FONT FACE="Courier New" SIZE=2>TRUE</FONT>, <FONT FACE="Courier New" SIZE=2>FALSE</FONT>, and <FONT FACE="Courier New" SIZE=2>RED</FONT>. The edges of the graph are of two types: "literal" edges that are independent of the clauses and "clause" edges that depend on the clauses. The literal edges form a triangle on the special vertices and also form a triangle on <I>x<SUB>i</I></SUB>, <IMG SRC="../IMAGES/rtdwnbrc.gif"><I>x<SUB>i</I></SUB>, and <FONT FACE="Courier New" SIZE=2>RED</FONT> for <I>i</I> = 1, 2, . . . , <I>n</I>.<P>
<I><B>d.     </I></B>Argue that in any 3-coloring <I>c</I> of a graph containing the literal edges, exactly one of a variable and its negation is colored <I>c</I>(<FONT FACE="Courier New" SIZE=2>TRUE</FONT>) and the other is colored <I>c</I>(<FONT FACE="Courier New" SIZE=2>FALSE</FONT>). Argue that for any truth assignment for &oslash;, there is a 3-coloring of the graph containing just the literal edges.<P>
The widget shown in Figure 36.20 is used to enforce the condition corresponding to a clause (<I>x</I> V <I>y</I> V <I>z</I>). Each clause requires a unique copy of the 5 vertices that are heavily shaded in the figure; they connect as shown to the literals of the clause and the special vertex <FONT FACE="Courier New" SIZE=2>TRUE</FONT>.<P>
<I><B>e.     </I></B>Argue that if each of <I>x, y</I>, and <I>z</I> is colored <I>c</I>(<FONT FACE="Courier New" SIZE=2>TRUE</FONT>) or <I>c</I>(<FONT FACE="Courier New" SIZE=2>FALSE</FONT>), then the widget is 3-colorable if and only if at least one of <I>x, y</I>, or <I>z</I> is colored <I>c</I>(<FONT FACE="Courier New" SIZE=2>TRUE</FONT>).<P>
<I><B>f.     </I></B>Complete the proof that 3-COLOR is NP-complete.<P>
<P>







<h1>Chapter notes</h1><P>
Garey and Johnson [79] provide a wonderful guide to NP-completeness, discussing the theory at length and providing a catalogue of many problems that were known to be NP-complete in 1979. (The list of NP-complete problem domains at the beginning of Section 36.5 is drawn from their table of contents.) Hopcroft and Ullman [104] and Lewis and Papadimitriou [139] have good treatments of NP-completeness in the context of complexity theory. Aho, Hopcroft, and Ullman [4] also cover NP-completeness and give several reductions, including a reduction for the vertex-cover problem from the hamiltonian-cycle problem.<P>
The class P was introduced in 1964 by Cobham [44] and, independently, in 1965 by Edmonds [61], who also introduced the class NP and conjectured that P <IMG SRC="../IMAGES/noteq.gif"> NP. The notion of NP-completeness was proposed in 1971 by Cook [49], who gave the first NP-completeness proofs for formula satisfiability and 3-CNF satisfiability. Levin [138] independently discovered the notion, giving an NP-completeness proof for a tiling problem. Karp [116] introduced the methodology of reductions in 1972 and demonstrated the rich variety of NP-complete problems. Karp's paper included the original NP-completeness proofs of the clique, vertex-cover, and hamiltonian-cycle problems. Since then, hundreds of problems have been proven to be NP-complete by many researchers.<P>
The proof of Theorem 36.14 was adapted from Papadimitriou and Steiglitz [154].<P>
<P>


<P>
<P>
<center>Go to <a href="chap37.htm">Chapter 37</A>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Back to <a href="toc.htm">Table of Contents</A>
</P>
</center>


</BODY></HTML>